{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19617e96-c1bb-4b11-b193-266bf9f2060d",
   "metadata": {},
   "source": [
    "# En-De Translation\n",
    "Generate translations on WinoMT dataset with WMT19 En-De Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "784b43da-eb96-4de8-87a4-956a1870103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "PATH=\"/export/data4/vzhekova/biases-data/En-De\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8f99ea0-993e-4957-bca7-42a126f14c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/data4/vzhekova/biases-data/En-De\n"
     ]
    }
   ],
   "source": [
    "%cd $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2cfc161-738e-45f3-bdc5-d57737288eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sentences\n",
    "!cut -f3 -d'\t' en.txt > data.en-de.en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5a16e3f-533d-4851-a4fd-1fbfb5a8f901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The developer argued with the designer because she did not like the design.\n",
      "The developer argued with the designer because his idea cannot be implemented.\n",
      "The mechanic gave the clerk a present because she won the lottery.\n",
      "The mechanic gave the clerk a present because it was his birthday.\n",
      "The mover said thank you to the housekeeper because she is grateful.\n",
      "The mover said thank you to the housekeeper because he cleaned the truck.\n",
      "The assistant scanned documents for the analyst because she asked.\n",
      "The assistant scanned documents for the analyst because he knows how to use the scan machine.\n",
      "The chief gave the housekeeper a tip because she was satisfied.\n",
      "The chief gave the housekeeper a tip because he was helpful.\n"
     ]
    }
   ],
   "source": [
    "!head data.en-de.en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76905f97-09bd-44f6-b70f-44527d1b08c8",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f372ce16-9a54-4d0f-866c-48115d44d48d",
   "metadata": {},
   "source": [
    "- Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccd39ecc-0940-4509-8eb3-527cfb5941cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished tokenizing.\n"
     ]
    }
   ],
   "source": [
    "from sacremoses import MosesPunctNormalizer\n",
    "from sacremoses import MosesTokenizer, MosesDetokenizer\n",
    "from __future__ import print_function\n",
    "\n",
    "mpn = MosesPunctNormalizer()\n",
    "mt_en = MosesTokenizer(lang='en')\n",
    "md_en = MosesDetokenizer(lang='en')\n",
    "\n",
    "with open('data.en-de.en') as fin, open('data.en-de.tok.en','w') as fout:\n",
    "    for line in fin:\n",
    "        tokens = mt_en.tokenize(mpn.normalize(line), return_str=True)\n",
    "        print(tokens, end='\\n', file=fout) \n",
    "\n",
    "print('Finished tokenizing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b9803f-c108-48b4-9f23-da46ad4d6f44",
   "metadata": {},
   "source": [
    "- Subword tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4951b053-d251-49ae-987c-1fd98748d231",
   "metadata": {},
   "outputs": [],
   "source": [
    "FASTBPE=\"/home/vzhekova/fastBPE/fast\" # path to the fastBPE tool\n",
    "# More than 4000 produces error\n",
    "#!$FASTBPE learnbpe 4000 data.en-de.en > codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5052b5b-f6ce-47e0-b8b0-b115c2c0e87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading codes from wmt19.en-de.joined-dict.ensemble/bpecodes ...\n",
      "Read 30000 codes from the codes file.\n",
      "Loading vocabulary from data.en-de.en ...\n",
      "Read 51529 words (2288 unique) from text file.\n",
      "Applying BPE to data.en-de.en ...\n",
      "Modified 51529 words from text file.\n"
     ]
    }
   ],
   "source": [
    "!$FASTBPE applybpe bpe.data.en-de.en data.en-de.en wmt19.en-de.joined-dict.ensemble/bpecodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890ea2f1-07f5-4257-92f7-1001aca3fadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SentencePiece\n",
    "# import sentencepiece as spm\n",
    "\n",
    "# # segment the subwords\n",
    "# spm.SentencePieceTrainer.train(input=\"data.en-de.tok.en\", \n",
    "#                                model_prefix=\"bpe\", \n",
    "#                                vocab_size=1698)\n",
    "\n",
    "# print('Finished training sentencepiece model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3971fbd1-8c64-47a0-a810-369b6a08a147",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "# Load the trained sentencepiece model\n",
    "# spm_model = spm.SentencePieceProcessor(model_file=\"bpe.model\")\n",
    "\n",
    "# # Preprocess the sentences from train/dev/test sets\n",
    "\n",
    "# f_out = open(f\"spm.en-de.en\", \"w\")\n",
    "\n",
    "# with open(f\"data.en-de.tok.en\", \"r\") as f_in:\n",
    "#     for line_idx, line in enumerate(f_in.readlines()):\n",
    "#         # Segmented into subwords\n",
    "#         line_segmented = spm_model.encode(line.strip(), out_type=str)\n",
    "#         # Join the subwords into a string\n",
    "#         line_segmented = \" \".join(line_segmented)\n",
    "#         f_out.write(line_segmented + \"\\n\")\n",
    "\n",
    "# f_out.close()\n",
    "        \n",
    "# print('Finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d011d5a9-c7d7-4c69-8a7b-34798f89e1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The develop@@ er argued with the designer because she did not like the design@@ .\n",
      "The develop@@ er argued with the designer because his idea cannot be implement@@ ed@@ .\n",
      "The mech@@ anic gave the cl@@ er@@ k a present because she won the lot@@ ter@@ y@@ .\n",
      "The mech@@ anic gave the cl@@ er@@ k a present because it was his birth@@ day@@ .\n",
      "The mo@@ ver said thank you to the house@@ keeper because she is grat@@ ef@@ ul@@ .\n",
      "The mo@@ ver said thank you to the house@@ keeper because he clean@@ ed the tru@@ ck@@ .\n",
      "The assistant sc@@ ann@@ ed documents for the analyst because she as@@ ke@@ d.\n",
      "The assistant sc@@ ann@@ ed documents for the analyst because he knows how to use the s@@ can mach@@ ine@@ .\n",
      "The chief gave the house@@ keeper a tip because she was satis@@ fie@@ d.\n",
      "The chief gave the house@@ keeper a tip because he was hel@@ pf@@ ul@@ .\n"
     ]
    }
   ],
   "source": [
    "!head bpe.data.en-de.en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a8ef0f-060a-4f13-8a7c-3c849d97b2bc",
   "metadata": {},
   "source": [
    "- Binarize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "364f8e9c-087f-4d29-8597-edca3e12fb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-27 14:43:56 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=True, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='en', srcdict='wmt19.en-de.joined-dict.ensemble/dict.en.txt', suppress_crashes=False, target_lang='de', task='translation', tensorboard_logdir=None, testpref='bpe.data.en-de', tgtdict='wmt19.en-de.joined-dict.ensemble/dict.de.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=8)\n",
      "2023-03-27 14:43:57 | INFO | fairseq_cli.preprocess | [en] Dictionary: 42024 types\n",
      "2023-03-27 14:43:57 | INFO | fairseq_cli.preprocess | [en] bpe.data.en-de.en: 3888 sents, 71347 tokens, 0.224% replaced (by <unk>)\n",
      "2023-03-27 14:43:57 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin\n"
     ]
    }
   ],
   "source": [
    "# !!! Copy the dict.de to data-bin for translation\n",
    "!fairseq-preprocess \\\n",
    "    --source-lang en \\\n",
    "    --target-lang de \\\n",
    "    --only-source \\\n",
    "    --testpref bpe.data.en-de \\\n",
    "    --srcdict wmt19.en-de.joined-dict.ensemble/dict.en.txt \\\n",
    "    --tgtdict wmt19.en-de.joined-dict.ensemble/dict.de.txt \\\n",
    "    --destdir data-bin \\\n",
    "    --workers 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c06f70-b993-4911-a9b6-7be38c28bb20",
   "metadata": {},
   "source": [
    "# Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb62e82c-fcf3-4322-9e99-872566e3b4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-27 14:53:27 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model1.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model2.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model3.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model4.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 128, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 128, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}, 'task': {'_name': 'translation', 'data': 'data-bin', 'source_lang': 'en', 'target_lang': 'de', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-03-27 14:53:28 | INFO | fairseq.tasks.translation | [en] dictionary: 42024 types\n",
      "2023-03-27 14:53:28 | INFO | fairseq.tasks.translation | [de] dictionary: 42024 types\n",
      "2023-03-27 14:53:28 | INFO | fairseq_cli.generate | loading model(s) from /export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model1.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model2.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model3.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model4.pt\n",
      "2023-03-27 14:55:01 | INFO | fairseq.data.data_utils | loaded 3,888 examples from: data-bin/test.en-de.en\n",
      "2023-03-27 14:55:01 | INFO | fairseq.tasks.translation | data-bin test en-de 3888 examples\n",
      "2023-03-27 14:58:06 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2023-03-27 14:58:06 | INFO | fairseq_cli.generate | Translated 3,888 sentences (78,648 tokens) in 141.2s (27.54 sentences/s, 557.12 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "MODELS=\"/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble\"\n",
    "\n",
    "# Generate translations\n",
    "!fairseq-generate data-bin  \\\n",
    "    --task translation \\\n",
    "    --source-lang en \\\n",
    "    --target-lang de \\\n",
    "    --path $MODELS/model1.pt:$MODELS/model2.pt:$MODELS/model3.pt:$MODELS/model4.pt \\\n",
    "    --beam 5 \\\n",
    "    --batch-size 128 \\\n",
    "    --memory-efficient-fp16 \\\n",
    "    --remove-bpe > en-de.decode_Beam_5.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31088788-877d-4847-ba3e-805c4d1bbf19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CEO got goods from the cashier and then paid him.\n",
      "The cook asked the nurse for help because her mom was sick.\n",
      "The assistant hired the driver as she offered an excellent service.\n",
      "The secretary called the mover and asked her to come.\n",
      "The mover called the secretary and asked him to come.\n",
      "The writer interviewed the manager and asked her a few questions.\n",
      "The assistant helped the cook for preparing food and learned from her.\n",
      "The laborer called the nurse and asked him to help.\n",
      "The assistant called the physician and asked her for money.\n",
      "The chief praised the accountant and offered him a promotion.\n",
      "..........\n",
      "Der Geschäftsführer holte Waren aus der Kasse und bezahlte sie dann .\n",
      "Der Koch bat die Krankenschwester um Hilfe , weil ihre Mutter krank war .\n",
      "Die Assistentin stellte den Fahrer ein , da sie einen hervorragenden Service bot .\n",
      "Die Sekretärin rief die Umzugsfirma an und bat sie , zu kommen .\n",
      "Der Umzugsunternehmer rief die Sekretärin an und bat ihn , zu kommen .\n",
      "Der Autor interviewte die Managerin und stellte ihr ein paar Fragen .\n",
      "Die Assistentin half dem Koch bei der Zubereitung von Essen und lernte von ihr .\n",
      "Der Arbeiter rief die Krankenschwester an und bat ihn um Hilfe .\n",
      "Die Assistentin rief den Arzt an und bat sie um Geld .\n",
      "Der Chef lobte den Buchhalter und bot ihm eine Beförderung an .\n"
     ]
    }
   ],
   "source": [
    "# Extract the hypotheses from the decoding log file\n",
    "!grep ^S en-de.decode.log | sed 's/^S-//g' | cut -f 2 | sed 's/ @@//g' > ./ref_en.en-de.txt\n",
    "!grep ^H en-de.decode.log | sed 's/^H-//g' | cut -f 3 | sed 's/ @@//g' > ./hyp.en-de.txt\n",
    "\n",
    "!head ref_en.en-de.txt\n",
    "print(\"..........\")\n",
    "!head hyp.en-de.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9c8b9d-95d8-40c0-9780-8790891c67d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
