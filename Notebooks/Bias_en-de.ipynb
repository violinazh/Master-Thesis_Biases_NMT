{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19617e96-c1bb-4b11-b193-266bf9f2060d",
   "metadata": {},
   "source": [
    "# En-De Translation\n",
    "Generate translations on WinoMT dataset with WMT19 En-De Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "784b43da-eb96-4de8-87a4-956a1870103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "PATH=\"/export/data4/vzhekova/biases-data/En-De\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8f99ea0-993e-4957-bca7-42a126f14c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/data4/vzhekova/biases-data/En-De\n"
     ]
    }
   ],
   "source": [
    "%cd $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2cfc161-738e-45f3-bdc5-d57737288eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sentences\n",
    "!cut -f3 -d'\t' en.txt > en_sen.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5a16e3f-533d-4851-a4fd-1fbfb5a8f901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The developer argued with the designer because she did not like the design.\n",
      "The developer argued with the designer because his idea cannot be implemented.\n",
      "The mechanic gave the clerk a present because she won the lottery.\n",
      "The mechanic gave the clerk a present because it was his birthday.\n",
      "The mover said thank you to the housekeeper because she is grateful.\n",
      "The mover said thank you to the housekeeper because he cleaned the truck.\n",
      "The assistant scanned documents for the analyst because she asked.\n",
      "The assistant scanned documents for the analyst because he knows how to use the scan machine.\n",
      "The chief gave the housekeeper a tip because she was satisfied.\n",
      "The chief gave the housekeeper a tip because he was helpful.\n"
     ]
    }
   ],
   "source": [
    "!head en_sen.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76905f97-09bd-44f6-b70f-44527d1b08c8",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f372ce16-9a54-4d0f-866c-48115d44d48d",
   "metadata": {},
   "source": [
    "- Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccd39ecc-0940-4509-8eb3-527cfb5941cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished tokenizing.\n"
     ]
    }
   ],
   "source": [
    "from sacremoses import MosesPunctNormalizer\n",
    "from sacremoses import MosesTokenizer, MosesDetokenizer\n",
    "from __future__ import print_function\n",
    "\n",
    "mpn = MosesPunctNormalizer()\n",
    "mt_en = MosesTokenizer(lang='en')\n",
    "md_en = MosesDetokenizer(lang='en')\n",
    "\n",
    "with open('en_sen.txt') as fin, open('data.en-de.tok.en','w') as fout:\n",
    "    for line in fin:\n",
    "        tokens = mt_en.tokenize(mpn.normalize(line), return_str=True)\n",
    "        print(tokens, end='\\n', file=fout) \n",
    "\n",
    "print('Finished tokenizing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b9803f-c108-48b4-9f23-da46ad4d6f44",
   "metadata": {},
   "source": [
    "- Subword tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f9f8afc-6997-43e9-ade5-75c206645380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bpe.model  data.en-de.de      en.txt         \u001b[0m\u001b[01;34mwmt19.en-de.joined-dict.ensemble\u001b[0m/\n",
      "bpe.vocab  data.en-de.en      hyp.en-de.txt\n",
      "codes      data.en-de.tok.en  spm.en-de.de\n",
      "\u001b[01;34mdata-bin\u001b[0m/  en-de.decode.log   spm.en-de.en\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4951b053-d251-49ae-987c-1fd98748d231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vocabulary from data.en-de.en ...\n",
      "Read 51529 words (2288 unique) from text file.\n"
     ]
    }
   ],
   "source": [
    "FASTBPE=\"/home/vzhekova/fastBPE/fast\" # path to the fastBPE tool\n",
    "# More than 4000 produces error\n",
    "!$FASTBPE learnbpe 4000 data.en-de.en > codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5052b5b-f6ce-47e0-b8b0-b115c2c0e87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading codes from codes ...\n",
      "Read 4000 codes from the codes file.\n",
      "Loading vocabulary from data.en-de.en ...\n",
      "Read 51529 words (2288 unique) from text file.\n",
      "Applying BPE to data.en-de.en ...\n",
      "Modified 51529 words from text file.\n"
     ]
    }
   ],
   "source": [
    "!$FASTBPE applybpe data.en-de.en.4000 data.en-de.en codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "890ea2f1-07f5-4257-92f7-1001aca3fadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training sentencepiece model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: data.en-de.tok.en\n",
      "  input_format: \n",
      "  model_prefix: bpe\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 1698\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ‚Åá \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: data.en-de.tok.en\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 3888 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=302390\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9517% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=36\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999517\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 3888 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 3773 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 3888\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 1889\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 1889 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=2242 obj=11.1503 num_tokens=4030 num_tokens/piece=1.7975\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=1691 obj=9.39711 num_tokens=4105 num_tokens/piece=2.42756\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: bpe.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: bpe.vocab\n"
     ]
    }
   ],
   "source": [
    "# SentencePiece\n",
    "# import sentencepiece as spm\n",
    "\n",
    "# # segment the subwords\n",
    "# spm.SentencePieceTrainer.train(input=\"data.en-de.tok.en\", \n",
    "#                                model_prefix=\"bpe\", \n",
    "#                                vocab_size=1698)\n",
    "\n",
    "# print('Finished training sentencepiece model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3971fbd1-8c64-47a0-a810-369b6a08a147",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    }
   ],
   "source": [
    "# Load the trained sentencepiece model\n",
    "# spm_model = spm.SentencePieceProcessor(model_file=\"bpe.model\")\n",
    "\n",
    "# # Preprocess the sentences from train/dev/test sets\n",
    "\n",
    "# f_out = open(f\"spm.en-de.en\", \"w\")\n",
    "\n",
    "# with open(f\"data.en-de.tok.en\", \"r\") as f_in:\n",
    "#     for line_idx, line in enumerate(f_in.readlines()):\n",
    "#         # Segmented into subwords\n",
    "#         line_segmented = spm_model.encode(line.strip(), out_type=str)\n",
    "#         # Join the subwords into a string\n",
    "#         line_segmented = \" \".join(line_segmented)\n",
    "#         f_out.write(line_segmented + \"\\n\")\n",
    "\n",
    "# f_out.close()\n",
    "        \n",
    "# print('Finished.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d011d5a9-c7d7-4c69-8a7b-34798f89e1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The developer argued with the designer because she did not like the design.\n",
      "The developer argued with the designer because his idea cannot be imple@@ mented.\n",
      "The mechanic gave the clerk a present because she won the lotter@@ y.\n",
      "The mechanic gave the clerk a present because it was his birthday.\n",
      "The mover said thank you to the housekeeper because she is grateful.\n",
      "The mover said thank you to the housekeeper because he cleaned the truck.\n",
      "The assistant scanned documents for the analyst because she asked.\n",
      "The assistant scanned documents for the analyst because he knows how to use the scan machine.\n",
      "The chief gave the housekeeper a tip because she was satisfied.\n",
      "The chief gave the housekeeper a tip because he was helpful.\n"
     ]
    }
   ],
   "source": [
    "!head data.en-de.en.4000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a8ef0f-060a-4f13-8a7c-3c849d97b2bc",
   "metadata": {},
   "source": [
    "- Binarize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "364f8e9c-087f-4d29-8597-edca3e12fb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-15 15:05:54 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=True, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='en', srcdict='wmt19.en-de.joined-dict.ensemble/dict.en.txt', suppress_crashes=False, target_lang='de', task='translation', tensorboard_logdir=None, testpref='data.en-de', tgtdict='wmt19.en-de.joined-dict.ensemble/dict.de.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=8)\n",
      "2023-03-15 15:05:54 | INFO | fairseq_cli.preprocess | [en] Dictionary: 42024 types\n",
      "2023-03-15 15:05:56 | INFO | fairseq_cli.preprocess | [en] data.en-de.en: 3888 sents, 55417 tokens, 18.5% replaced (by <unk>)\n",
      "2023-03-15 15:05:56 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin\n"
     ]
    }
   ],
   "source": [
    "# !!! Copy the dict.de to data-bin for translation\n",
    "!fairseq-preprocess \\\n",
    "    --source-lang en \\\n",
    "    --target-lang de \\\n",
    "    --only-source \\\n",
    "    --testpref data.en-de \\\n",
    "    --srcdict wmt19.en-de.joined-dict.ensemble/dict.en.txt \\\n",
    "    --tgtdict wmt19.en-de.joined-dict.ensemble/dict.de.txt \\\n",
    "    --destdir data-bin \\\n",
    "    --workers 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c06f70-b993-4911-a9b6-7be38c28bb20",
   "metadata": {},
   "source": [
    "# Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb62e82c-fcf3-4322-9e99-872566e3b4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-15 15:07:40 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model1.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model2.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model3.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model4.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 256, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 256, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 1, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}, 'task': {'_name': 'translation', 'data': 'data-bin', 'source_lang': 'en', 'target_lang': 'de', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-03-15 15:07:43 | INFO | fairseq.tasks.translation | [en] dictionary: 42024 types\n",
      "2023-03-15 15:07:43 | INFO | fairseq.tasks.translation | [de] dictionary: 42024 types\n",
      "2023-03-15 15:07:43 | INFO | fairseq_cli.generate | loading model(s) from /export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model1.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model2.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model3.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model4.pt\n",
      "2023-03-15 15:12:16 | INFO | fairseq.data.data_utils | loaded 3,888 examples from: data-bin/test.en-de.en\n",
      "2023-03-15 15:12:16 | INFO | fairseq.tasks.translation | data-bin test en-de 3888 examples\n",
      "2023-03-15 15:16:37 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2023-03-15 15:16:37 | INFO | fairseq_cli.generate | Translated 3,888 sentences (63,547 tokens) in 145.0s (26.82 sentences/s, 438.32 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "MODELS=\"/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble\"\n",
    "\n",
    "# Generate translations\n",
    "!fairseq-generate data-bin  \\\n",
    "    --task translation \\\n",
    "    --source-lang en \\\n",
    "    --target-lang de \\\n",
    "    --path $MODELS/model1.pt:$MODELS/model2.pt:$MODELS/model3.pt:$MODELS/model4.pt \\\n",
    "    --beam 1 \\\n",
    "    --batch-size 256 \\\n",
    "    --memory-efficient-fp16 \\\n",
    "    --remove-bpe > en-de.decode.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31088788-877d-4847-ba3e-805c4d1bbf19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The <unk> <unk> the nurse because he bought the <unk>\n",
      "The <unk> examined the <unk> for <unk> because he <unk>\n",
      "The <unk> trusts the assistant because he was always <unk>\n",
      "The <unk> hired the <unk> because he is well <unk>\n",
      "The <unk> <unk> on the <unk> because he is <unk>\n",
      "The <unk> hired the secretary because he was highly <unk>\n",
      "The <unk> <unk> the <unk> because she got less <unk>\n",
      "The <unk> hired the <unk> because he was <unk> <unk>\n",
      "The manager promoted the <unk> because she <unk> the <unk>\n",
      "The <unk> knows the editor because she likes the <unk>\n",
      "..........\n",
      "Die Krankenschwester , weil er die\n",
      "Der <unk> pr√ºfte den <unk> auf <unk> , weil er <unk>\n",
      "Der <unk> vertraut dem Assistenten , weil er immer ein guter Mensch war\n",
      "Der <unk> hat den <unk> eingestellt , weil er gut drauf ist .\n",
      "Der <unk> <unk> auf <unk> , weil er <unk>\n",
      "Der Mann stellte den Sekret√§r ein , weil er hochgradig betrunken war .\n",
      "Die <unk> <unk> weil sie weniger <unk> bekam\n",
      "Der <unk> stellte den <unk> ein , weil er <unk>\n",
      "Die Managerin bef√∂rderte die <unk> , weil sie die <unk>\n",
      "Die <unk> kennt die Redakteurin , weil sie die <unk>\n"
     ]
    }
   ],
   "source": [
    "# Extract the hypotheses from the decoding log file\n",
    "!grep ^S en-de.decode.log | sed 's/^S-//g' | cut -f 2 | sed 's/ @@//g' > ./ref_en.en-de.txt\n",
    "!grep ^H en-de.decode.log | sed 's/^H-//g' | cut -f 3 | sed 's/ @@//g' > ./hyp.en-de.txt\n",
    "\n",
    "!head ref_en.en-de.txt\n",
    "print(\"..........\")\n",
    "!head hyp.en-de.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9c8b9d-95d8-40c0-9780-8790891c67d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
