{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee7f7abf-ae39-4baa-9ef1-1638e5b4ed47",
   "metadata": {},
   "source": [
    "# En-Fr Translation\n",
    "Generate translations on MuST-SHE dataset with WMT14 En-Fr Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "416b2005-931f-4e35-ac54-ec1f1857c0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ad23e83-1b89-48ea-8608-bb618bf3c19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/data4/vzhekova/MuST-SHE_v1.2/MuST-SHE-v1.2-data/tsv\n"
     ]
    }
   ],
   "source": [
    "%cd /export/data4/vzhekova/MuST-SHE_v1.2/MuST-SHE-v1.2-data/tsv\n",
    "\n",
    "!cut -f5 MONOLINGUAL.fr_v1.2.tsv > data.en-fr.en\n",
    "!cut -f6 MONOLINGUAL.fr_v1.2.tsv > data.en-fr.fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66b5663e-9b69-4e32-98f0-9a626b80991a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/data4/vzhekova/biases-data/En-Fr\n"
     ]
    }
   ],
   "source": [
    "PATH=\"/export/data4/vzhekova/biases-data/En-Fr\"\n",
    "\n",
    "%cd $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9dca8c96-5bd9-4d3f-9a1f-f7a388c944d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First lines of English:\n",
      "\n",
      "Now, I thought, \"How could I really capture this?\n",
      "I mean, from this entry, it would seem that I was born into a world that perceived someone like me to have nothing positive whatsoever going for them, when in fact, today I'm celebrated for the opportunities and adventures my life has procured.\n",
      "So, I immediately went to look up the 2009 online edition, expecting to find a revision worth noting.\n",
      "His name was Dr. Pizzutillo, an Italian American, whose name, apparently, was too difficult for most Americans to pronounce, so he went by Dr. P. And Dr. P always wore really colorful bow ties and had the very perfect disposition to work with children.\n",
      "And, one day, he came in to my session — exhaustive and unforgiving, these sessions — and he said to me, \"Wow.\n",
      "Now, of course, this was a simple ploy on Dr. P's part to get me to do the exercises I didn't want to do before the prospect of being the richest five-year-old in the second floor ward, but what he effectively did for me was reshape an awful daily occurrence into a new and promising experience for me.\n",
      "And I have to wonder today to what extent his vision and his declaration of me as a strong and powerful little girl shaped my own view of myself as an inherently strong, powerful and athletic person well into the future.\n",
      "And so my mother's prenatal physician had gone on vacation, so the man who delivered me was a complete stranger to my parents.\n",
      "And, because I was born without the fibula bones, and had feet turned in, and a few toes in this foot and a few toes in that, he had to be the bearer — this stranger had to be the bearer of bad news.\n",
      "And, because I was born without the fibula bones, and had feet turned in, and a few toes in this foot and a few toes in that, he had to be the bearer — this stranger had to be the bearer of bad news.\n",
      "\n",
      "First lines of French:\n",
      "\n",
      "Je me suis demandé comment je pourrais résumer visuellement cela.\n",
      "Je veux dire, d'après cette entrée, il semblerait que je sois née dans un monde qui percevrait les gens comme moi comme n'ayant absolument rien pour eux, alors qu'en fait, aujourd'hui, je suis célébrée pour les opportunités et les aventures que ma vie m'a apportée.\n",
      "Alors je suis tout de suite allée regarder dans l'édition 2009 en m'attendant à trouver une révision notable.\n",
      "Son nom est Dr Pizzutillo. Un Italo-Américain, dont le nom, apparemment, était trop difficile à prononcer pour la plupart des Américains, alors il est devenu Dr P. Et Dr. P portait toujours des noeuds papillon très colorés et avait le plus parfait tempérament pour travailler avec des enfants.\n",
      "Et un jour il est venu à ma séance - des séances épuisantes et sans pitié — et il m'a dit \"Wahou.\n",
      "Bien sûr, c'était juste un stratagème de la part de Dr P ♪ pour me faire faire ces exercices que je ne voulais pas faire dans la perspective de devenir la fille de 5 ans la plus riche de l'étage, mais ce qu'il a vraiment fait pour moi, ça a été de transformer un affreux événement quotidien en une expérience nouvelle et prometteuse.\n",
      "Et je me demande aujourd'hui, dans quelle mesure sa vision, et le fait qu'il m'ait déclaré une petite fille forte et puissante, ont dessiné ma propre vision de moi-même loin dans le futur, comme une personne par nature forte, puissante et athlétique.\n",
      "Et donc le médecin prénatal de ma mère était parti en vacances, et l'homme qui m'a mise au monde était un étranger complet pour mes parents.\n",
      "Et, comme je suis née sans tibia, et que j'avais les pieds tournés vers l'intérieur, et quelques orteils sur ce pied-ci, et quelques orteils sur ce pied-là, il a dû être le porteur, cet étranger a dû être le porteur de la mauvaise nouvelle.\n",
      "Et, comme je suis née sans tibia, et que j'avais les pieds tournés vers l'intérieur, et quelques orteils sur ce pied-ci, et quelques orteils sur ce pied-là, il a dû être le porteur, cet étranger a dû être le porteur de la mauvaise nouvelle.\n"
     ]
    }
   ],
   "source": [
    "!echo -e \"\\nFirst lines of English:\\n\"\n",
    "!head data.en-fr.en\n",
    "!echo -e \"\\nFirst lines of French:\\n\"\n",
    "!head data.en-fr.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2794931d-1c8e-4754-b81d-87c688e398f5",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a940cda-28a8-4c30-90df-11084b117e7d",
   "metadata": {},
   "source": [
    "- Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "49a31954-1bac-4f40-92a9-bce45df99f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished tokenizing.\n"
     ]
    }
   ],
   "source": [
    "# Tokenize text; MuST-SHE dataset\n",
    "from sacremoses import MosesPunctNormalizer\n",
    "from sacremoses import MosesTokenizer, MosesDetokenizer\n",
    "from __future__ import print_function\n",
    "\n",
    "mpn = MosesPunctNormalizer()\n",
    "mt_en = MosesTokenizer(lang='en')\n",
    "\n",
    "with open('data.en-fr.en') as fin, open('tok.data.en-fr.en','w') as fout:\n",
    "    for line in fin:\n",
    "        tokens = mt_en.tokenize(mpn.normalize(line), return_str=True)\n",
    "        print(tokens, end='\\n', file=fout) \n",
    "        \n",
    "mt_fr = MosesTokenizer(lang='fr')\n",
    "\n",
    "with open('data.en-fr.fr') as fin, open('tok.data.en-fr.fr','w') as fout:\n",
    "    for line in fin:\n",
    "        tokens = mt_fr.tokenize(mpn.normalize(line), return_str=True)\n",
    "        print(tokens, end='\\n', file=fout)\n",
    "\n",
    "print('Finished tokenizing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836cc4e4-c210-4b47-a70d-40ffd5bc4087",
   "metadata": {},
   "source": [
    "- Subword segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a753f0-3e72-45bd-824b-722b4fe2cf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train subword model\n",
    "#!subword-nmt learn-bpe -s 32000 < data.en-fr.tok.en > sw.model.en\n",
    "#!subword-nmt learn-bpe -s 32000 < data.en-fr.tok.fr > sw.model.fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44a05e66-8fce-416a-b8e1-098bc2da3c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished subword.\n"
     ]
    }
   ],
   "source": [
    "# Apply subword model; reuse bpecodes from existing model\n",
    "!subword-nmt apply-bpe -c wmt14.en-fr.joined-dict.transformer/bpecodes < tok.data.en-fr.en > sw.data.en-fr.en\n",
    "!subword-nmt apply-bpe -c wmt14.en-fr.joined-dict.transformer/bpecodes < tok.data.en-fr.fr > sw.data.en-fr.fr\n",
    "\n",
    "print('Finished subword.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e36c9ea3-3a74-4eb2-9e19-960ccec689a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First lines of tokenized English:\n",
      "\n",
      "Now , I thought , &quot; How could I really capture this ?\n",
      "I mean , from this entry , it would seem that I was born into a world that perceived someone like me to have nothing positive whatsoever going for them , when in fact , today I &apos;m celebrated for the opportunities and adv@@ entures my life has procu@@ red .\n",
      "So , I immediately went to look up the 2009 online edition , exp@@ ecting to find a revision worth noting .\n",
      "His name was Dr. P@@ iz@@ z@@ uti@@ ll@@ o , an Italian American , whose name , apparently , was too difficult for most Americans to pron@@ ounce , so he went by Dr. P. And Dr. P always wor@@ e really color@@ ful bow ties and had the very perfect disposition to work with children .\n",
      "And , one day , he came in to my session - exhaustive and un@@ for@@ giving , these sessions - and he said to me , &quot; W@@ ow .\n",
      "Now , of course , this was a simple plo@@ y on Dr. P &apos;s part to get me to do the exercises I didn &apos;t want to do before the prospect of being the rich@@ est fi@@ ve@@ -@@ year@@ -@@ old in the second floor ward , but what he effectively did for me was resh@@ ape an aw@@ ful daily occurrence into a new and promising experience for me .\n",
      "And I have to wonder today to what extent his vision and his declaration of me as a strong and powerful little girl shaped my own view of myself as an inher@@ ently strong , powerful and athle@@ tic person well into the future .\n",
      "And so my mother &apos;s pren@@ atal physician had gone on vacation , so the man who delivered me was a complete str@@ anger to my parents .\n",
      "And , because I was born without the fi@@ bu@@ la b@@ ones , and had feet turned in , and a few to@@ es in this foot and a few to@@ es in that , he had to be the be@@ arer - this str@@ anger had to be the be@@ arer of bad news .\n",
      "And , because I was born without the fi@@ bu@@ la b@@ ones , and had feet turned in , and a few to@@ es in this foot and a few to@@ es in that , he had to be the be@@ arer - this str@@ anger had to be the be@@ arer of bad news .\n",
      "\n",
      "First lines of tokenized French:\n",
      "\n",
      "Je me suis demandé comment je pourr@@ ais résumer visu@@ ellement cela .\n",
      "Je veux dire , d&apos; après cette entrée , il semblerait que je so@@ is née dans un monde qui perc@@ ev@@ rait les gens comme moi comme n&apos; ayant absolument rien pour eux , alors qu&apos; en fait , aujourd&apos; hui , je suis céléb@@ rée pour les opportunités et les av@@ entures que ma vie m&apos; a apportée .\n",
      "Alors je suis tout de suite allée regarder dans l&apos; édition 2009 en m&apos; attendant à trouver une révision notable .\n",
      "Son nom est Dr P@@ iz@@ z@@ uti@@ ll@@ o . Un Ital@@ o@@ -@@ Améric@@ ain , dont le nom , apparemment , était trop difficile à prononcer pour la plupart des Américains , alors il est devenu Dr P. Et Dr . P portait toujours des no@@ eu@@ ds pap@@ illon très color@@ és et avait le plus parfait tempér@@ ament pour travailler avec des enfants .\n",
      "Et un jour il est venu à ma séance - des séances épuis@@ antes et sans p@@ itié - et il m&apos; a dit &quot; W@@ ah@@ ou .\n",
      "Bien sûr , c&apos; était juste un strat@@ ag@@ ème de la part de Dr P ♪ pour me faire faire ces exercices que je ne vou@@ lais pas faire dans la perspective de devenir la fille de 5 ans la plus riche de l&apos; étage , mais ce qu&apos; il a vraiment fait pour moi , ça a été de transformer un aff@@ reux événement quotidien en une expérience nouvelle et promet@@ teuse .\n",
      "Et je me demande aujourd&apos; hui , dans quelle mesure sa vision , et le fait qu&apos; il m&apos; ait déclaré une petite fille forte et pu@@ issante , ont dess@@ iné ma propre vision de mo@@ i@@ -@@ même loin dans le futur , comme une personne par nature forte , pu@@ issante et athl@@ étique .\n",
      "Et donc le médecin prénat@@ al de ma mère était parti en vacances , et l&apos; homme qui m&apos; a mise au monde était un étranger complet pour mes parents .\n",
      "Et , comme je suis née sans ti@@ bia , et que j&apos; avais les pieds tourn@@ és vers l&apos; intérieur , et quelques or@@ te@@ ils sur ce pi@@ ed@@ -@@ ci , et quelques or@@ te@@ ils sur ce pi@@ ed@@ -@@ là , il a dû être le porteur , cet étranger a dû être le porteur de la mauvaise nouvelle .\n",
      "Et , comme je suis née sans ti@@ bia , et que j&apos; avais les pieds tourn@@ és vers l&apos; intérieur , et quelques or@@ te@@ ils sur ce pi@@ ed@@ -@@ ci , et quelques or@@ te@@ ils sur ce pi@@ ed@@ -@@ là , il a dû être le porteur , cet étranger a dû être le porteur de la mauvaise nouvelle .\n"
     ]
    }
   ],
   "source": [
    "!echo -e \"\\nFirst lines of tokenized English:\\n\"\n",
    "!head sw.data.en-fr.en\n",
    "\n",
    "!echo -e \"\\nFirst lines of tokenized French:\\n\"\n",
    "!head sw.data.en-fr.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0402e210-4d76-4bdf-b3a8-7eed29cda037",
   "metadata": {},
   "source": [
    "- Binarize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "035e9211-725c-486f-ace6-0cc622f9fb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-22 11:38:01 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=False, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='en', srcdict='wmt14.en-fr.joined-dict.transformer/dict.en.txt', suppress_crashes=False, target_lang='fr', task='translation', tensorboard_logdir=None, testpref='sw.data.en-fr', tgtdict='wmt14.en-fr.joined-dict.transformer/dict.fr.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=8)\n",
      "2023-03-22 11:38:02 | INFO | fairseq_cli.preprocess | [en] Dictionary: 44512 types\n",
      "2023-03-22 11:38:02 | INFO | fairseq_cli.preprocess | [en] sw.data.en-fr.en: 1108 sents, 38148 tokens, 0.0% replaced (by <unk>)\n",
      "2023-03-22 11:38:02 | INFO | fairseq_cli.preprocess | [fr] Dictionary: 44512 types\n",
      "2023-03-22 11:38:03 | INFO | fairseq_cli.preprocess | [fr] sw.data.en-fr.fr: 1108 sents, 40394 tokens, 0.0% replaced (by <unk>)\n",
      "2023-03-22 11:38:03 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin\n"
     ]
    }
   ],
   "source": [
    "# Binarize the data for training; test with moses tokenizer and subword_nmt failed -> BLEU score of 4\n",
    "\n",
    "# reuse model dict; solution for dictionary size to match test dataset \n",
    "# --tokenizer moses \\\n",
    "# --bpe subword_nmt \\\n",
    "!fairseq-preprocess \\\n",
    "    --source-lang en \\\n",
    "    --target-lang fr \\\n",
    "    --testpref sw.data.en-fr \\\n",
    "    --srcdict wmt14.en-fr.joined-dict.transformer/dict.en.txt \\\n",
    "    --tgtdict wmt14.en-fr.joined-dict.transformer/dict.fr.txt \\\n",
    "    --destdir data-bin \\\n",
    "    --workers 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fb8bee-451c-4f6c-bad6-6a5af54505fe",
   "metadata": {},
   "source": [
    "# Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cc698b33-d31f-4046-98ce-76c1cc617ee9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/data4/vzhekova/biases-data/En-Fr\n"
     ]
    }
   ],
   "source": [
    "%cd $PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dd7515-96e1-42e1-8358-7e6ffef919f6",
   "metadata": {},
   "source": [
    "- Beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b0264b10-bdb8-439e-bd09-856241d499b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-22 12:43:45 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'wmt14.en-fr.joined-dict.transformer/model.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 256, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 256, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}, 'task': {'_name': 'translation', 'data': 'data-bin', 'source_lang': 'en', 'target_lang': 'fr', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-03-22 12:43:47 | INFO | fairseq.tasks.translation | [en] dictionary: 44512 types\n",
      "2023-03-22 12:43:47 | INFO | fairseq.tasks.translation | [fr] dictionary: 44512 types\n",
      "2023-03-22 12:43:47 | INFO | fairseq_cli.generate | loading model(s) from wmt14.en-fr.joined-dict.transformer/model.pt\n",
      "2023-03-22 12:44:09 | INFO | fairseq.data.data_utils | loaded 1,108 examples from: data-bin/test.en-fr.en\n",
      "2023-03-22 12:44:09 | INFO | fairseq.data.data_utils | loaded 1,108 examples from: data-bin/test.en-fr.fr\n",
      "2023-03-22 12:44:09 | INFO | fairseq.tasks.translation | data-bin test en-fr 1108 examples\n",
      "2023-03-22 12:45:04 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2023-03-22 12:45:04 | INFO | fairseq_cli.generate | Translated 1,108 sentences (42,298 tokens) in 30.3s (36.63 sentences/s, 1398.25 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "# Generate translations\n",
    "!fairseq-generate data-bin  \\\n",
    "    --task translation \\\n",
    "    --source-lang en \\\n",
    "    --target-lang fr \\\n",
    "    --path wmt14.en-fr.joined-dict.transformer/model.pt \\\n",
    "    --beam 5 \\\n",
    "    --batch-size 256 \\\n",
    "    --memory-efficient-fp16 \\\n",
    "    --remove-bpe=subword_nmt > en-fr.decode.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aef7f3-4838-419e-9e80-62c0114c9a86",
   "metadata": {},
   "source": [
    "- Top-K-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d0871d36-181f-4ec0-87cb-89843b11fa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate translations\n",
    "# !fairseq-generate data-bin  \\\n",
    "#     --task translation \\\n",
    "#     --source-lang en \\\n",
    "#     --target-lang fr \\\n",
    "#     --path wmt14.en-fr.joined-dict.transformer/model.pt \\\n",
    "#     --sampling \\\n",
    "#     --sampling-topk 5 \\\n",
    "#     --nbest 5 \\\n",
    "#     --batch-size 256 \\\n",
    "#     --memory-efficient-fp16 \\\n",
    "#     --remove-bpe=subword_nmt > en-fr.decode.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3813030-4723-4e73-855c-802807ad6c55",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0f16baf3-949a-4346-8d5c-3c78c0a9de7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C&apos; est là que je suis né et que j&apos; ai passé les sept premières années de ma vie .\n",
      "Elle a suivi un cours dans une école de commerce et elle est devenue médecin vétérinaire .\n",
      "En tant que conservateur afro @-@ latino @-@ américain , je suis l&apos; un des rares .\n",
      "Je suis heureux de dire qu&apos; au cours des trois dernières années , nous avons fait des progrès .\n",
      "Après plusieurs séries d&apos; entrevues , je me suis inscrit au programme de bourses et j&apos; ai obtenu une bourse complète .\n",
      "Je lui ai prescrit de la pénicilline et je l&apos; ai envoyé en route .\n",
      "Je suis parmi tous ceux qui connaissent les précieuses contributions des dénonciateurs .\n",
      "Bonjour . Je m&apos; appelle Aparna . Je suis un bourreau -\n",
      "Et je pensais que c &quot; était super cool , alors je le montrais à mon ami .\n",
      "Je suis quelqu&apos; un qui se passionne vraiment pour les choses , alors je vais tempérer ça .\n",
      "..........\n",
      "Je suis née ici même , et j&apos; y ai passé les sept premières années de ma vie .\n",
      "Elle a fait une école de commerce puis est devenue vétérinaire .\n",
      "Les conservatrices afro-latinas ne sont qu&apos; une poignée .\n",
      "Je suis ravi de dire que les trois dernières années , nous avons progressé .\n",
      "Après plusieurs entretiens , j&apos; ai été acceptée dans le programme avec une bourse complète .\n",
      "Je lui ai prescrit de la pénicilline et l&apos; ai renvoyé chez lui .\n",
      "Je suis bien placée pour avoir conscience des contributions précieuses que font les lanceurs d&apos; alerte .\n",
      "Bonjour , je m&apos; appelle Aparna , je suis une acheteuse compulsive\n",
      "Je trouvais ça super et donc j&apos; étais fière de le montrer à mon ami .\n",
      "Je suis quelqu&apos; un qui m&apos; emballe très vite , alors je tempérais cela .\n"
     ]
    }
   ],
   "source": [
    "# Extract the hypotheses and references from the decoding log file\n",
    "# Replacing subword segmentation: sed -r 's/(@@ )|(@@ ?$)//g'\n",
    "!grep ^H en-fr.decode.log | sed 's/^H-//g' | cut -f 3 | sed 's/ @@//g' > ./hyp.en-fr.txt\n",
    "!grep ^T en-fr.decode.log | sed 's/^T-//g' | cut -f 2 | sed 's/ @@//g' > ./ref.en-fr.txt\n",
    "\n",
    "!head ./hyp.en-fr.txt\n",
    "print(\"..........\")\n",
    "!head ./ref.en-fr.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05368c0d-3e10-4ff8-9d9e-9c5d32856a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only the first hypothesis\n",
    "!awk 'NR % 5 == 1' ./hyp.en-fr.txt > ./hyp.en-fr.best.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "def5dcc4-b30b-43a6-b19e-92f135357a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished detokenizing.\n"
     ]
    }
   ],
   "source": [
    "# Detokenize text        \n",
    "\n",
    "md_fr = MosesDetokenizer(lang='fr')\n",
    "\n",
    "with open('hyp.en-fr.txt', encoding='utf8') as fin, open('hyp_detok.en-fr.txt','w', encoding='utf8') as fout:\n",
    "    for line in fin:\n",
    "        tokens = md_fr.detokenize(line.split(), return_str=True)\n",
    "        print(tokens, end='\\n', file=fout)\n",
    "        \n",
    "with open('ref.en-fr.txt', encoding='utf8') as fin, open('ref_detok.en-fr.txt','w', encoding='utf8') as fout:\n",
    "    for line in fin:\n",
    "        tokens = md_fr.detokenize(line.split(), return_str=True)\n",
    "        print(tokens, end='\\n', file=fout)\n",
    "\n",
    "print('Finished detokenizing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aff664f1-625b-48a2-8b7d-26f8329e367a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C'est là que je suis né et que j'ai passé les sept premières années de ma vie.\n",
      "Elle a suivi un cours dans une école de commerce et elle est devenue médecin vétérinaire.\n",
      "En tant que conservateur afro-latino-américain, je suis l'un des rares.\n",
      "Je suis heureux de dire qu'au cours des trois dernières années, nous avons fait des progrès.\n",
      "Après plusieurs séries d'entrevues, je me suis inscrit au programme de bourses et j'ai obtenu une bourse complète.\n",
      "Je lui ai prescrit de la pénicilline et je l'ai envoyé en route.\n",
      "Je suis parmi tous ceux qui connaissent les précieuses contributions des dénonciateurs.\n",
      "Bonjour. Je m'appelle Aparna. Je suis un bourreau -\n",
      "Et je pensais que c \"était super cool, alors je le montrais à mon ami.\n",
      "Je suis quelqu'un qui se passionne vraiment pour les choses, alors je vais tempérer ça.\n",
      "..........\n",
      "Je suis née ici même, et j'y ai passé les sept premières années de ma vie.\n",
      "Elle a fait une école de commerce puis est devenue vétérinaire.\n",
      "Les conservatrices afro-latinas ne sont qu'une poignée.\n",
      "Je suis ravi de dire que les trois dernières années, nous avons progressé.\n",
      "Après plusieurs entretiens, j'ai été acceptée dans le programme avec une bourse complète.\n",
      "Je lui ai prescrit de la pénicilline et l'ai renvoyé chez lui.\n",
      "Je suis bien placée pour avoir conscience des contributions précieuses que font les lanceurs d'alerte.\n",
      "Bonjour, je m'appelle Aparna, je suis une acheteuse compulsive\n",
      "Je trouvais ça super et donc j'étais fière de le montrer à mon ami.\n",
      "Je suis quelqu'un qui m'emballe très vite, alors je tempérais cela.\n"
     ]
    }
   ],
   "source": [
    "!head ./hyp_detok.en-fr.txt\n",
    "print(\"..........\")\n",
    "!head ./ref_detok.en-fr.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb82c04e-3fe6-45f0-abc8-fd1d94b13105",
   "metadata": {},
   "source": [
    "- BLEU score (sacreBleu works on detokenized input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "04b7966d-1948-4c16-bc1d-924c1f34181d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"name\": \"BLEU\",\n",
      " \"score\": 37.2,\n",
      " \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.3.1\",\n",
      " \"verbose_score\": \"63.4/42.6/31.0/22.8 (BP = 1.000 ratio = 1.059 hyp_len = 34334 ref_len = 32422)\",\n",
      " \"nrefs\": \"1\",\n",
      " \"case\": \"mixed\",\n",
      " \"eff\": \"no\",\n",
      " \"tok\": \"13a\",\n",
      " \"smooth\": \"exp\",\n",
      " \"version\": \"2.3.1\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "# BLEU score of 18.7 (beam=5), BLEU score of 18.2 (beam=1)\n",
    "# BLEU score of 37.2 (beam=5) when using bpecodes\n",
    "\n",
    "# BLEU score of 15.9 (sampling-topk=5)\n",
    "!cat ./hyp_detok.en-fr.txt | sacrebleu ./ref_detok.en-fr.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88a021a9-42b5-4938-bea3-6c8250e46261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(ignore_case=False, order=4, ref='./ref_detok.en-fr.txt', sacrebleu=True, sentence_bleu=False, sys='./hyp_detok.en-fr.txt')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vzhekova/miniconda3/envs/nmt/bin/fairseq-score\", line 8, in <module>\n",
      "    sys.exit(cli_main())\n",
      "  File \"/home/vzhekova/fairseq/fairseq_cli/score.py\", line 98, in cli_main\n",
      "    score(f)\n",
      "  File \"/home/vzhekova/fairseq/fairseq_cli/score.py\", line 61, in score\n",
      "    print(sacrebleu.corpus_bleu(fdsys, [fdref]).format())\n",
      "  File \"/home/vzhekova/miniconda3/envs/nmt/lib/python3.8/site-packages/sacrebleu/compat.py\", line 37, in corpus_bleu\n",
      "    return metric.corpus_score(hypotheses, references)\n",
      "  File \"/home/vzhekova/miniconda3/envs/nmt/lib/python3.8/site-packages/sacrebleu/metrics/base.py\", line 414, in corpus_score\n",
      "    self._check_corpus_score_args(hypotheses, references)\n",
      "  File \"/home/vzhekova/miniconda3/envs/nmt/lib/python3.8/site-packages/sacrebleu/metrics/base.py\", line 258, in _check_corpus_score_args\n",
      "    raise TypeError(f'{prefix}: {err_msg}')\n",
      "TypeError: BLEU: Each element of `refs` should be a sequence of strings.\n"
     ]
    }
   ],
   "source": [
    "!fairseq-score \\\n",
    "    --sacrebleu \\\n",
    "    --sys ./hyp_detok.en-fr.txt \\\n",
    "    --ref ./ref_detok.en-fr.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eba02d1-76dd-4eb7-9251-c02cbe4a8a6a",
   "metadata": {},
   "source": [
    "- Gender accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1c7c3861-f7a2-4d13-bbd0-7fe6e0c5237f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\tTerm Coverage\tGender Accuracy\n",
      "-------------------------------------------------\n",
      "1F\t0.04716981132075472\t0.4782608695652174\n",
      "1M\t0.07073170731707316\t0.6666666666666666\n",
      "2F\t0.08227848101265822\t0.45098039215686275\n",
      "2M\t0.13009708737864079\t0.5616438356164384\n",
      "3F\t0.0\t0.0\n",
      "3M\t0.0\t0.0\n",
      "4F\t0.14814814814814814\t0.2\n",
      "4M\t0.125\t0.375\n",
      "-------------------------------------------------\n",
      "Global\t0.08656873032528856\t0.5233160621761658\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Evaluate gender accuracy; 0.52\n",
    "!python /export/data4/vzhekova/MuST-SHE_v1.2/MuST-SHE-v1.1-eval-script/mustshe_acc_v1.1.py \\\n",
    "    --input hyp.en-fr.txt \\\n",
    "    --tsv-definition /export/data4/vzhekova/MuST-SHE_v1.2/MuST-SHE-v1.2-data/tsv/MONOLINGUAL.fr_v1.2.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfad36b-0045-402e-9ca0-99b6ef4f5736",
   "metadata": {},
   "source": [
    "# Translation with fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e6120c9-455b-49db-a93e-434613fec708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/data4/vzhekova/biases-data/En-Fr\n"
     ]
    }
   ],
   "source": [
    "%cd $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "302ac27c-11de-4606-96c7-82b36050b7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-22 11:43:12 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/export/data4/vzhekova/biases-data/En-Fr_MuST-C/checkpoints/checkpoint_best.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 256, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 256, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}, 'task': {'_name': 'translation', 'data': 'data-bin', 'source_lang': 'en', 'target_lang': 'fr', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-03-22 11:43:14 | INFO | fairseq.tasks.translation | [en] dictionary: 44512 types\n",
      "2023-03-22 11:43:14 | INFO | fairseq.tasks.translation | [fr] dictionary: 44512 types\n",
      "2023-03-22 11:43:14 | INFO | fairseq_cli.generate | loading model(s) from /export/data4/vzhekova/biases-data/En-Fr_MuST-C/checkpoints/checkpoint_best.pt\n",
      "2023-03-22 11:43:32 | INFO | fairseq.data.data_utils | loaded 1,108 examples from: data-bin/test.en-fr.en\n",
      "2023-03-22 11:43:32 | INFO | fairseq.data.data_utils | loaded 1,108 examples from: data-bin/test.en-fr.fr\n",
      "2023-03-22 11:43:32 | INFO | fairseq.tasks.translation | data-bin test en-fr 1108 examples\n",
      "2023-03-22 11:44:24 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2023-03-22 11:44:24 | INFO | fairseq_cli.generate | Translated 1,108 sentences (41,748 tokens) in 29.4s (37.65 sentences/s, 1418.75 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "# Generate translations\n",
    "!fairseq-generate data-bin  \\\n",
    "    --task translation \\\n",
    "    --source-lang en \\\n",
    "    --target-lang fr \\\n",
    "    --path /export/data4/vzhekova/biases-data/En-Fr_MuST-C/checkpoints/checkpoint_best.pt \\\n",
    "    --beam 5 \\\n",
    "    --batch-size 256 \\\n",
    "    --memory-efficient-fp16 \\\n",
    "    --remove-bpe=subword_nmt > en-fr.decode_finetuned.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "09e16d10-91cf-4901-976e-d0c5686fe698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C&apos; est sur ces terrains que je suis née et que j&apos; ai passé les sept premières années de ma vie .\n",
      "Elle a suivi un cours dans une école de commerce , et elle est devenue vétérinaire .\n",
      "En tant que conservateur afro-latin , je suis l&apos; un des rares .\n",
      "Je suis ravi de pouvoir dire qu&apos; au cours des trois dernières années , nous avons fait des progrès .\n",
      "Après de nombreux entretiens , j&apos; ai rejoint le programme de bourses avec une bourse complète .\n",
      "Et je lui ai donné une ordonnance de pénicilline et je l&apos; ai envoyé sur son chemin .\n",
      "Je sais les contributions précieuses que les dénonciateurs font .\n",
      "Bonjour . Je m&apos; appelle Aparna .\n",
      "Et je pensais que c&apos; était super cool , alors je le montrais à mon ami .\n",
      "Je suis quelqu&apos; un qui est vraiment excité par les choses , alors je l&apos; atténuerais .\n",
      "..........\n",
      "Je suis née ici même , et j&apos; y ai passé les sept premières années de ma vie .\n",
      "Elle a fait une école de commerce puis est devenue vétérinaire .\n",
      "Les conservatrices afro-latinas ne sont qu&apos; une poignée .\n",
      "Je suis ravi de dire que les trois dernières années , nous avons progressé .\n",
      "Après plusieurs entretiens , j&apos; ai été acceptée dans le programme avec une bourse complète .\n",
      "Je lui ai prescrit de la pénicilline et l&apos; ai renvoyé chez lui .\n",
      "Je suis bien placée pour avoir conscience des contributions précieuses que font les lanceurs d&apos; alerte .\n",
      "Bonjour , je m&apos; appelle Aparna , je suis une acheteuse compulsive\n",
      "Je trouvais ça super et donc j&apos; étais fière de le montrer à mon ami .\n",
      "Je suis quelqu&apos; un qui m&apos; emballe très vite , alors je tempérais cela .\n"
     ]
    }
   ],
   "source": [
    "# Extract the hypotheses and references from the decoding log file\n",
    "!grep ^H en-fr.decode_finetuned.log | sed 's/^H-//g' | cut -f 3 | sed 's/ @@//g' > ./hyp_finetuned.txt\n",
    "!grep ^T en-fr.decode_finetuned.log | sed 's/^T-//g' | cut -f 2 | sed 's/ @@//g' > ./ref_finetuned.txt\n",
    "\n",
    "!head ./hyp_finetuned.txt\n",
    "print(\"..........\")\n",
    "!head ./ref_finetuned.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "85266c00-f128-4d94-8c3a-21835a634d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished detokenizing.\n"
     ]
    }
   ],
   "source": [
    "# Detokenize text        \n",
    "\n",
    "md_fr = MosesDetokenizer(lang='fr')\n",
    "\n",
    "with open('hyp_finetuned.txt', encoding='utf8') as fin, open('hyp_finetuned_detok.txt','w', encoding='utf8') as fout:\n",
    "    for line in fin:\n",
    "        tokens = md_fr.detokenize(line.split(), return_str=True)\n",
    "        print(tokens, end='\\n', file=fout)\n",
    "        \n",
    "with open('ref_finetuned.txt', encoding='utf8') as fin, open('ref_finetuned_detok.txt','w', encoding='utf8') as fout:\n",
    "    for line in fin:\n",
    "        tokens = md_fr.detokenize(line.split(), return_str=True)\n",
    "        print(tokens, end='\\n', file=fout)\n",
    "\n",
    "print('Finished detokenizing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c0a27a7-9bff-44cb-b214-a881508123d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"name\": \"BLEU\",\n",
      " \"score\": 39.6,\n",
      " \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.3.1\",\n",
      " \"verbose_score\": \"65.7/45.3/33.3/24.9 (BP = 1.000 ratio = 1.037 hyp_len = 33619 ref_len = 32422)\",\n",
      " \"nrefs\": \"1\",\n",
      " \"case\": \"mixed\",\n",
      " \"eff\": \"no\",\n",
      " \"tok\": \"13a\",\n",
      " \"smooth\": \"exp\",\n",
      " \"version\": \"2.3.1\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "# BLEU score of 27.0 (beam=5)\n",
    "# BLEU score of 39.6 (beam=5) when using bpecodes\n",
    "!cat ./hyp_finetuned_detok.txt | sacrebleu ./ref_finetuned_detok.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb3ec7c8-cd82-4f11-a67f-c17006617892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\tTerm Coverage\tGender Accuracy\n",
      "-------------------------------------------------\n",
      "1F\t0.030660377358490566\t0.375\n",
      "1M\t0.06829268292682927\t0.6571428571428571\n",
      "2F\t0.10548523206751055\t0.39285714285714285\n",
      "2M\t0.11262135922330097\t0.5285714285714286\n",
      "3F\t0.0\t0.0\n",
      "3M\t0.0\t0.0\n",
      "4F\t0.07407407407407407\t0.0\n",
      "4M\t0.16666666666666666\t0.5555555555555556\n",
      "-------------------------------------------------\n",
      "Global\t0.08342077649527807\t0.4946808510638298\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Evaluate gender accuracy; 0.49\n",
    "!python /export/data4/vzhekova/MuST-SHE_v1.2/MuST-SHE-v1.1-eval-script/mustshe_acc_v1.1.py \\\n",
    "    --input hyp_finetuned_detok.txt \\\n",
    "    --tsv-definition /export/data4/vzhekova/MuST-SHE_v1.2/MuST-SHE-v1.2-data/tsv/MONOLINGUAL.fr_v1.2.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2e0880-8d09-4a50-8f0c-452ce79c7198",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
