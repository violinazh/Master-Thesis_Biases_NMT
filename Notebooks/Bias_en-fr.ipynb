{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee7f7abf-ae39-4baa-9ef1-1638e5b4ed47",
   "metadata": {},
   "source": [
    "# En-Fr Translation\n",
    "Generate translations on MuST-SHE dataset with WMT14 En-Fr Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "416b2005-931f-4e35-ac54-ec1f1857c0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ad23e83-1b89-48ea-8608-bb618bf3c19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/data4/vzhekova/MuST-SHE_v1.2/MuST-SHE-v1.2-data/tsv\n"
     ]
    }
   ],
   "source": [
    "%cd /export/data4/vzhekova/MuST-SHE_v1.2/MuST-SHE-v1.2-data/tsv\n",
    "\n",
    "!cut -f5 MONOLINGUAL.fr_v1.2.tsv > data.en-fr.en\n",
    "!cut -f6 MONOLINGUAL.fr_v1.2.tsv > data.en-fr.fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66b5663e-9b69-4e32-98f0-9a626b80991a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/data4/vzhekova/biases-data/En-Fr\n"
     ]
    }
   ],
   "source": [
    "PATH=\"/export/data4/vzhekova/biases-data/En-Fr\"\n",
    "\n",
    "%cd $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "9dca8c96-5bd9-4d3f-9a1f-f7a388c944d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First lines of English:\n",
      "\n",
      "﻿Now, I thought, \"How could I really capture this?\n",
      "I mean, from this entry, it would seem that I was born into a world that perceived someone like me to have nothing positive whatsoever going for them, when in fact, today I'm celebrated for the opportunities and adventures my life has procured.\n",
      "So, I immediately went to look up the 2009 online edition, expecting to find a revision worth noting.\n",
      "His name was Dr. Pizzutillo, an Italian American, whose name, apparently, was too difficult for most Americans to pronounce, so he went by Dr. P. And Dr. P always wore really colorful bow ties and had the very perfect disposition to work with children.\n",
      "And, one day, he came in to my session — exhaustive and unforgiving, these sessions — and he said to me, \"Wow.\n",
      "Now, of course, this was a simple ploy on Dr. P's part to get me to do the exercises I didn't want to do before the prospect of being the richest five-year-old in the second floor ward, but what he effectively did for me was reshape an awful daily occurrence into a new and promising experience for me.\n",
      "And I have to wonder today to what extent his vision and his declaration of me as a strong and powerful little girl shaped my own view of myself as an inherently strong, powerful and athletic person well into the future.\n",
      "And so my mother's prenatal physician had gone on vacation, so the man who delivered me was a complete stranger to my parents.\n",
      "And, because I was born without the fibula bones, and had feet turned in, and a few toes in this foot and a few toes in that, he had to be the bearer — this stranger had to be the bearer of bad news.\n",
      "And, because I was born without the fibula bones, and had feet turned in, and a few toes in this foot and a few toes in that, he had to be the bearer — this stranger had to be the bearer of bad news.\n",
      "\n",
      "First lines of French:\n",
      "\n",
      "﻿Je me suis demandé comment je pourrais résumer visuellement cela.\n",
      "Je veux dire, d'après cette entrée, il semblerait que je sois née dans un monde qui percevrait les gens comme moi comme n'ayant absolument rien pour eux, alors qu'en fait, aujourd'hui, je suis célébrée pour les opportunités et les aventures que ma vie m'a apportée.\n",
      "Alors je suis tout de suite allée regarder dans l'édition 2009 en m'attendant à trouver une révision notable.\n",
      "Son nom est Dr Pizzutillo. Un Italo-Américain, dont le nom, apparemment, était trop difficile à prononcer pour la plupart des Américains, alors il est devenu Dr P. Et Dr. P portait toujours des noeuds papillon très colorés et avait le plus parfait tempérament pour travailler avec des enfants.\n",
      "Et un jour il est venu à ma séance - des séances épuisantes et sans pitié — et il m'a dit \"Wahou.\n",
      "Bien sûr, c'était juste un stratagème de la part de Dr P ♪ pour me faire faire ces exercices que je ne voulais pas faire dans la perspective de devenir la fille de 5 ans la plus riche de l'étage, mais ce qu'il a vraiment fait pour moi, ça a été de transformer un affreux événement quotidien en une expérience nouvelle et prometteuse.\n",
      "Et je me demande aujourd'hui, dans quelle mesure sa vision, et le fait qu'il m'ait déclaré une petite fille forte et puissante, ont dessiné ma propre vision de moi-même loin dans le futur, comme une personne par nature forte, puissante et athlétique.\n",
      "Et donc le médecin prénatal de ma mère était parti en vacances, et l'homme qui m'a mise au monde était un étranger complet pour mes parents.\n",
      "Et, comme je suis née sans tibia, et que j'avais les pieds tournés vers l'intérieur, et quelques orteils sur ce pied-ci, et quelques orteils sur ce pied-là, il a dû être le porteur, cet étranger a dû être le porteur de la mauvaise nouvelle.\n",
      "Et, comme je suis née sans tibia, et que j'avais les pieds tournés vers l'intérieur, et quelques orteils sur ce pied-ci, et quelques orteils sur ce pied-là, il a dû être le porteur, cet étranger a dû être le porteur de la mauvaise nouvelle.\n"
     ]
    }
   ],
   "source": [
    "!echo -e \"\\nFirst lines of English:\\n\"\n",
    "!head data.en-fr.en\n",
    "!echo -e \"\\nFirst lines of French:\\n\"\n",
    "!head data.en-fr.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2794931d-1c8e-4754-b81d-87c688e398f5",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a940cda-28a8-4c30-90df-11084b117e7d",
   "metadata": {},
   "source": [
    "- Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49a31954-1bac-4f40-92a9-bce45df99f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished tokenizing.\n"
     ]
    }
   ],
   "source": [
    "# Tokenize text; MuST-SHE dataset\n",
    "# TODO: write script for preprocessing\n",
    "from sacremoses import MosesPunctNormalizer\n",
    "from sacremoses import MosesTokenizer, MosesDetokenizer\n",
    "from __future__ import print_function\n",
    "\n",
    "mpn = MosesPunctNormalizer()\n",
    "mt_en = MosesTokenizer(lang='en')\n",
    "md_en = MosesDetokenizer(lang='en')\n",
    "\n",
    "with open('data.en-fr.en') as fin, open('data.en-fr.tok.en','w') as fout:\n",
    "    for line in fin:\n",
    "        tokens = mt_en.tokenize(mpn.normalize(line), return_str=True)\n",
    "        print(tokens, end='\\n', file=fout) \n",
    "        \n",
    "mt_fr = MosesTokenizer(lang='fr')\n",
    "md_fr = MosesDetokenizer(lang='fr')\n",
    "\n",
    "with open('data.en-fr.fr') as fin, open('data.en-fr.tok.fr','w') as fout:\n",
    "    for line in fin:\n",
    "        tokens = mt_fr.tokenize(mpn.normalize(line), return_str=True)\n",
    "        print(tokens, end='\\n', file=fout)\n",
    "\n",
    "print('Finished tokenizing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3fda767b-fb58-4bb1-9ecd-64f79f73afe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished detokenizing.\n"
     ]
    }
   ],
   "source": [
    "# Detokenize text\n",
    "\n",
    "# mpn = MosesPunctNormalizer()\n",
    "# mt = MosesTokenizer(lang='en')\n",
    "# md = MosesDetokenizer(lang='en')\n",
    "\n",
    "# md.detokenize(mt.tokenize(md.detokenize(mpn.normalize('So, I immediately went to look up the 2009 online edition, expecting to find a revision worth noting.').split())))\n",
    "\n",
    "# with open('data.en-fr.tok.en') as fin, open('data.en-fr.detok.en','w') as fout:\n",
    "#     for line in fin:\n",
    "#         tokens = md_en.detokenize(line.split(), return_str=True)\n",
    "#         print(tokens, end='\\n', file=fout) \n",
    "\n",
    "# with open('data.en-fr.tok.fr') as fin, open('data.en-fr.detok.fr','w') as fout:\n",
    "#     for line in fin:\n",
    "#         tokens = md_fr.detokenize(line.split(), return_str=True)\n",
    "#         print(tokens, end='\\n', file=fout)\n",
    "\n",
    "# print('Finished detokenizing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836cc4e4-c210-4b47-a70d-40ffd5bc4087",
   "metadata": {},
   "source": [
    "- Subword tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44a05e66-8fce-416a-b8e1-098bc2da3c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 14%|####8                               | 4343/32000 [00:06<00:18, 1496.44it/s]no pair has frequency >= 2. Stopping\n",
      " 14%|#####2                               | 4536/32000 [00:07<00:42, 639.16it/s]\n",
      " 16%|#####7                               | 4994/32000 [00:10<01:19, 338.17it/s]no pair has frequency >= 2. Stopping\n",
      " 16%|#####7                               | 5014/32000 [00:10<00:57, 473.37it/s]\n",
      "Finished subword.\n"
     ]
    }
   ],
   "source": [
    "# Dividing tokenized text into subword units\n",
    "\n",
    "!subword-nmt learn-bpe -s 32000 < data.en-fr.tok.en > sw.model.en\n",
    "!subword-nmt apply-bpe -c sw.model.en < data.en-fr.tok.en > sw.data.en\n",
    "\n",
    "!subword-nmt learn-bpe -s 32000 < data.en-fr.tok.fr > sw.model.fr\n",
    "!subword-nmt apply-bpe -c sw.model.fr < data.en-fr.tok.fr > sw.data.fr\n",
    "\n",
    "print('Finished subword.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e36c9ea3-3a74-4eb2-9e19-960ccec689a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First lines of tokenized English:\n",
      "\n",
      "Now , I thought , &quot; How could I really capture this ?\n",
      "I mean , from this ent@@ ry , it would seem that I was born into a world that percei@@ ved someone like me to have nothing positive whatsoever going for them , when in fact , today I &apos;m celebr@@ ated for the oppor@@ t@@ uni@@ ties and adventures my life has pro@@ cur@@ ed .\n",
      "So , I immediately went to look up the 200@@ 9 online e@@ dition , expec@@ ting to find a re@@ vision wor@@ th n@@ oting .\n",
      "His name was Dr. P@@ i@@ zz@@ u@@ til@@ lo , an Italian American , whose name , apparently , was too difficult for most Americ@@ ans to pr@@ on@@ ounce , so he went by Dr. P@@ . And Dr. P always wor@@ e really colorful bow ties and had the very perfect disp@@ os@@ i@@ tion to work with children .\n",
      "And , one day , he came in to my session - exha@@ us@@ tive and un@@ for@@ giving , these sessions - and he said to me , &quot; W@@ ow .\n",
      "Now , of course , this was a simple p@@ loy on Dr. P &apos;s part to get me to do the exer@@ cis@@ es I didn &apos;t want to do before the prospect of being the richest five-year-old in the second floor ward , but what he effec@@ tively did for me was re@@ shape an aw@@ ful daily occur@@ r@@ ence into a new and promising experience for me .\n",
      "And I have to won@@ der today to what ext@@ ent his vision and his declar@@ ation of me as a strong and powerful little girl shaped my own view of myself as an in@@ her@@ ently strong , powerful and athletic person well into the future .\n",
      "And so my mother &apos;s pr@@ en@@ at@@ al physician had gone on vac@@ ation , so the man who deliver@@ ed me was a complete stranger to my parents .\n",
      "And , because I was born without the fibula bones , and had feet turned in , and a few toes in this foot and a few toes in that , he had to be the bearer - this stranger had to be the bearer of bad news .\n",
      "And , because I was born without the fibula bones , and had feet turned in , and a few toes in this foot and a few toes in that , he had to be the bearer - this stranger had to be the bearer of bad news .\n",
      "\n",
      "First lines of tokenized French:\n",
      "\n",
      "Je me suis demandé comment je pourrais ré@@ su@@ mer vi@@ su@@ ellement cela .\n",
      "Je veux dire , d&apos; après cette entrée , il sembl@@ erait que je sois née dans un monde qui perce@@ vrait les gens comme moi comme n&apos; ayant absolument rien pour eux , alors qu&apos; en fait , aujourd&apos; hui , je suis céléb@@ rée pour les opportuni@@ tés et les aventu@@ res que ma vie m&apos; a ap@@ port@@ ée .\n",
      "Alors je suis tout de suite allée regarder dans l&apos; édi@@ tion 2009 en m&apos; att@@ endant à trouver une ré@@ vision not@@ able .\n",
      "Son nom est Dr P@@ i@@ zz@@ uti@@ ll@@ o . Un I@@ tal@@ o-@@ Américain , dont le nom , apparemment , était trop difficile à pron@@ oncer pour la plupart des Améric@@ ains , alors il est devenu Dr P@@ . Et Dr . P portait toujours des no@@ eu@@ ds papi@@ llon très co@@ lor@@ és et avait le plus parfait tempér@@ am@@ ent pour travailler avec des enfants .\n",
      "Et un jour il est venu à ma sé@@ ance - des séances épuis@@ antes et sans pi@@ tié - et il m&apos; a dit &quot; W@@ ah@@ ou .\n",
      "Bien sûr , c&apos; était juste un str@@ at@@ ag@@ ème de la part de Dr P ♪ pour me faire faire ces exerci@@ ces que je ne voulais pas faire dans la pers@@ pec@@ tive de devenir la fille de 5 ans la plus riche de l&apos; ét@@ age , mais ce qu&apos; il a vraiment fait pour moi , ça a été de transformer un aff@@ r@@ eux événement quotidien en une expérience nouvelle et prometteuse .\n",
      "Et je me demande aujourd&apos; hui , dans quelle mesure sa vision , et le fait qu&apos; il m&apos; ait déclaré une petite fille forte et puissante , ont dess@@ iné ma propre vision de moi-même loin dans le futur , comme une personne par nature forte , puissante et athlétique .\n",
      "Et donc le médecin pré@@ n@@ at@@ al de ma mère était parti en vac@@ ances , et l&apos; homme qui m&apos; a mise au monde était un étranger compl@@ et pour mes parents .\n",
      "Et , comme je suis née sans tibia , et que j&apos; avais les pieds tournés vers l&apos; intérieur , et quelques orteils sur ce pied-ci , et quelques orteils sur ce pied-là , il a dû être le porteur , cet étranger a dû être le porteur de la mauvaise nouvelle .\n",
      "Et , comme je suis née sans tibia , et que j&apos; avais les pieds tournés vers l&apos; intérieur , et quelques orteils sur ce pied-ci , et quelques orteils sur ce pied-là , il a dû être le porteur , cet étranger a dû être le porteur de la mauvaise nouvelle .\n"
     ]
    }
   ],
   "source": [
    "!echo -e \"\\nFirst lines of tokenized English:\\n\"\n",
    "!head sw.data.en-fr.en\n",
    "\n",
    "!echo -e \"\\nFirst lines of tokenized French:\\n\"\n",
    "!head sw.data.en-fr.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0402e210-4d76-4bdf-b3a8-7eed29cda037",
   "metadata": {},
   "source": [
    "- Binarize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "035e9211-725c-486f-ace6-0cc622f9fb73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-23 15:57:58 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=False, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='en', srcdict='wmt14.en-fr.joined-dict.transformer/dict.en.txt', suppress_crashes=False, target_lang='fr', task='translation', tensorboard_logdir=None, testpref='sw.data.en-fr', tgtdict='wmt14.en-fr.joined-dict.transformer/dict.fr.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=8)\n",
      "2023-02-23 15:57:59 | INFO | fairseq_cli.preprocess | [en] Dictionary: 44512 types\n",
      "2023-02-23 15:57:59 | INFO | fairseq_cli.preprocess | [en] sw.data.en-fr.en: 1108 sents, 38882 tokens, 4.37% replaced (by <unk>)\n",
      "2023-02-23 15:57:59 | INFO | fairseq_cli.preprocess | [fr] Dictionary: 44512 types\n",
      "2023-02-23 15:58:00 | INFO | fairseq_cli.preprocess | [fr] sw.data.en-fr.fr: 1108 sents, 40580 tokens, 5.63% replaced (by <unk>)\n",
      "2023-02-23 15:58:00 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin\n"
     ]
    }
   ],
   "source": [
    "# Binarize the data for training; test with moses tokenizer and subword_nmt failed -> BLEU score of 4\n",
    "\n",
    "# reuse model dict; solution for dictionary size to match test dataset\n",
    "# map words appearing less than threshold times to unknown \n",
    "# --tokenizer moses \\\n",
    "# --bpe subword_nmt \\\n",
    "!fairseq-preprocess \\\n",
    "    --source-lang en \\\n",
    "    --target-lang fr \\\n",
    "    --testpref sw.data.en-fr \\\n",
    "    --srcdict wmt14.en-fr.joined-dict.transformer/dict.en.txt \\\n",
    "    --tgtdict wmt14.en-fr.joined-dict.transformer/dict.fr.txt \\\n",
    "    --destdir data-bin \\\n",
    "    --thresholdtgt 0 \\\n",
    "    --thresholdsrc 0 \\\n",
    "    --workers 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fb8bee-451c-4f6c-bad6-6a5af54505fe",
   "metadata": {},
   "source": [
    "# Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc698b33-d31f-4046-98ce-76c1cc617ee9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/data4/vzhekova/biases-data/En-Fr\n"
     ]
    }
   ],
   "source": [
    "%cd $PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dd7515-96e1-42e1-8358-7e6ffef919f6",
   "metadata": {},
   "source": [
    "- Beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0264b10-bdb8-439e-bd09-856241d499b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-23 15:58:28 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'wmt14.en-fr.joined-dict.transformer/model.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 256, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 256, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}, 'task': {'_name': 'translation', 'data': 'data-bin', 'source_lang': 'en', 'target_lang': 'fr', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-02-23 15:58:29 | INFO | fairseq.tasks.translation | [en] dictionary: 44512 types\n",
      "2023-02-23 15:58:29 | INFO | fairseq.tasks.translation | [fr] dictionary: 44512 types\n",
      "2023-02-23 15:58:29 | INFO | fairseq_cli.generate | loading model(s) from wmt14.en-fr.joined-dict.transformer/model.pt\n",
      "2023-02-23 15:58:54 | INFO | fairseq.data.data_utils | loaded 1,108 examples from: data-bin/test.en-fr.en\n",
      "2023-02-23 15:58:54 | INFO | fairseq.data.data_utils | loaded 1,108 examples from: data-bin/test.en-fr.fr\n",
      "2023-02-23 15:58:54 | INFO | fairseq.tasks.translation | data-bin test en-fr 1108 examples\n",
      "2023-02-23 15:59:47 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2023-02-23 15:59:47 | INFO | fairseq_cli.generate | Translated 1,108 sentences (42,305 tokens) in 30.9s (35.84 sentences/s, 1368.52 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "# Generate translations\n",
    "!fairseq-generate data-bin  \\\n",
    "    --task translation \\\n",
    "    --source-lang en \\\n",
    "    --target-lang fr \\\n",
    "    --path wmt14.en-fr.joined-dict.transformer/model.pt \\\n",
    "    --beam 5 \\\n",
    "    --batch-size 256 \\\n",
    "    --memory-efficient-fp16 \\\n",
    "    --remove-bpe=subword_nmt > en-fr.decode.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3aef7f3-4838-419e-9e80-62c0114c9a86",
   "metadata": {},
   "source": [
    "- Top-K-Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d0871d36-181f-4ec0-87cb-89843b11fa71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-23 16:21:37 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'wmt14.en-fr.joined-dict.transformer/model.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 256, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 256, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 5, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': True, 'sampling_topk': 5, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}, 'task': {'_name': 'translation', 'data': 'data-bin', 'source_lang': 'en', 'target_lang': 'fr', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-02-23 16:21:38 | INFO | fairseq.tasks.translation | [en] dictionary: 44512 types\n",
      "2023-02-23 16:21:38 | INFO | fairseq.tasks.translation | [fr] dictionary: 44512 types\n",
      "2023-02-23 16:21:38 | INFO | fairseq_cli.generate | loading model(s) from wmt14.en-fr.joined-dict.transformer/model.pt\n",
      "2023-02-23 16:22:00 | INFO | fairseq.data.data_utils | loaded 1,108 examples from: data-bin/test.en-fr.en\n",
      "2023-02-23 16:22:00 | INFO | fairseq.data.data_utils | loaded 1,108 examples from: data-bin/test.en-fr.fr\n",
      "2023-02-23 16:22:00 | INFO | fairseq.tasks.translation | data-bin test en-fr 1108 examples\n",
      "2023-02-23 16:23:29 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2023-02-23 16:23:29 | INFO | fairseq_cli.generate | Translated 1,108 sentences (41,598 tokens) in 35.1s (31.54 sentences/s, 1183.97 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "# Generate translations\n",
    "!fairseq-generate data-bin  \\\n",
    "    --task translation \\\n",
    "    --source-lang en \\\n",
    "    --target-lang fr \\\n",
    "    --path wmt14.en-fr.joined-dict.transformer/model.pt \\\n",
    "    --sampling \\\n",
    "    --sampling-topk 5 \\\n",
    "    --nbest 5 \\\n",
    "    --batch-size 256 \\\n",
    "    --memory-efficient-fp16 \\\n",
    "    --remove-bpe=subword_nmt > en-fr.decode.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3813030-4723-4e73-855c-802807ad6c55",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f16baf3-949a-4346-8d5c-3c78c0a9de7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J&apos; ai voulu faire de ces &quot; ministers &quot; un allié de la communauté de la LGBTQ .\n",
      "J&apos; ai voulu faire de ces &quot; ministers &quot; des alliés de la communauté du LGBTQ .\n",
      "Je voulais ouvrir ces postes pour être un allié de la collectivité des LGBTQ .\n",
      "Je tenais à faire de ces &quot; Adieux &quot; des alliés du LGBTQ .\n",
      "Je voulais ouvrir ces &quot; BACQ &quot; comme allié de la communauté .\n",
      "Au début de mon séjour , en 2000 , j&apos; étais très intéressé par les collectivités .\n",
      "Au début de mon séjour , en 2000 , j&apos; ai manifesté un grand intérêt pour les collectivités .\n",
      "Au début de mon séjour là @-@ bas en 2001 , j&apos; étais très intéressé aux collectivités .\n",
      "Au début de mon séjour là @-@ bas , en 2000 , la vie communautaire m&apos; a beaucoup intéressé .\n",
      "Au début du séjour que j&apos; ai effectué dans cette ville en 2000 , j&apos; étais très intéressée aux communautés .\n",
      "..........\n",
      "Je <<unk>> ouvrir ces portes en tant qu&apos; alliée de la communauté LGBTQ .\n",
      "À mes débuts en 2000 , j&apos; étais très intéressé par les communautés .\n",
      "Après lui , j&apos; étais un peu <<unk>> pour mon prochain <<unk>> zéro .\n",
      "Je suis allée chez <<unk>> pour célébrer cela , pour la fé<<unk>> ter .\n",
      "Je <<unk>> ça super et donc j&apos; étais <<unk>> de le montrer à mon ami .\n",
      "Je suis Dan , un associé dans un cabinet international de conseil en créativité .\n",
      "Je suis <<unk>> dans mon <<unk>> à Boston et fait une petite expérience .\n",
      "Et le juge l&apos; a certifié adulte , mais je vois ce <<unk>> .\n",
      "Voici ici , une jeune <<unk>> et un male qui s&apos; adonnent à une course poursuite .\n",
      "J&apos; ai eu le grand privilège , quand j&apos; étais un jeune avocat , de rencontrer <<unk>> Parks .\n"
     ]
    }
   ],
   "source": [
    "# Extract the hypotheses and references from the decoding log file\n",
    "!grep ^H en-fr.decode.log | sed 's/^H-//g' | cut -f 3 | sed 's/ @@//g' > ./hyp.en-fr.txt\n",
    "!grep ^T en-fr.decode.log | sed 's/^T-//g' | cut -f 2 | sed 's/ @@//g' > ./ref.en-fr.txt\n",
    "\n",
    "!head ./hyp.en-fr.txt\n",
    "print(\"..........\")\n",
    "!head ./ref.en-fr.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "05368c0d-3e10-4ff8-9d9e-9c5d32856a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract only the first hypothesis\n",
    "!awk 'NR % 5 == 1' ./hyp.en-fr.txt > ./hyp.en-fr.best.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "def5dcc4-b30b-43a6-b19e-92f135357a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished detokenizing.\n"
     ]
    }
   ],
   "source": [
    "# Detokenize text        \n",
    "\n",
    "with open('./hyp.en-fr.best.txt', encoding='utf8') as fin, open('hyp_detok.en-fr.txt','w', encoding='utf8') as fout:\n",
    "    for line in fin:\n",
    "        tokens = md_en.detokenize(line.split(), return_str=True)\n",
    "        print(tokens, end='\\n', file=fout)\n",
    "        \n",
    "with open('ref.en-fr.txt', encoding='utf8') as fin, open('ref_detok.en-fr.txt','w', encoding='utf8') as fout:\n",
    "    for line in fin:\n",
    "        tokens = md_fr.detokenize(line.split(), return_str=True)\n",
    "        print(tokens, end='\\n', file=fout)\n",
    "\n",
    "print('Finished detokenizing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aff664f1-625b-48a2-8b7d-26f8329e367a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J' ai voulu faire de ces \"ministers\" un allié de la communauté de la LGBTQ.\n",
      "Au début de mon séjour, en 2000, j' étais très intéressé par les collectivités.\n",
      "Après ça, j' étais un peu impatiente de me rendre à la prochaine rendez-vous zéros.\n",
      "Je suis allé à la maison de Σ pour célébrer - pour la congratuer.\n",
      "Et je trouvais que c \"était super cool, alors je l' ai montré à mon ami.\n",
      "Je m' appelle Dan, je suis partenaire d' une conquête globale de création.\n",
      "Je suis retourné à mon laboratoire à Boston et y ai réalisé une petite expérience.\n",
      "Et le juge l' a reconnu comme un adulte, mais je vois ça.\n",
      "Nous avons donc là une jeune femme et un jeune homme qui s' adonnent à un jeu d' aumônerie.\n",
      "J' ai eu le grand privilège, quand j' étais un jeune avocat, de rencontrer \"Waters Parks\".\n",
      "..........\n",
      "Je <<unk>> ouvrir ces portes en tant qu'alliée de la communauté LGBTQ.\n",
      "À mes débuts en 2000, j'étais très intéressé par les communautés.\n",
      "Après lui, j'étais un peu <<unk>> pour mon prochain <<unk>> zéro.\n",
      "Je suis allée chez <<unk>> pour célébrer cela, pour la fé<<unk>> ter.\n",
      "Je <<unk>> ça super et donc j'étais <<unk>> de le montrer à mon ami.\n",
      "Je suis Dan, un associé dans un cabinet international de conseil en créativité.\n",
      "Je suis <<unk>> dans mon <<unk>> à Boston et fait une petite expérience.\n",
      "Et le juge l'a certifié adulte, mais je vois ce <<unk>>.\n",
      "Voici ici, une jeune <<unk>> et un male qui s'adonnent à une course poursuite.\n",
      "J'ai eu le grand privilège, quand j'étais un jeune avocat, de rencontrer <<unk>> Parks.\n"
     ]
    }
   ],
   "source": [
    "!head ./hyp_detok.en-fr.txt\n",
    "print(\"..........\")\n",
    "!head ./ref_detok.en-fr.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb82c04e-3fe6-45f0-abc8-fd1d94b13105",
   "metadata": {},
   "source": [
    "- BLEU score (sacreBleu works on detokenized input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04b7966d-1948-4c16-bc1d-924c1f34181d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"name\": \"BLEU\",\n",
      " \"score\": 15.9,\n",
      " \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.3.1\",\n",
      " \"verbose_score\": \"48.1/24.4/14.1/8.3 (BP = 0.829 ratio = 0.842 hyp_len = 35701 ref_len = 42400)\",\n",
      " \"nrefs\": \"1\",\n",
      " \"case\": \"mixed\",\n",
      " \"eff\": \"no\",\n",
      " \"tok\": \"13a\",\n",
      " \"smooth\": \"exp\",\n",
      " \"version\": \"2.3.1\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "# BLEU score of 18.7 (beam=5), BLEU score of 18.2 (beam=1)\n",
    "# BLEU score of 15.9 (sampling-topk=5)\n",
    "!cat ./hyp_detok.en-fr.txt | sacrebleu ./ref_detok.en-fr.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88a021a9-42b5-4938-bea3-6c8250e46261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(ignore_case=False, order=4, ref='./ref_detok.en-fr.txt', sacrebleu=True, sentence_bleu=False, sys='./hyp_detok.en-fr.txt')\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/vzhekova/miniconda3/envs/nmt/bin/fairseq-score\", line 8, in <module>\n",
      "    sys.exit(cli_main())\n",
      "  File \"/home/vzhekova/fairseq/fairseq_cli/score.py\", line 98, in cli_main\n",
      "    score(f)\n",
      "  File \"/home/vzhekova/fairseq/fairseq_cli/score.py\", line 61, in score\n",
      "    print(sacrebleu.corpus_bleu(fdsys, [fdref]).format())\n",
      "  File \"/home/vzhekova/miniconda3/envs/nmt/lib/python3.8/site-packages/sacrebleu/compat.py\", line 37, in corpus_bleu\n",
      "    return metric.corpus_score(hypotheses, references)\n",
      "  File \"/home/vzhekova/miniconda3/envs/nmt/lib/python3.8/site-packages/sacrebleu/metrics/base.py\", line 414, in corpus_score\n",
      "    self._check_corpus_score_args(hypotheses, references)\n",
      "  File \"/home/vzhekova/miniconda3/envs/nmt/lib/python3.8/site-packages/sacrebleu/metrics/base.py\", line 258, in _check_corpus_score_args\n",
      "    raise TypeError(f'{prefix}: {err_msg}')\n",
      "TypeError: BLEU: Each element of `refs` should be a sequence of strings.\n"
     ]
    }
   ],
   "source": [
    "!fairseq-score \\\n",
    "    --sacrebleu \\\n",
    "    --sys ./hyp_detok.en-fr.txt \\\n",
    "    --ref ./ref_detok.en-fr.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eba02d1-76dd-4eb7-9251-c02cbe4a8a6a",
   "metadata": {},
   "source": [
    "- Gender accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c7c3861-f7a2-4d13-bbd0-7fe6e0c5237f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\tTerm Coverage\tGender Accuracy\n",
      "-------------------------------------------------\n",
      "1F\t0.03773584905660377\t0.16666666666666666\n",
      "1M\t0.07804878048780488\t0.5777777777777777\n",
      "2F\t0.12447257383966245\t0.3787878787878788\n",
      "2M\t0.11650485436893204\t0.5555555555555556\n",
      "3F\t0.0\t0.0\n",
      "3M\t0.0\t0.0\n",
      "4F\t0.07407407407407407\t0.0\n",
      "4M\t0.16666666666666666\t0.5\n",
      "-------------------------------------------------\n",
      "Global\t0.09286463798530954\t0.4647887323943662\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Evaluate gender accuracy; 0.46\n",
    "!python /export/data4/vzhekova/MuST-SHE_v1.2/MuST-SHE-v1.1-eval-script/mustshe_acc_v1.1.py \\\n",
    "    --input hyp.en-fr.txt \\\n",
    "    --tsv-definition /export/data4/vzhekova/MuST-SHE_v1.2/MuST-SHE-v1.2-data/tsv/MONOLINGUAL.fr_v1.2.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfad36b-0045-402e-9ca0-99b6ef4f5736",
   "metadata": {},
   "source": [
    "# Translation with fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e6120c9-455b-49db-a93e-434613fec708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/data4/vzhekova/biases-data/En-Fr\n"
     ]
    }
   ],
   "source": [
    "%cd $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "302ac27c-11de-4606-96c7-82b36050b7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-10 14:57:29 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/export/data4/vzhekova/biases-data/En-Fr_MuST-C/checkpoints/checkpoint_best.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 256, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 256, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}, 'task': {'_name': 'translation', 'data': 'data-bin', 'source_lang': 'en', 'target_lang': 'fr', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-03-10 14:57:30 | INFO | fairseq.tasks.translation | [en] dictionary: 44512 types\n",
      "2023-03-10 14:57:30 | INFO | fairseq.tasks.translation | [fr] dictionary: 44512 types\n",
      "2023-03-10 14:57:30 | INFO | fairseq_cli.generate | loading model(s) from /export/data4/vzhekova/biases-data/En-Fr_MuST-C/checkpoints/checkpoint_best.pt\n",
      "2023-03-10 14:57:48 | INFO | fairseq.data.data_utils | loaded 1,108 examples from: data-bin/test.en-fr.en\n",
      "2023-03-10 14:57:48 | INFO | fairseq.data.data_utils | loaded 1,108 examples from: data-bin/test.en-fr.fr\n",
      "2023-03-10 14:57:48 | INFO | fairseq.tasks.translation | data-bin test en-fr 1108 examples\n",
      "2023-03-10 14:58:38 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2023-03-10 14:58:38 | INFO | fairseq_cli.generate | Translated 1,108 sentences (39,289 tokens) in 27.8s (39.84 sentences/s, 1412.77 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "# Generate translations\n",
    "!fairseq-generate data-bin  \\\n",
    "    --task translation \\\n",
    "    --source-lang en \\\n",
    "    --target-lang fr \\\n",
    "    --path /export/data4/vzhekova/biases-data/En-Fr_MuST-C/checkpoints/checkpoint_best.pt \\\n",
    "    --beam 5 \\\n",
    "    --batch-size 256 \\\n",
    "    --memory-efficient-fp16 \\\n",
    "    --remove-bpe=subword_nmt > en-fr.decode_finetuned.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09e16d10-91cf-4901-976e-d0c5686fe698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Je <unk> ouvrir ces <unk> en tant qu <unk> de la communauté LGBQT .\n",
      "Au début de mon séjour ici en 2000 , j <unk> été très intéressé par les communautés .\n",
      "Ensuite , j <unk> un peu <unk> d <unk> à mon prochain <unk> o .\n",
      "Je suis <unk> à la maison de <unk> pour la célébrer - la congrater .\n",
      "Et je <unk> que c <unk> super cool , alors je le <unk> à mon ami .\n",
      "Je m <unk> Dan , je suis partenaire d &apos;une association mondiale de création .\n",
      "Je suis <unk> dans mon laboratoire à Boston et j <unk> fait une petite expérience .\n",
      "Et le juge l &apos;a certifié comme adulte , mais je vois cette <unk> .\n",
      "Ici , nous avons une jeune <unk> et un <unk> engagés dans un jeu de <unk> .\n",
      "J <unk> eu le grand privilège , quand j <unk> jeune avocat , de rencontrer <unk> Parks .\n",
      "..........\n",
      "Je <<unk>> ouvrir ces portes en tant qu&apos; alliée de la communauté LGBTQ .\n",
      "À mes débuts en 2000 , j&apos; étais très intéressé par les communautés .\n",
      "Après lui , j&apos; étais un peu <<unk>> pour mon prochain <<unk>> zéro .\n",
      "Je suis allée chez <<unk>> pour célébrer cela , pour la fé<<unk>> ter .\n",
      "Je <<unk>> ça super et donc j&apos; étais <<unk>> de le montrer à mon ami .\n",
      "Je suis Dan , un associé dans un cabinet international de conseil en créativité .\n",
      "Je suis <<unk>> dans mon <<unk>> à Boston et fait une petite expérience .\n",
      "Et le juge l&apos; a certifié adulte , mais je vois ce <<unk>> .\n",
      "Voici ici , une jeune <<unk>> et un male qui s&apos; adonnent à une course poursuite .\n",
      "J&apos; ai eu le grand privilège , quand j&apos; étais un jeune avocat , de rencontrer <<unk>> Parks .\n"
     ]
    }
   ],
   "source": [
    "# Extract the hypotheses and references from the decoding log file\n",
    "!grep ^H en-fr.decode_finetuned.log | sed 's/^H-//g' | cut -f 3 | sed 's/ @@//g' > ./hyp_finetuned.txt\n",
    "!grep ^T en-fr.decode_finetuned.log | sed 's/^T-//g' | cut -f 2 | sed 's/ @@//g' > ./ref_finetuned.txt\n",
    "\n",
    "!head ./hyp_finetuned.txt\n",
    "print(\"..........\")\n",
    "!head ./ref_finetuned.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85266c00-f128-4d94-8c3a-21835a634d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished detokenizing.\n"
     ]
    }
   ],
   "source": [
    "# Detokenize text        \n",
    "\n",
    "md_en = MosesDetokenizer(lang='en')\n",
    "md_fr = MosesDetokenizer(lang='fr')\n",
    "\n",
    "with open('hyp_finetuned.txt', encoding='utf8') as fin, open('hyp_finetuned_detok.txt','w', encoding='utf8') as fout:\n",
    "    for line in fin:\n",
    "        tokens = md_en.detokenize(line.split(), return_str=True)\n",
    "        print(tokens, end='\\n', file=fout)\n",
    "        \n",
    "with open('ref_finetuned.txt', encoding='utf8') as fin, open('ref_finetuned_detok.txt','w', encoding='utf8') as fout:\n",
    "    for line in fin:\n",
    "        tokens = md_fr.detokenize(line.split(), return_str=True)\n",
    "        print(tokens, end='\\n', file=fout)\n",
    "\n",
    "print('Finished detokenizing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c0a27a7-9bff-44cb-b214-a881508123d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"name\": \"BLEU\",\n",
      " \"score\": 27.0,\n",
      " \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.3.1\",\n",
      " \"verbose_score\": \"61.4/37.1/21.9/10.7 (BP = 1.000 ratio = 1.066 hyp_len = 45219 ref_len = 42400)\",\n",
      " \"nrefs\": \"1\",\n",
      " \"case\": \"mixed\",\n",
      " \"eff\": \"no\",\n",
      " \"tok\": \"13a\",\n",
      " \"smooth\": \"exp\",\n",
      " \"version\": \"2.3.1\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "# BLEU score of 27.0 (beam=5)\n",
    "!cat ./hyp_finetuned_detok.txt | sacrebleu ./ref_finetuned_detok.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb3ec7c8-cd82-4f11-a67f-c17006617892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\tTerm Coverage\tGender Accuracy\n",
      "-------------------------------------------------\n",
      "1F\t0.030660377358490566\t0.375\n",
      "1M\t0.06829268292682927\t0.6571428571428571\n",
      "2F\t0.10548523206751055\t0.39285714285714285\n",
      "2M\t0.11262135922330097\t0.5285714285714286\n",
      "3F\t0.0\t0.0\n",
      "3M\t0.0\t0.0\n",
      "4F\t0.07407407407407407\t0.0\n",
      "4M\t0.16666666666666666\t0.5555555555555556\n",
      "-------------------------------------------------\n",
      "Global\t0.08342077649527807\t0.4946808510638298\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Evaluate gender accuracy; 0.49\n",
    "!python /export/data4/vzhekova/MuST-SHE_v1.2/MuST-SHE-v1.1-eval-script/mustshe_acc_v1.1.py \\\n",
    "    --input hyp_finetuned_detok.txt \\\n",
    "    --tsv-definition /export/data4/vzhekova/MuST-SHE_v1.2/MuST-SHE-v1.2-data/tsv/MONOLINGUAL.fr_v1.2.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2e0880-8d09-4a50-8f0c-452ce79c7198",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
