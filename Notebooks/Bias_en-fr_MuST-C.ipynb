{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e322256a-12ac-482e-b44a-ae8eb5bf4c88",
   "metadata": {
    "tags": []
   },
   "source": [
    "# En-Fr Translation\n",
    "Generate translations on MuST-C dataset with WMT14 En-Fr Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a7e843c-f187-4799-9a34-5c8309fb8e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if we can connect to the GPU with PyTorch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.current_device()\n",
    "    print('Current device:', torch.cuda.get_device_name(device))\n",
    "else:\n",
    "    print('Failed to find GPU. Will use CPU.')\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb50f64a-34c1-4bb4-9fd8-2f9c1675a740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/data4/vzhekova/biases-data/En-Fr_MuST-C\n"
     ]
    }
   ],
   "source": [
    "PATH=\"/export/data4/vzhekova/biases-data/En-Fr_MuST-C\"\n",
    "\n",
    "%cd $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70d73cda-759a-45a5-ac92-d3a6a651f6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First lines of English:\n",
      "\n",
      "Back in New York, I am the head of development for a non-profit called Robin Hood.\n",
      "When I'm not fighting poverty, I'm fighting fires as the assistant captain of a volunteer fire company.\n",
      "Now in our town, where the volunteers supplement a highly skilled career staff, you have to get to the fire scene pretty early to get in on any action.\n",
      "I remember my first fire.\n",
      "I was the second volunteer on the scene, so there was a pretty good chance I was going to get in.\n",
      "But still it was a real footrace against the other volunteers to get to the captain in charge to find out what our assignments would be.\n",
      "When I found the captain, he was having a very engaging conversation with the homeowner, who was surely having one of the worst days of her life.\n",
      "Here it was, the middle of the night, she was standing outside in the pouring rain, under an umbrella, in her pajamas, barefoot, while her house was in flames.\n",
      "The other volunteer who had arrived just before me — let's call him Lex Luther — (Laughter) got to the captain first and was asked to go inside and save the homeowner's dog. The dog! I was stunned with jealousy.\n",
      "Here was some lawyer or money manager who, for the rest of his life, gets to tell people that he went into a burning building to save a living creature, just because he beat me by five seconds.\n",
      "\n",
      "First lines of French:\n",
      "\n",
      "A New York, je suis responsable du développment pour un organisme à but non lucratif appelé Robin Hood.\n",
      "Quand je ne suis pas en train de combattre la pauvreté, je combat des incendies en tant qu'assistant capitaine d'une compagnie de pompiers volontaires.\n",
      "Et dans notre ville, où les volontaires viennent renforcer une équipe professionnelle hautement qualifiée, il faut arriver sur le lieu de l'incendie très tôt pour prendre part à l'action.\n",
      "Je me souviens de mon premier incendie.\n",
      "J'étais le deuxième volontaire sur les lieux, et donc j'avais de bonnes chances d'y aller.\n",
      "Mais pourtant c'était une vrai course à pied contre les autres volontaires pour arriver jusqu'au capitaine responsable pour découvrir ce que seraient nos missions.\n",
      "Quand j'ai trouvé le capitaine, il était en pleine conversation avec la propriétaire, qui était surement en train de vivre la pire journée de sa vie.\n",
      "C'était en pleine nuit, elle était là dehors sous la pluie battante, sous un parapluie, en pyjama, pieds nus, pendant que sa maison était en flammes.\n",
      "L'autre volontaire qui était arrivé juste avant moi — appelons-le Lex Luther — (Rires) est arrivé le premier auprès du capitaine et on lui a demandé d'aller à l'intérieur et de sauver le chien de la propriétaire. Le chien ! J'étais abasourdi de jalousie.\n",
      "C'était un avocat ou un brasseur d'argent qui, pour le reste de sa vie, pourrait dire aux gens qu'il était entré dans un bâtiment en feu pour sauver une créature vivante, juste parce qu'il m'avait battu de 5 secondes.\n"
     ]
    }
   ],
   "source": [
    "!echo -e \"\\nFirst lines of English:\\n\"\n",
    "!head tst.en-fr.en\n",
    "!echo -e \"\\nFirst lines of French:\\n\"\n",
    "!head tst.en-fr.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f796928-2616-4b1a-87c2-791af617f1b0",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a19bbf8-4629-4aba-a51a-7f6ea31aa102",
   "metadata": {},
   "source": [
    "- Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "493058f2-f1c6-4070-b224-6f7507402c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished tokenizing.\n"
     ]
    }
   ],
   "source": [
    "# Tokenize text\n",
    "\n",
    "from sacremoses import MosesPunctNormalizer\n",
    "from sacremoses import MosesTokenizer, MosesDetokenizer\n",
    "from __future__ import print_function\n",
    "\n",
    "mpn = MosesPunctNormalizer()\n",
    "\n",
    "# Preprocess the sentences from train/dev/test sets\n",
    "for partition in [\"train\", \"dev\", \"tst\"]:\n",
    "    for lang in [\"fr\", \"en\"]:\n",
    "        mt = MosesTokenizer(lang=lang)\n",
    "        with open(f\"{partition}.en-fr.{lang}\") as fin, open(f\"tok.{partition}.en-fr.{lang}\",'w') as fout:\n",
    "            for line in fin:\n",
    "                tokens = mt.tokenize(mpn.normalize(line), return_str=True)\n",
    "                print(tokens, end='\\n', file=fout) \n",
    "\n",
    "        \n",
    "\n",
    "print('Finished tokenizing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7f557d-45e9-49b3-8f5a-d1544ac36e9b",
   "metadata": {},
   "source": [
    "- Subword tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66c357bc-7d53-4bd1-bc86-c052a679e601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|#####################################| 32000/32000 [08:16<00:00, 64.48it/s]\n",
      "100%|#####################################| 32000/32000 [08:01<00:00, 66.39it/s]\n",
      "/bin/bash: fin: No such file or directory\n",
      "/bin/bash: fin: No such file or directory\n",
      "/bin/bash: fin: No such file or directory\n",
      "/bin/bash: fin: No such file or directory\n",
      "/bin/bash: fin: No such file or directory\n",
      "/bin/bash: fin: No such file or directory\n",
      "Finished subword.\n"
     ]
    }
   ],
   "source": [
    "# Training subword model\n",
    "\n",
    "#!subword-nmt learn-bpe -s 32000 < tok.train.en-fr.en > sw.model.en\n",
    "#!subword-nmt learn-bpe -s 32000 < tok.train.en-fr.fr > sw.model.fr\n",
    "\n",
    "#print('Finished subword training.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32ff6693-5bcc-4c55-8292-56b2dae06eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apllied subword model.\n"
     ]
    }
   ],
   "source": [
    "# Applying subword model\n",
    "\n",
    "for partition in [\"train\", \"dev\", \"tst\"]:\n",
    "    for lang in [\"fr\", \"en\"]:\n",
    "        sw = f\"sw.model.{lang}\"\n",
    "        fin = f\"tok.{partition}.en-fr.{lang}\"\n",
    "        fout = f\"sw.{partition}.en-fr.{lang}\"\n",
    "        #!subword-nmt apply-bpe -c $sw < $fin > $fout\n",
    "        !subword-nmt apply-bpe -c bpecodes < $fin > $fout\n",
    "        \n",
    "print('Aplied subword model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94d57d8a-48b3-4773-8755-0027fee444ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First lines of tokenized English:\n",
      "\n",
      "Thank you so much , Chris . And it &apos;s truly a great hon@@ or to have the opportunity to come to this stage twice ; I &apos;m extremely grateful .\n",
      "I have been b@@ low@@ n away by this conference , and I want to thank all of you for the many nice comments about what I had to say the other night .\n",
      "And I say that sincerely , partly because ( M@@ ock so@@ b ) I need that . ( L@@ aughter )\n",
      "( L@@ aughter ) I fle@@ w on Air Force Two for eight years .\n",
      "( L@@ aughter ) Now I have to take off my shoes or boo@@ ts to get on an air@@ plane ! ( L@@ aughter ) ( Appl@@ ause )\n",
      "I &apos;ll tell you one quick story to illustrate what that &apos;s been like for me . ( L@@ aughter )\n",
      "It &apos;s a true story - every bit of this is true .\n",
      "So@@ on after T@@ ip@@ per and I left the - ( M@@ ock so@@ b ) White House - ( L@@ aughter ) we were driving from our home in N@@ ash@@ ville to a little farm we have 50 miles east of N@@ ash@@ ville . Dri@@ ving ourselves . ( L@@ aughter )\n",
      "( L@@ aughter ) I looked in the re@@ ar@@ -@@ view mirror and all of a sudden it just hit me .\n",
      "There was no motor@@ cade back there .\n",
      "\n",
      "First lines of tokenized French:\n",
      "\n",
      "Merci beaucoup , Chris . C&apos; est vraiment un honneur de pouvoir venir sur cette scène une deuxième fois .\n",
      "J&apos; ai été très impressionn@@ é par cette conférence , et je tiens à vous remercier tous pour vos nombreux et sympath@@ iques commentaires sur ce que j&apos; ai dit l&apos; autre soir .\n",
      "Et je dis çà sincèrement , en autres parce que - F@@ aux s@@ ang@@ lot - j&apos; en ai besoin ! - R@@ ires - Met@@ te@@ z@@ -@@ vous à ma place !\n",
      "J&apos; ai vol@@ é avec Air Force 2 pendant huit ans .\n",
      "Et maintenant , je dois enlever mes chaussures pour monter à bord d&apos; un avion ! - R@@ ires Applaudissements -\n",
      "Je vais vous racon@@ ter une petite histoire pour vous montrer ce que çà a été pour moi .\n",
      "C&apos; est une histoire vraie , dans tous ses détails .\n",
      "Après que T@@ ip@@ per et moi avons quitté la - F@@ aux s@@ ang@@ lot - Maison Bl@@ anche - R@@ ires - nous étions en route pour une petite ferme que nous avons à 80 km à l&apos; est de N@@ ash@@ ville - conduisant nou@@ s@@ -@@ mêmes .\n",
      "Je sais que ça doit vous paraître sans importance mais - R@@ ires - en jet@@ ant un oeil sur le rétro@@ vis@@ eur , j&apos; ai réalisé tout à coup .\n",
      "Il n&apos; y avait pas d&apos; escor@@ te derrière .\n"
     ]
    }
   ],
   "source": [
    "!echo -e \"\\nFirst lines of tokenized English:\\n\"\n",
    "!head sw.train.en-fr.en\n",
    "\n",
    "!echo -e \"\\nFirst lines of tokenized French:\\n\"\n",
    "!head sw.train.en-fr.fr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029a0cb1-a80c-4c8e-92eb-b20136ceea4f",
   "metadata": {},
   "source": [
    "- Binarize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06e184c4-cbae-4c7a-ac52-fd8b6537398c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-21 16:43:41 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=False, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='en', srcdict='/export/data4/vzhekova/biases-data/En-Fr/wmt14.en-fr.joined-dict.transformer/dict.en.txt', suppress_crashes=False, target_lang='fr', task='translation', tensorboard_logdir=None, testpref='sw.tst.en-fr', tgtdict='/export/data4/vzhekova/biases-data/En-Fr/wmt14.en-fr.joined-dict.transformer/dict.fr.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='sw.train.en-fr', use_plasma_view=False, user_dir=None, validpref='sw.dev.en-fr', wandb_project=None, workers=8)\n",
      "2023-03-21 16:43:42 | INFO | fairseq_cli.preprocess | [en] Dictionary: 44512 types\n",
      "2023-03-21 16:44:13 | INFO | fairseq_cli.preprocess | [en] sw.train.en-fr.en: 275085 sents, 6862252 tokens, 0.000146% replaced (by <unk>)\n",
      "2023-03-21 16:44:13 | INFO | fairseq_cli.preprocess | [en] Dictionary: 44512 types\n",
      "2023-03-21 16:44:13 | INFO | fairseq_cli.preprocess | [en] sw.dev.en-fr.en: 1412 sents, 36552 tokens, 0.0% replaced (by <unk>)\n",
      "2023-03-21 16:44:13 | INFO | fairseq_cli.preprocess | [en] Dictionary: 44512 types\n",
      "2023-03-21 16:44:14 | INFO | fairseq_cli.preprocess | [en] sw.tst.en-fr.en: 2632 sents, 61927 tokens, 0.0% replaced (by <unk>)\n",
      "2023-03-21 16:44:14 | INFO | fairseq_cli.preprocess | [fr] Dictionary: 44512 types\n",
      "2023-03-21 16:44:50 | INFO | fairseq_cli.preprocess | [fr] sw.train.en-fr.fr: 275085 sents, 7352570 tokens, 0.000286% replaced (by <unk>)\n",
      "2023-03-21 16:44:50 | INFO | fairseq_cli.preprocess | [fr] Dictionary: 44512 types\n",
      "2023-03-21 16:44:51 | INFO | fairseq_cli.preprocess | [fr] sw.dev.en-fr.fr: 1412 sents, 39010 tokens, 0.0% replaced (by <unk>)\n",
      "2023-03-21 16:44:51 | INFO | fairseq_cli.preprocess | [fr] Dictionary: 44512 types\n",
      "2023-03-21 16:44:52 | INFO | fairseq_cli.preprocess | [fr] sw.tst.en-fr.fr: 2632 sents, 68014 tokens, 0.0% replaced (by <unk>)\n",
      "2023-03-21 16:44:52 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin\n"
     ]
    }
   ],
   "source": [
    "# Binarize the data for training\n",
    " \n",
    "# reuse model dict\n",
    "!fairseq-preprocess \\\n",
    "    --source-lang en \\\n",
    "    --target-lang fr \\\n",
    "    --trainpref sw.train.en-fr \\\n",
    "    --validpref sw.dev.en-fr \\\n",
    "    --testpref sw.tst.en-fr \\\n",
    "    --srcdict /export/data4/vzhekova/biases-data/En-Fr/wmt14.en-fr.joined-dict.transformer/dict.en.txt \\\n",
    "    --tgtdict /export/data4/vzhekova/biases-data/En-Fr/wmt14.en-fr.joined-dict.transformer/dict.fr.txt \\\n",
    "    --destdir data-bin \\\n",
    "    --workers 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4358bc05-4e64-4e72-adb6-4a7992c40534",
   "metadata": {},
   "source": [
    "# Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33db12c3-c5f0-4558-979d-b9609c7db520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/data4/vzhekova/biases-data/En-Fr_MuST-C\n"
     ]
    }
   ],
   "source": [
    "%cd $PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f1f87b-662c-492c-b931-582300a4b53d",
   "metadata": {},
   "source": [
    "- Beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a85474f-5b19-4375-8a2a-89538a0b878d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-21 16:46:33 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/export/data4/vzhekova/biases-data/En-Fr/wmt14.en-fr.joined-dict.transformer/model.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 256, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 256, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}, 'task': {'_name': 'translation', 'data': 'data-bin', 'source_lang': 'en', 'target_lang': 'fr', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-03-21 16:46:34 | INFO | fairseq.tasks.translation | [en] dictionary: 44512 types\n",
      "2023-03-21 16:46:34 | INFO | fairseq.tasks.translation | [fr] dictionary: 44512 types\n",
      "2023-03-21 16:46:34 | INFO | fairseq_cli.generate | loading model(s) from /export/data4/vzhekova/biases-data/En-Fr/wmt14.en-fr.joined-dict.transformer/model.pt\n",
      "2023-03-21 16:46:56 | INFO | fairseq.data.data_utils | loaded 2,632 examples from: data-bin/test.en-fr.en\n",
      "2023-03-21 16:46:56 | INFO | fairseq.data.data_utils | loaded 2,632 examples from: data-bin/test.en-fr.fr\n",
      "2023-03-21 16:46:56 | INFO | fairseq.tasks.translation | data-bin test en-fr 2632 examples\n",
      "2023-03-21 16:48:14 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2023-03-21 16:48:14 | INFO | fairseq_cli.generate | Translated 2,632 sentences (68,067 tokens) in 37.4s (70.35 sentences/s, 1819.29 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "# Generate translations\n",
    "!fairseq-generate data-bin  \\\n",
    "    --task translation \\\n",
    "    --source-lang en \\\n",
    "    --target-lang fr \\\n",
    "    --path /export/data4/vzhekova/biases-data/En-Fr/wmt14.en-fr.joined-dict.transformer/model.pt \\\n",
    "    --beam 5 \\\n",
    "    --batch-size 256 \\\n",
    "    --memory-efficient-fp16 \\\n",
    "    --remove-bpe=subword_nmt > en-fr.decode.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f2fd49-e7d2-4d9c-907c-b71787a41f6c",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c94eda2-41da-41b5-8ed3-5592e04508f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Troisième technique : la catégorisation .\n",
      "Et c&apos; est tout . Merci .\n",
      "Vous pouvez aller jusqu&apos; au bout .\n",
      "Maintenant , c&apos; est une des images .\n",
      "Réfléchissons donc aux atomes .\n",
      "Voici leur couloir d&apos; embâcle .\n",
      "Et elle frappe un 257 .\n",
      "Mais que faisons @-@ nous ?\n",
      "Mark Bezos : Merci .\n",
      "Jetez un coup d&apos; oeil sur ce qu&apos; elle fait .\n",
      "..........\n",
      "Troisième technique : la catégorisation .\n",
      "Voilà tout . Merci .\n",
      "On peut faire tout ça .\n",
      "Voici l&apos; une des photos .\n",
      "Alors , pensons aux atomes .\n",
      "Voici leur rayon confiture .\n",
      "Et elle frappe à 257 .\n",
      "Mais nous en faisons quoi ?\n",
      "Mark Bezos : Merci .\n",
      "Regardez ce qu&apos; elle fait .\n"
     ]
    }
   ],
   "source": [
    "# Extract the hypotheses and references from the decoding log file\n",
    "!grep ^H en-fr.decode.log | sed 's/^H-//g' | cut -f 3 | sed 's/ @@//g' > ./hyp.txt\n",
    "!grep ^T en-fr.decode.log | sed 's/^T-//g' | cut -f 2 | sed 's/ @@//g' > ./ref.txt\n",
    "\n",
    "!head ./hyp.txt\n",
    "print(\"..........\")\n",
    "!head ./ref.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8560756f-60b3-4af2-ac38-897e030e5da5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished detokenizing.\n"
     ]
    }
   ],
   "source": [
    "# Detokenize text        \n",
    "\n",
    "md_fr = MosesDetokenizer(lang='fr')\n",
    "\n",
    "with open('hyp.txt', encoding='utf8') as fin, open('hyp_detok.txt','w', encoding='utf8') as fout:\n",
    "    for line in fin:\n",
    "        tokens = md_fr.detokenize(line.split(), return_str=True)\n",
    "        print(tokens, end='\\n', file=fout)\n",
    "        \n",
    "with open('ref.txt', encoding='utf8') as fin, open('ref_detok.txt','w', encoding='utf8') as fout:\n",
    "    for line in fin:\n",
    "        tokens = md_fr.detokenize(line.split(), return_str=True)\n",
    "        print(tokens, end='\\n', file=fout)\n",
    "\n",
    "print('Finished detokenizing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d9274ae1-a009-4e59-aea1-951d390ae87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Troisième technique : la catégorisation.\n",
      "Et c'est tout. Merci.\n",
      "Vous pouvez aller jusqu'au bout.\n",
      "Maintenant, c'est une des images.\n",
      "Réfléchissons donc aux atomes.\n",
      "Voici leur couloir d'embâcle.\n",
      "Et elle frappe un 257.\n",
      "Mais que faisons-nous ?\n",
      "Mark Bezos : Merci.\n",
      "Jetez un coup d'oeil sur ce qu'elle fait.\n",
      "..........\n",
      "Troisième technique : la catégorisation.\n",
      "Voilà tout. Merci.\n",
      "On peut faire tout ça.\n",
      "Voici l'une des photos.\n",
      "Alors, pensons aux atomes.\n",
      "Voici leur rayon confiture.\n",
      "Et elle frappe à 257.\n",
      "Mais nous en faisons quoi ?\n",
      "Mark Bezos : Merci.\n",
      "Regardez ce qu'elle fait.\n"
     ]
    }
   ],
   "source": [
    "!head ./hyp_detok.txt\n",
    "print(\"..........\")\n",
    "!head ./ref_detok.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84d0e08b-5b01-47e5-bec7-cd2305b164b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"name\": \"BLEU\",\n",
      " \"score\": 44.5,\n",
      " \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.3.1\",\n",
      " \"verbose_score\": \"69.8/50.0/38.2/29.5 (BP = 1.000 ratio = 1.002 hyp_len = 55620 ref_len = 55507)\",\n",
      " \"nrefs\": \"1\",\n",
      " \"case\": \"mixed\",\n",
      " \"eff\": \"no\",\n",
      " \"tok\": \"13a\",\n",
      " \"smooth\": \"exp\",\n",
      " \"version\": \"2.3.1\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "# BLEU score of 20.3 (beam=5)\n",
    "# BLEU score of 44.5 (beam=5) when using bpecodes\n",
    "!cat ./hyp_detok.txt | sacrebleu ./ref_detok.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2543292-a7e0-42bf-8edb-f747ea3c9ea2",
   "metadata": {},
   "source": [
    "# Finetuning WMT14 En-Fr model on MuST-C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afca00a0-dbc8-4d50-be3b-9a537e56ca25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-21 16:50:36 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 4096, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 4096, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 5, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.0005], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': '/export/data4/vzhekova/biases-data/En-Fr/wmt14.en-fr.joined-dict.transformer/model.pt', 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': 2, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': Namespace(_name='transformer_vaswani_wmt_en_fr_big', activation_dropout=0.0, activation_fn='relu', adam_betas='(0.9, 0.98)', adam_eps=1e-08, adaptive_input=False, adaptive_softmax_cutoff=None, adaptive_softmax_dropout=0, aim_repo=None, aim_run_hash=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, arch='transformer_vaswani_wmt_en_fr_big', attention_dropout=0.0, azureml_logging=False, batch_size=None, batch_size_valid=None, best_checkpoint_metric='loss', bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, checkpoint_activations=False, checkpoint_shard_count=1, checkpoint_suffix='', clip_norm=0.0, combine_valid_subsets=None, continue_once=None, cpu=False, cpu_offload=False, criterion='label_smoothed_cross_entropy', cross_self_attention=False, curriculum=0, data='data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='pytorch_ddp', ddp_comm_hook='none', decoder_attention_heads=16, decoder_embed_dim=1024, decoder_embed_path=None, decoder_ffn_embed_dim=4096, decoder_input_dim=1024, decoder_layerdrop=0, decoder_layers=6, decoder_layers_to_keep=None, decoder_learned_pos=False, decoder_normalize_before=False, decoder_output_dim=1024, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_num_procs=1, distributed_port=-1, distributed_rank=0, distributed_world_size=1, dropout=0.3, ema_decay=0.9999, ema_fp32=False, ema_seed_model=None, ema_start_update=0, ema_update_freq=1, empty_cache_freq=0, encoder_attention_heads=16, encoder_embed_dim=1024, encoder_embed_path=None, encoder_ffn_embed_dim=4096, encoder_layerdrop=0, encoder_layers=6, encoder_layers_to_keep=None, encoder_learned_pos=False, encoder_normalize_before=False, eos=2, eval_bleu=False, eval_bleu_args='{}', eval_bleu_detok='space', eval_bleu_detok_args='{}', eval_bleu_print_samples=False, eval_bleu_remove_bpe=None, eval_tokenized_bleu=False, fast_stat_sync=False, find_unused_parameters=False, finetune_from_model='/export/data4/vzhekova/biases-data/En-Fr/wmt14.en-fr.joined-dict.transformer/model.pt', fix_batches_to_gpus=False, fixed_validation_seed=None, fp16=False, fp16_adam_stats=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, fp32_reduce_scatter=False, gen_subset='test', gradient_as_bucket_view=False, grouped_shuffling=False, heartbeat_timeout=-1, ignore_prefix_size=0, ignore_unused_valid_subsets=False, keep_best_checkpoints=-1, keep_interval_updates=-1, keep_interval_updates_pattern=-1, keep_last_epochs=2, label_smoothing=0.1, layernorm_embedding=False, left_pad_source=True, left_pad_target=False, load_alignments=False, load_checkpoint_on_all_dp_ranks=False, localsgd_frequency=3, log_file=None, log_format=None, log_interval=100, lr=[0.0005], lr_scheduler='inverse_sqrt', max_epoch=5, max_tokens=4096, max_tokens_valid=4096, max_update=0, max_valid_steps=None, maximize_best_checkpoint_metric=False, memory_efficient_bf16=False, memory_efficient_fp16=False, merge_src_tgt_embed=False, min_loss_scale=0.0001, model_parallel_size=1, no_cross_attention=False, no_epoch_checkpoints=False, no_last_checkpoints=False, no_progress_bar=False, no_reshard_after_forward=False, no_save=False, no_save_optimizer_state=False, no_scale_embedding=False, no_seed_provided=False, no_token_positional_embeddings=False, not_fsdp_flatten_parameters=False, nprocs_per_node=1, num_batch_buckets=0, num_shards=1, num_workers=1, offload_activations=False, on_cpu_convert_precision=False, optimizer='adam', optimizer_overrides='{}', pad=1, patience=-1, pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, plasma_path='/tmp/plasma', profile=False, quant_noise_pq=0, quant_noise_pq_block_size=8, quant_noise_scalar=0, quantization_config_path=None, report_accuracy=False, required_batch_size_multiple=8, required_seq_len_multiple=1, reset_dataloader=False, reset_logging=False, reset_lr_scheduler=False, reset_meters=False, reset_optimizer=False, restore_file='checkpoint_last.pt', save_dir='checkpoints', save_interval=1, save_interval_updates=0, scoring='bleu', seed=1, sentence_avg=False, shard_id=0, share_all_embeddings=False, share_decoder_input_output_embed=True, skip_invalid_size_inputs_valid_test=False, skip_remainder_batch=False, slowmo_base_algorithm='localsgd', slowmo_momentum=None, source_lang=None, stop_min_lr=-1.0, stop_time_hours=0, store_ema=False, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, threshold_loss_scale=None, tie_adaptive_weights=False, tokenizer=None, tpu=False, train_subset='train', truncate_source=False, unk=3, update_epoch_batch_itr=False, update_freq=[1], update_ordered_indices_seed=False, upsample_primary=-1, use_bmuf=False, use_old_adam=False, use_plasma_view=False, use_sharded_state=False, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, wandb_project=None, warmup_init_lr=-1, warmup_updates=4000, weight_decay=0.0001, write_checkpoints_asynchronously=False, zero_sharding='none'), 'task': {'_name': 'translation', 'data': 'data-bin', 'source_lang': None, 'target_lang': None, 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'label_smoothed_cross_entropy', 'label_smoothing': 0.1, 'report_accuracy': False, 'ignore_prefix_size': 0, 'sentence_avg': False}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9, 0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0001, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [0.0005]}, 'lr_scheduler': {'_name': 'inverse_sqrt', 'warmup_updates': 4000, 'warmup_init_lr': -1.0, 'lr': [0.0005]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-03-21 16:50:36 | INFO | fairseq.tasks.translation | [en] dictionary: 44512 types\n",
      "2023-03-21 16:50:36 | INFO | fairseq.tasks.translation | [fr] dictionary: 44512 types\n",
      "2023-03-21 16:50:45 | INFO | fairseq_cli.train | TransformerModel(\n",
      "  (encoder): TransformerEncoderBase(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(44512, 1024, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerEncoderLayerBase(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerEncoderLayerBase(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerEncoderLayerBase(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerEncoderLayerBase(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerEncoderLayerBase(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerEncoderLayerBase(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): TransformerDecoderBase(\n",
      "    (dropout_module): FairseqDropout()\n",
      "    (embed_tokens): Embedding(44512, 1024, padding_idx=1)\n",
      "    (embed_positions): SinusoidalPositionalEmbedding()\n",
      "    (layers): ModuleList(\n",
      "      (0): TransformerDecoderLayerBase(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (1): TransformerDecoderLayerBase(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (2): TransformerDecoderLayerBase(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (3): TransformerDecoderLayerBase(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (4): TransformerDecoderLayerBase(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (5): TransformerDecoderLayerBase(\n",
      "        (dropout_module): FairseqDropout()\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (activation_dropout_module): FairseqDropout()\n",
      "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (encoder_attn): MultiheadAttention(\n",
      "          (dropout_module): FairseqDropout()\n",
      "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "        )\n",
      "        (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (output_projection): Linear(in_features=1024, out_features=44512, bias=False)\n",
      "  )\n",
      ")\n",
      "2023-03-21 16:50:45 | INFO | fairseq_cli.train | task: TranslationTask\n",
      "2023-03-21 16:50:45 | INFO | fairseq_cli.train | model: TransformerModel\n",
      "2023-03-21 16:50:45 | INFO | fairseq_cli.train | criterion: LabelSmoothedCrossEntropyCriterion\n",
      "2023-03-21 16:50:45 | INFO | fairseq_cli.train | num. shared model params: 267,517,952 (num. trained: 267,517,952)\n",
      "2023-03-21 16:50:45 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
      "2023-03-21 16:50:45 | INFO | fairseq.data.data_utils | loaded 1,412 examples from: data-bin/valid.en-fr.en\n",
      "2023-03-21 16:50:45 | INFO | fairseq.data.data_utils | loaded 1,412 examples from: data-bin/valid.en-fr.fr\n",
      "2023-03-21 16:50:45 | INFO | fairseq.tasks.translation | data-bin valid en-fr 1412 examples\n",
      "2023-03-21 16:50:50 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.weight <- decoder.output_projection.weight\n",
      "2023-03-21 16:50:50 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
      "2023-03-21 16:50:50 | INFO | fairseq.utils | rank   0: capabilities =  6.1  ; total memory = 10.917 GB ; name = GeForce GTX 1080 Ti                     \n",
      "2023-03-21 16:50:50 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
      "2023-03-21 16:50:50 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
      "2023-03-21 16:50:50 | INFO | fairseq_cli.train | max tokens per device = 4096 and max sentences per device = None\n",
      "2023-03-21 16:50:50 | INFO | fairseq.checkpoint_utils | loading pretrained model from /export/data4/vzhekova/biases-data/En-Fr/wmt14.en-fr.joined-dict.transformer/model.pt: optimizer, lr scheduler, meters, dataloader will be reset\n",
      "2023-03-21 16:50:50 | INFO | fairseq.trainer | Preparing to load checkpoint /export/data4/vzhekova/biases-data/En-Fr/wmt14.en-fr.joined-dict.transformer/model.pt\n",
      "2023-03-21 16:50:59 | INFO | fairseq.trainer | Loaded checkpoint /export/data4/vzhekova/biases-data/En-Fr/wmt14.en-fr.joined-dict.transformer/model.pt (epoch 29 @ 0 updates)\n",
      "2023-03-21 16:51:00 | INFO | fairseq.trainer | loading train data for epoch 1\n",
      "2023-03-21 16:51:00 | INFO | fairseq.data.data_utils | loaded 275,085 examples from: data-bin/train.en-fr.en\n",
      "2023-03-21 16:51:00 | INFO | fairseq.data.data_utils | loaded 275,085 examples from: data-bin/train.en-fr.fr\n",
      "2023-03-21 16:51:00 | INFO | fairseq.tasks.translation | data-bin train en-fr 275085 examples\n",
      "2023-03-21 16:51:00 | INFO | fairseq.data.iterators | grouped total_num_itrs = 2027\n",
      "epoch 001:   0%|                                       | 0/2027 [00:00<?, ?it/s]2023-03-21 16:51:00 | INFO | fairseq.trainer | begin training epoch 1\n",
      "2023-03-21 16:51:00 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "/home/vzhekova/fairseq/fairseq/utils.py:374: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
      "  warnings.warn(\n",
      "epoch 001: 100%|▉| 2026/2027 [27:03<00:00,  1.19it/s, loss=3.741, nll_loss=2.04,2023-03-21 17:18:04 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 001 | valid on 'valid' subset:   0%|               | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset:   6%|▍      | 1/18 [00:00<00:05,  3.16it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset:  11%|▊      | 2/18 [00:00<00:04,  3.84it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset:  17%|█▏     | 3/18 [00:00<00:03,  4.02it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset:  22%|█▌     | 4/18 [00:00<00:03,  4.35it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset:  28%|█▉     | 5/18 [00:01<00:03,  4.22it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset:  33%|██▎    | 6/18 [00:01<00:02,  4.20it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset:  39%|██▋    | 7/18 [00:01<00:02,  4.07it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset:  44%|███    | 8/18 [00:01<00:02,  4.09it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset:  50%|███▌   | 9/18 [00:02<00:02,  4.13it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset:  56%|███▎  | 10/18 [00:02<00:01,  4.02it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset:  61%|███▋  | 11/18 [00:02<00:01,  3.91it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset:  67%|████  | 12/18 [00:02<00:01,  3.91it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset:  72%|████▎ | 13/18 [00:03<00:01,  3.85it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset:  78%|████▋ | 14/18 [00:03<00:01,  3.92it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset:  83%|█████ | 15/18 [00:03<00:00,  3.96it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset:  89%|█████▎| 16/18 [00:03<00:00,  4.02it/s]\u001b[A\n",
      "epoch 001 | valid on 'valid' subset: 100%|██████| 18/18 [00:04<00:00,  6.09it/s]\u001b[A\n",
      "                                                                                \u001b[A2023-03-21 17:18:08 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 3.56 | nll_loss 1.767 | ppl 3.4 | wps 9704.6 | wpb 2167.2 | bsz 78.4 | num_updates 2027\n",
      "2023-03-21 17:18:08 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 2027 updates\n",
      "2023-03-21 17:18:08 | INFO | fairseq.trainer | Saving checkpoint to /export/data4/vzhekova/biases-data/En-Fr_MuST-C/checkpoints/checkpoint1.pt\n",
      "2023-03-21 17:18:22 | INFO | fairseq.trainer | Finished saving checkpoint to /export/data4/vzhekova/biases-data/En-Fr_MuST-C/checkpoints/checkpoint1.pt\n",
      "2023-03-21 17:18:32 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint1.pt (epoch 1 @ 2027 updates, score 3.56) (writing took 23.59357076883316 seconds)\n",
      "2023-03-21 17:18:32 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
      "2023-03-21 17:18:32 | INFO | train | epoch 001 | loss 3.645 | nll_loss 1.931 | ppl 3.81 | wps 4454.1 | ups 1.23 | wpb 3627.3 | bsz 135.7 | num_updates 2027 | lr 0.000253375 | gnorm 2.335 | train_wall 1613 | gb_free 2.7 | wall 1661\n",
      "2023-03-21 17:18:32 | INFO | fairseq.data.iterators | grouped total_num_itrs = 2027\n",
      "epoch 002:   0%|                                       | 0/2027 [00:00<?, ?it/s]2023-03-21 17:18:32 | INFO | fairseq.trainer | begin training epoch 2\n",
      "2023-03-21 17:18:32 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "epoch 002: 100%|▉| 2026/2027 [27:01<00:00,  1.27it/s, loss=4.17, nll_loss=2.521,2023-03-21 17:45:34 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 002 | valid on 'valid' subset:   0%|               | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:   6%|▍      | 1/18 [00:00<00:05,  3.07it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:  11%|▊      | 2/18 [00:00<00:04,  3.77it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:  17%|█▏     | 3/18 [00:00<00:03,  3.95it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:  22%|█▌     | 4/18 [00:00<00:03,  4.30it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:  28%|█▉     | 5/18 [00:01<00:03,  4.21it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:  33%|██▎    | 6/18 [00:01<00:02,  4.19it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:  39%|██▋    | 7/18 [00:01<00:02,  4.08it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:  44%|███    | 8/18 [00:01<00:02,  4.09it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:  50%|███▌   | 9/18 [00:02<00:02,  4.14it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:  56%|███▎  | 10/18 [00:02<00:01,  4.02it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:  61%|███▋  | 11/18 [00:02<00:01,  3.91it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:  67%|████  | 12/18 [00:03<00:01,  3.90it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:  72%|████▎ | 13/18 [00:03<00:01,  3.84it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:  78%|████▋ | 14/18 [00:03<00:01,  3.92it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:  83%|█████ | 15/18 [00:03<00:00,  3.96it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset:  89%|█████▎| 16/18 [00:04<00:00,  4.02it/s]\u001b[A\n",
      "epoch 002 | valid on 'valid' subset: 100%|██████| 18/18 [00:04<00:00,  6.14it/s]\u001b[A\n",
      "                                                                                \u001b[A2023-03-21 17:45:38 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 3.905 | nll_loss 2.139 | ppl 4.41 | wps 9699.8 | wpb 2167.2 | bsz 78.4 | num_updates 4054 | best_loss 3.56\n",
      "2023-03-21 17:45:38 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 4054 updates\n",
      "2023-03-21 17:45:38 | INFO | fairseq.trainer | Saving checkpoint to /export/data4/vzhekova/biases-data/En-Fr_MuST-C/checkpoints/checkpoint2.pt\n",
      "2023-03-21 17:45:52 | INFO | fairseq.trainer | Finished saving checkpoint to /export/data4/vzhekova/biases-data/En-Fr_MuST-C/checkpoints/checkpoint2.pt\n",
      "2023-03-21 17:46:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint2.pt (epoch 2 @ 4054 updates, score 3.905) (writing took 71.55622649565339 seconds)\n",
      "2023-03-21 17:46:50 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
      "2023-03-21 17:46:50 | INFO | train | epoch 002 | loss 3.87 | nll_loss 2.184 | ppl 4.54 | wps 4330.1 | ups 1.19 | wpb 3627.3 | bsz 135.7 | num_updates 4054 | lr 0.000496659 | gnorm 3.694 | train_wall 1611 | gb_free 3.5 | wall 3359\n",
      "2023-03-21 17:46:50 | INFO | fairseq.data.iterators | grouped total_num_itrs = 2027\n",
      "epoch 003:   0%|                                       | 0/2027 [00:00<?, ?it/s]2023-03-21 17:46:50 | INFO | fairseq.trainer | begin training epoch 3\n",
      "2023-03-21 17:46:50 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "epoch 003:  93%|▉| 1887/2027 [24:55<01:50,  1.27it/s, loss=4.042, nll_loss=2.379"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 004: 100%|▉| 2026/2027 [26:47<00:00,  1.24it/s, loss=3.868, nll_loss=2.1862023-03-21 18:41:42 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
      "\n",
      "epoch 004 | valid on 'valid' subset:   0%|               | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:   6%|▍      | 1/18 [00:00<00:05,  2.93it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:  11%|▊      | 2/18 [00:00<00:04,  3.70it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:  17%|█▏     | 3/18 [00:00<00:03,  3.94it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:  22%|█▌     | 4/18 [00:00<00:03,  4.30it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:  28%|█▉     | 5/18 [00:01<00:03,  4.19it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:  33%|██▎    | 6/18 [00:01<00:02,  4.17it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:  39%|██▋    | 7/18 [00:01<00:02,  4.06it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:  44%|███    | 8/18 [00:01<00:02,  4.08it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:  50%|███▌   | 9/18 [00:02<00:02,  4.12it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:  56%|███▎  | 10/18 [00:02<00:01,  4.02it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:  61%|███▋  | 11/18 [00:02<00:01,  3.91it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:  67%|████  | 12/18 [00:03<00:01,  3.89it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:  72%|████▎ | 13/18 [00:03<00:01,  3.85it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:  78%|████▋ | 14/18 [00:03<00:01,  3.91it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:  83%|█████ | 15/18 [00:03<00:00,  3.95it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset:  89%|█████▎| 16/18 [00:04<00:00,  3.99it/s]\u001b[A\n",
      "epoch 004 | valid on 'valid' subset: 100%|██████| 18/18 [00:04<00:00,  6.04it/s]\u001b[A\n",
      "                                                                                \u001b[A2023-03-21 18:41:46 | INFO | valid | epoch 004 | valid on 'valid' subset | loss 3.881 | nll_loss 2.103 | ppl 4.29 | wps 9672.8 | wpb 2167.2 | bsz 78.4 | num_updates 8108 | best_loss 3.56\n",
      "2023-03-21 18:41:46 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 4 @ 8108 updates\n",
      "2023-03-21 18:41:46 | INFO | fairseq.trainer | Saving checkpoint to /export/data4/vzhekova/biases-data/En-Fr_MuST-C/checkpoints/checkpoint4.pt\n",
      "2023-03-21 18:42:02 | INFO | fairseq.trainer | Finished saving checkpoint to /export/data4/vzhekova/biases-data/En-Fr_MuST-C/checkpoints/checkpoint4.pt\n",
      "2023-03-21 18:43:00 | INFO | fairseq.checkpoint_utils | Saved checkpoint checkpoints/checkpoint4.pt (epoch 4 @ 8108 updates, score 3.881) (writing took 73.62728280387819 seconds)\n",
      "2023-03-21 18:43:01 | INFO | fairseq_cli.train | end of epoch 4 (average epoch stats below)\n",
      "2023-03-21 18:43:01 | INFO | train | epoch 004 | loss 3.909 | nll_loss 2.229 | ppl 4.69 | wps 4359 | ups 1.2 | wpb 3627.3 | bsz 135.7 | num_updates 8108 | lr 0.000351191 | gnorm 3.691 | train_wall 1595 | gb_free 3.3 | wall 6731\n",
      "2023-03-21 18:43:01 | INFO | fairseq.data.iterators | grouped total_num_itrs = 2027\n",
      "epoch 005:   0%|                                       | 0/2027 [00:00<?, ?it/s]2023-03-21 18:43:01 | INFO | fairseq.trainer | begin training epoch 5\n",
      "2023-03-21 18:43:01 | INFO | fairseq_cli.train | Start iterating over samples\n",
      "epoch 005:  94%|▉| 1905/2027 [25:12<01:34,  1.29it/s, loss=3.818, nll_loss=2.129"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 fairseq-train data-bin \\\n",
    "    --arch transformer_vaswani_wmt_en_fr_big --share-decoder-input-output-embed \\\n",
    "    --optimizer adam --adam-betas '(0.9, 0.98)' --clip-norm 0.0 \\\n",
    "    --lr 5e-4 --lr-scheduler inverse_sqrt --warmup-updates 4000 \\\n",
    "    --dropout 0.3 --weight-decay 0.0001 \\\n",
    "    --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
    "    --keep-last-epochs 2 \\\n",
    "    --max-tokens 4096 \\\n",
    "    --max-epoch 5 \\\n",
    "    --finetune-from-model /export/data4/vzhekova/biases-data/En-Fr/wmt14.en-fr.joined-dict.transformer/model.pt\t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3689236c-6111-48b7-b240-c8c2d0fb65ea",
   "metadata": {},
   "source": [
    "- Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30652b59-81ec-4e35-b3b2-c0da8ad8120b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/data4/vzhekova/biases-data/En-Fr_MuST-C\n"
     ]
    }
   ],
   "source": [
    "%cd $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37c9111e-af7e-4e27-a697-755ccb93cd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-21 20:15:06 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'checkpoints/checkpoint_best.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 256, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 256, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}, 'task': {'_name': 'translation', 'data': 'data-bin', 'source_lang': 'en', 'target_lang': 'fr', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-03-21 20:15:08 | INFO | fairseq.tasks.translation | [en] dictionary: 44512 types\n",
      "2023-03-21 20:15:08 | INFO | fairseq.tasks.translation | [fr] dictionary: 44512 types\n",
      "2023-03-21 20:15:08 | INFO | fairseq_cli.generate | loading model(s) from checkpoints/checkpoint_best.pt\n",
      "2023-03-21 20:15:26 | INFO | fairseq.data.data_utils | loaded 2,632 examples from: data-bin/test.en-fr.en\n",
      "2023-03-21 20:15:26 | INFO | fairseq.data.data_utils | loaded 2,632 examples from: data-bin/test.en-fr.fr\n",
      "2023-03-21 20:15:26 | INFO | fairseq.tasks.translation | data-bin test en-fr 2632 examples\n",
      "2023-03-21 20:16:41 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2023-03-21 20:16:41 | INFO | fairseq_cli.generate | Translated 2,632 sentences (66,656 tokens) in 37.3s (70.50 sentences/s, 1785.49 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "# Generate translations\n",
    "!fairseq-generate data-bin  \\\n",
    "    --task translation \\\n",
    "    --source-lang en \\\n",
    "    --target-lang fr \\\n",
    "    --path checkpoints/checkpoint_best.pt \\\n",
    "    --beam 5 \\\n",
    "    --batch-size 256 \\\n",
    "    --memory-efficient-fp16 \\\n",
    "    --remove-bpe=subword_nmt > en-fr.decode_finetuned.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a0bd18-be1d-4057-bb51-fba22a0d95ac",
   "metadata": {},
   "source": [
    "- Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e3471b2-d643-41e1-a10f-9d0f6fdcb707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La troisième technique : catégorisation .\n",
      "Et c&apos; est tout . Merci .\n",
      "Vous pouvez faire tout le chemin .\n",
      "Voici une des images .\n",
      "Réfléchissons aux atomes .\n",
      "Voici leur jam aisle .\n",
      "Et elle touche une 257ème .\n",
      "Mais que faites-nous avec ?\n",
      "Mark Bezos : Merci .\n",
      "Regardez ce qu&apos; elle fait .\n",
      "..........\n",
      "Troisième technique : la catégorisation .\n",
      "Voilà tout . Merci .\n",
      "On peut faire tout ça .\n",
      "Voici l&apos; une des photos .\n",
      "Alors , pensons aux atomes .\n",
      "Voici leur rayon confiture .\n",
      "Et elle frappe à 257 .\n",
      "Mais nous en faisons quoi ?\n",
      "Mark Bezos : Merci .\n",
      "Regardez ce qu&apos; elle fait .\n"
     ]
    }
   ],
   "source": [
    "# Extract the hypotheses and references from the decoding log file\n",
    "!grep ^H en-fr.decode_finetuned.log | sed 's/^H-//g' | cut -f 3 | sed 's/ @@//g' > ./hyp_finetuned.txt\n",
    "!grep ^T en-fr.decode_finetuned.log | sed 's/^T-//g' | cut -f 2 | sed 's/ @@//g' > ./ref_finetuned.txt\n",
    "\n",
    "!head ./hyp_finetuned.txt\n",
    "print(\"..........\")\n",
    "!head ./ref_finetuned.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b5e9178-9a75-4fee-aae2-ef81f4847486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished detokenizing.\n"
     ]
    }
   ],
   "source": [
    "# Detokenize text        \n",
    "\n",
    "md_fr = MosesDetokenizer(lang='fr')\n",
    "\n",
    "with open('hyp_finetuned.txt', encoding='utf8') as fin, open('hyp_finetuned_detok.txt','w', encoding='utf8') as fout:\n",
    "    for line in fin:\n",
    "        tokens = md_fr.detokenize(line.split(), return_str=True)\n",
    "        print(tokens, end='\\n', file=fout)\n",
    "        \n",
    "with open('ref_finetuned.txt', encoding='utf8') as fin, open('ref_finetuned_detok.txt','w', encoding='utf8') as fout:\n",
    "    for line in fin:\n",
    "        tokens = md_fr.detokenize(line.split(), return_str=True)\n",
    "        print(tokens, end='\\n', file=fout)\n",
    "\n",
    "print('Finished detokenizing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aae30479-cbde-4007-9a7a-f0cf3a4536ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"name\": \"BLEU\",\n",
      " \"score\": 45.9,\n",
      " \"signature\": \"nrefs:1|case:mixed|eff:no|tok:13a|smooth:exp|version:2.3.1\",\n",
      " \"verbose_score\": \"72.3/52.9/40.7/31.7 (BP = 0.975 ratio = 0.975 hyp_len = 54117 ref_len = 55507)\",\n",
      " \"nrefs\": \"1\",\n",
      " \"case\": \"mixed\",\n",
      " \"eff\": \"no\",\n",
      " \"tok\": \"13a\",\n",
      " \"smooth\": \"exp\",\n",
      " \"version\": \"2.3.1\"\n",
      "}\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "# BLEU score of 33.8 (beam=5)\n",
    "# BLEU score of 45.9 (beam=5) after using bpecodes\n",
    "!cat ./hyp_finetuned_detok.txt | sacrebleu ./ref_finetuned_detok.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bd464e-4e97-46f1-aa7c-02a08648a0db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
