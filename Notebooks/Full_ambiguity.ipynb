{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "7eb9c1b6-7f4d-468a-984f-e7b61fa4b7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.enabled = False \n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "PATH=\"/export/data4/vzhekova/biases-data/Test_De/Statistics/Full_ambiguity\"\n",
    "FASTBPE=\"/home/vzhekova/fastBPE/fast\" # path to the fastBPE tool\n",
    "FAST_ALIGN=\"/home/vzhekova/fast_align/build/fast_align\" # path to the fast_align tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "48aa5a31-2b6f-4744-bd0e-cd820e61740d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# check if we can connect to the GPU with PyTorch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.current_device()\n",
    "    print('Current device:', torch.cuda.get_device_name(device))\n",
    "else:\n",
    "    print('Failed to find GPU. Will use CPU.')\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "c199b4a0-7cab-4d4c-b270-e55ef77d010d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/data4/vzhekova/biases-data/Test_De/Statistics/Full_ambiguity\n"
     ]
    }
   ],
   "source": [
    "%cd $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf0636bc-6478-4b07-8a97-bd6e694ac4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sentences\n",
    "!cut -f3 -d'\t' en.txt > en_sentences.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c28ebdb9-66ef-4876-a057-1a48e75b10fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sentences containing 'because' and remove the second part of the clause\n",
    "# 330 unique sentences in total\n",
    "with open('en_sentences.txt', 'r') as fin, open('en_original.txt', 'w') as fout:\n",
    "    for line in fin:\n",
    "        sentence = ''\n",
    "        tokens = line.split(\" \")\n",
    "        for token in tokens:\n",
    "            if token == 'because':\n",
    "                print(sentence + '.', end='\\n', file=fout)\n",
    "            sentence = sentence + token.replace(',', '') + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "919d7d23-9867-4311-9da8-f64bf8f2e948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify gender ambiguous words with gender\n",
    "\n",
    "# List with source words\n",
    "words = set() # set forces uniqueness\n",
    "with open('words.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        words.add(line.strip())\n",
    "        \n",
    "with open('en_original.txt') as in_file, open('en_disambiguated.txt', 'w') as out_file: \n",
    "    for line in in_file:\n",
    "        sentence = line.split(' ')\n",
    "        for token in sentence:\n",
    "            if (token.replace(',', '') in words): # tokens often contain \",\"\n",
    "                token_pos = sentence.index(token)\n",
    "                sentence[token_pos] = \"male \" + token # could also replace with \"female\"\n",
    "        print(' '.join(sentence), end='', file=out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087ec0de-a7d8-4c97-a71f-48fb82d1ac2c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Translation English-German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d4f3657-9c41-4db4-b7a7-c9b69e6d5f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished tokenizing.\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "from sacremoses import MosesPunctNormalizer\n",
    "from sacremoses import MosesTokenizer, MosesDetokenizer\n",
    "from __future__ import print_function\n",
    "\n",
    "mpn = MosesPunctNormalizer()\n",
    "mt_en = MosesTokenizer(lang='en')\n",
    "md_en = MosesDetokenizer(lang='en')\n",
    "\n",
    "with open('en_original.txt') as fin, open('tok.en_original.en','w') as fout:\n",
    "    for line in fin:\n",
    "        tokens = mt_en.tokenize(mpn.normalize(line), return_str=True)\n",
    "        print(tokens, end='\\n', file=fout) \n",
    "        \n",
    "with open('en_disambiguated.txt') as fin, open('tok.en_disambiguated.en','w') as fout:\n",
    "    for line in fin:\n",
    "        tokens = mt_en.tokenize(mpn.normalize(line), return_str=True)\n",
    "        print(tokens, end='\\n', file=fout)\n",
    "\n",
    "print('Finished tokenizing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c50fa559-689b-4781-aad0-d25b6de74274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading codes from bpecodes.en ...\n",
      "Read 30000 codes from the codes file.\n",
      "Loading vocabulary from tok.en_original.en ...\n",
      "Read 2733 words (470 unique) from text file.\n",
      "Applying BPE to tok.en_original.en ...\n",
      "Modified 2733 words from text file.\n",
      "Loading codes from bpecodes.en ...\n",
      "Read 30000 codes from the codes file.\n",
      "Loading vocabulary from tok.en_disambiguated.en ...\n",
      "Read 3388 words (471 unique) from text file.\n",
      "Applying BPE to tok.en_disambiguated.en ...\n",
      "Modified 3388 words from text file.\n",
      "Finished subword.\n"
     ]
    }
   ],
   "source": [
    "# Dividing text into subword units\n",
    "\n",
    "!$FASTBPE applybpe bpe.en_original.en tok.en_original.en bpecodes.en\n",
    "!$FASTBPE applybpe bpe.en_disambiguated.en tok.en_disambiguated.en bpecodes.en\n",
    "\n",
    "print('Finished subword.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1ec72fd-81a4-4cd2-93a6-22c47288284f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-09 11:28:37 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin_original_en-de', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=True, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='en', srcdict='/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/dict.en.txt', suppress_crashes=False, target_lang='de', task='translation', tensorboard_logdir=None, testpref='bpe.en_original', tgtdict='/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/dict.de.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=8)\n",
      "2023-05-09 11:28:37 | INFO | fairseq_cli.preprocess | [en] Dictionary: 42024 types\n",
      "2023-05-09 11:28:38 | INFO | fairseq_cli.preprocess | [en] bpe.en_original.en: 330 sents, 3720 tokens, 0.0% replaced (by <unk>)\n",
      "2023-05-09 11:28:38 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin_original_en-de\n"
     ]
    }
   ],
   "source": [
    "# Binarize text\n",
    "!fairseq-preprocess \\\n",
    "    --source-lang en \\\n",
    "    --target-lang de \\\n",
    "    --testpref bpe.en_original \\\n",
    "    --only-source \\\n",
    "    --srcdict /export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/dict.en.txt \\\n",
    "    --tgtdict /export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/dict.de.txt \\\n",
    "    --destdir data-bin_original_en-de \\\n",
    "    --workers 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1615792f-24aa-40b5-958a-10790d5481b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-09 11:29:02 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin_disambiguated_en-de', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=True, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='en', srcdict='/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/dict.en.txt', suppress_crashes=False, target_lang='de', task='translation', tensorboard_logdir=None, testpref='bpe.en_disambiguated', tgtdict='/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/dict.de.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=8)\n",
      "2023-05-09 11:29:02 | INFO | fairseq_cli.preprocess | [en] Dictionary: 42024 types\n",
      "2023-05-09 11:29:02 | INFO | fairseq_cli.preprocess | [en] bpe.en_disambiguated.en: 330 sents, 4375 tokens, 0.0% replaced (by <unk>)\n",
      "2023-05-09 11:29:02 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin_disambiguated_en-de\n"
     ]
    }
   ],
   "source": [
    "!fairseq-preprocess \\\n",
    "    --source-lang en \\\n",
    "    --target-lang de \\\n",
    "    --testpref bpe.en_disambiguated \\\n",
    "    --only-source \\\n",
    "    --srcdict /export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/dict.en.txt \\\n",
    "    --tgtdict /export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/dict.de.txt \\\n",
    "    --destdir data-bin_disambiguated_en-de \\\n",
    "    --workers 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0534e037-1503-462b-aacc-bed90ec0118b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS=\"/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble\"\n",
    "NBEST = 10\n",
    "BEAM = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1df524a1-a957-45a8-ad21-a362d7abd060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-09 11:30:46 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model1.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model2.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model3.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model4.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 64, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 64, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 10, 'beam_mt': 0, 'nbest': 10, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}, 'task': {'_name': 'translation', 'data': 'data-bin_original_en-de', 'source_lang': 'en', 'target_lang': 'de', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-05-09 11:30:46 | INFO | fairseq.tasks.translation | [en] dictionary: 42024 types\n",
      "2023-05-09 11:30:46 | INFO | fairseq.tasks.translation | [de] dictionary: 42024 types\n",
      "2023-05-09 11:30:46 | INFO | fairseq_cli.generate | loading model(s) from /export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model1.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model2.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model3.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model4.pt\n",
      "2023-05-09 11:33:39 | INFO | fairseq.data.data_utils | loaded 330 examples from: data-bin_original_en-de/test.en-de.en\n",
      "2023-05-09 11:33:39 | INFO | fairseq.tasks.translation | data-bin_original_en-de test en-de 330 examples\n",
      "2023-05-09 11:34:21 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2023-05-09 11:34:21 | INFO | fairseq_cli.generate | Translated 330 sentences (4,106 tokens) in 23.5s (14.04 sentences/s, 174.66 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "# Generate N hypothesis\n",
    "!fairseq-generate data-bin_original_en-de  \\\n",
    "    --task translation \\\n",
    "    --source-lang en \\\n",
    "    --target-lang de \\\n",
    "    --path $MODELS/model1.pt:$MODELS/model2.pt:$MODELS/model3.pt:$MODELS/model4.pt \\\n",
    "    --beam $BEAM \\\n",
    "    --nbest $NBEST \\\n",
    "    --batch-size 64 \\\n",
    "    --memory-efficient-fp16 \\\n",
    "    --remove-bpe > original_en-de.decode_Beam_10.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13e4522e-8427-4fa0-904c-6b7edc65c969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-09 11:34:54 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model1.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model2.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model3.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model4.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 64, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 64, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 10, 'beam_mt': 0, 'nbest': 10, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}, 'task': {'_name': 'translation', 'data': 'data-bin_disambiguated_en-de', 'source_lang': 'en', 'target_lang': 'de', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-05-09 11:34:54 | INFO | fairseq.tasks.translation | [en] dictionary: 42024 types\n",
      "2023-05-09 11:34:54 | INFO | fairseq.tasks.translation | [de] dictionary: 42024 types\n",
      "2023-05-09 11:34:54 | INFO | fairseq_cli.generate | loading model(s) from /export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model1.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model2.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model3.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model4.pt\n",
      "2023-05-09 11:35:33 | INFO | fairseq.data.data_utils | loaded 330 examples from: data-bin_disambiguated_en-de/test.en-de.en\n",
      "2023-05-09 11:35:33 | INFO | fairseq.tasks.translation | data-bin_disambiguated_en-de test en-de 330 examples\n",
      "2023-05-09 11:36:00 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2023-05-09 11:36:00 | INFO | fairseq_cli.generate | Translated 330 sentences (5,261 tokens) in 18.1s (18.23 sentences/s, 290.57 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "# Generate N hypothesis\n",
    "!fairseq-generate data-bin_disambiguated_en-de  \\\n",
    "    --task translation \\\n",
    "    --source-lang en \\\n",
    "    --target-lang de \\\n",
    "    --path $MODELS/model1.pt:$MODELS/model2.pt:$MODELS/model3.pt:$MODELS/model4.pt \\\n",
    "    --beam $BEAM \\\n",
    "    --nbest $NBEST \\\n",
    "    --batch-size 64 \\\n",
    "    --memory-efficient-fp16 \\\n",
    "    --remove-bpe > disambiguated_en-de.decode_Beam_10.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9425c7dc-f10a-4b6f-81e5-f7d89f14d91f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Backtranslation German-English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6efb5c4a-0c37-4a6f-bd00-0aaea4da69fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'LC_ALL=C sort -V' sorts the results in natural order \n",
    "!grep ^H original_en-de.decode_Beam_10.log | LC_ALL=C sort -V | sed 's/^H-//g' | cut -f 3 | sed 's/ @@//g' > ./hyp_original.txt\n",
    "!grep ^H disambiguated_en-de.decode_Beam_10.log | LC_ALL=C sort -V | sed 's/^H-//g' | cut -f 3 | sed 's/ @@//g' > ./hyp_disambiguated.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b245127-a93d-45e3-b3a7-b9791d8b4189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading codes from bpecodes.de ...\n",
      "Read 30000 codes from the codes file.\n",
      "Loading vocabulary from hyp_original.txt ...\n",
      "Read 27703 words (1212 unique) from text file.\n",
      "Applying BPE to hyp_original.txt ...\n",
      "Modified 27703 words from text file.\n",
      "Loading codes from bpecodes.de ...\n",
      "Read 30000 codes from the codes file.\n",
      "Loading vocabulary from hyp_disambiguated.txt ...\n",
      "Read 32952 words (1120 unique) from text file.\n",
      "Applying BPE to hyp_disambiguated.txt ...\n",
      "Modified 32952 words from text file.\n",
      "Finished subword.\n"
     ]
    }
   ],
   "source": [
    "# Dividing tokenized text into subword units\n",
    "\n",
    "!$FASTBPE applybpe bpe.hyp_original.de hyp_original.txt bpecodes.de\n",
    "!$FASTBPE applybpe bpe.hyp_disambiguated.de hyp_disambiguated.txt bpecodes.de\n",
    "\n",
    "print('Finished subword.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9dd3cf73-9c96-49df-b749-f2bbe337df62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-09 11:37:00 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin_original_de-en', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=True, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='de', srcdict='/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/dict.de.txt', suppress_crashes=False, target_lang='en', task='translation', tensorboard_logdir=None, testpref='bpe.hyp_original', tgtdict='/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/dict.en.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=8)\n",
      "2023-05-09 11:37:00 | INFO | fairseq_cli.preprocess | [de] Dictionary: 42024 types\n",
      "2023-05-09 11:37:01 | INFO | fairseq_cli.preprocess | [de] bpe.hyp_original.de: 3300 sents, 40636 tokens, 0.0% replaced (by <unk>)\n",
      "2023-05-09 11:37:01 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin_original_de-en\n"
     ]
    }
   ],
   "source": [
    "!fairseq-preprocess \\\n",
    "    --source-lang de \\\n",
    "    --target-lang en \\\n",
    "    --only-source \\\n",
    "    --testpref bpe.hyp_original \\\n",
    "    --srcdict /export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/dict.de.txt \\\n",
    "    --tgtdict /export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/dict.en.txt \\\n",
    "    --destdir data-bin_original_de-en \\\n",
    "    --workers 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "702ebc86-b0d5-4d1d-9436-41934e67ec0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-09 11:37:08 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin_disambiguated_de-en', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=True, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='de', srcdict='/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/dict.de.txt', suppress_crashes=False, target_lang='en', task='translation', tensorboard_logdir=None, testpref='bpe.hyp_disambiguated', tgtdict='/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/dict.en.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=8)\n",
      "2023-05-09 11:37:08 | INFO | fairseq_cli.preprocess | [de] Dictionary: 42024 types\n",
      "2023-05-09 11:37:09 | INFO | fairseq_cli.preprocess | [de] bpe.hyp_disambiguated.de: 3300 sents, 50777 tokens, 0.0% replaced (by <unk>)\n",
      "2023-05-09 11:37:09 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin_disambiguated_de-en\n"
     ]
    }
   ],
   "source": [
    "!fairseq-preprocess \\\n",
    "    --source-lang de \\\n",
    "    --target-lang en \\\n",
    "    --only-source \\\n",
    "    --testpref bpe.hyp_disambiguated \\\n",
    "    --srcdict /export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/dict.de.txt \\\n",
    "    --tgtdict /export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/dict.en.txt \\\n",
    "    --destdir data-bin_disambiguated_de-en \\\n",
    "    --workers 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "852891a2-e6c1-4300-9000-cd8f2a4ad4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS=\"/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble\"\n",
    "NBEST = 10\n",
    "BEAM = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07103d7f-cbc3-456a-acaa-1618cdcf70c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-09 12:09:43 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model1.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model2.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model3.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model4.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 64, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 64, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 10, 'beam_mt': 0, 'nbest': 10, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}, 'task': {'_name': 'translation', 'data': 'data-bin_original_de-en', 'source_lang': 'de', 'target_lang': 'en', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-05-09 12:09:44 | INFO | fairseq.tasks.translation | [de] dictionary: 42024 types\n",
      "2023-05-09 12:09:44 | INFO | fairseq.tasks.translation | [en] dictionary: 42024 types\n",
      "2023-05-09 12:09:44 | INFO | fairseq_cli.generate | loading model(s) from /export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model1.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model2.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model3.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model4.pt\n",
      "2023-05-09 12:12:10 | INFO | fairseq.data.data_utils | loaded 3,300 examples from: data-bin_original_de-en/test.de-en.de\n",
      "2023-05-09 12:12:10 | INFO | fairseq.tasks.translation | data-bin_original_de-en test de-en 3300 examples\n",
      "2023-05-09 12:14:50 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2023-05-09 12:14:50 | INFO | fairseq_cli.generate | Translated 3,300 sentences (36,404 tokens) in 108.8s (30.34 sentences/s, 334.74 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "# Generate N hypothesis\n",
    "!fairseq-generate data-bin_original_de-en  \\\n",
    "    --task translation \\\n",
    "    --source-lang de \\\n",
    "    --target-lang en \\\n",
    "    --path $MODELS/model1.pt:$MODELS/model2.pt:$MODELS/model3.pt:$MODELS/model4.pt \\\n",
    "    --beam $BEAM \\\n",
    "    --nbest $NBEST \\\n",
    "    --batch-size 64 \\\n",
    "    --memory-efficient-fp16 \\\n",
    "    --remove-bpe > original_de-en.decode_Beam_10_backtranslation.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c08bb193-d831-474f-9ae3-7f3956f65574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-09 12:21:17 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model1.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model2.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model3.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model4.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 64, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 64, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 10, 'beam_mt': 0, 'nbest': 10, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}, 'task': {'_name': 'translation', 'data': 'data-bin_disambiguated_de-en', 'source_lang': 'de', 'target_lang': 'en', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-05-09 12:21:17 | INFO | fairseq.tasks.translation | [de] dictionary: 42024 types\n",
      "2023-05-09 12:21:17 | INFO | fairseq.tasks.translation | [en] dictionary: 42024 types\n",
      "2023-05-09 12:21:17 | INFO | fairseq_cli.generate | loading model(s) from /export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model1.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model2.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model3.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model4.pt\n",
      "2023-05-09 12:21:56 | INFO | fairseq.data.data_utils | loaded 3,300 examples from: data-bin_disambiguated_de-en/test.de-en.de\n",
      "2023-05-09 12:21:56 | INFO | fairseq.tasks.translation | data-bin_disambiguated_de-en test de-en 3300 examples\n",
      "2023-05-09 12:24:58 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2023-05-09 12:24:58 | INFO | fairseq_cli.generate | Translated 3,300 sentences (41,806 tokens) in 126.8s (26.02 sentences/s, 329.59 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "# Generate N hypothesis\n",
    "!fairseq-generate data-bin_disambiguated_de-en  \\\n",
    "    --task translation \\\n",
    "    --source-lang de \\\n",
    "    --target-lang en \\\n",
    "    --path $MODELS/model1.pt:$MODELS/model2.pt:$MODELS/model3.pt:$MODELS/model4.pt \\\n",
    "    --beam $BEAM \\\n",
    "    --nbest $NBEST \\\n",
    "    --batch-size 64 \\\n",
    "    --memory-efficient-fp16 \\\n",
    "    --remove-bpe > disambiguated_de-en.decode_Beam_10_backtranslation.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cd64bb5b-f01d-43e6-9b52-ca4a000040c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'LC_ALL=C sort -V' sorts the results in natural order \n",
    "!grep ^H original_de-en.decode_Beam_10_backtranslation.log | LC_ALL=C sort -V | sed 's/^H-//g' | cut -f 3 | sed 's/ @@//g' > ./hyp_original_back.txt\n",
    "!grep ^H disambiguated_de-en.decode_Beam_10_backtranslation.log | LC_ALL=C sort -V | sed 's/^H-//g' | cut -f 3 | sed 's/ @@//g' > ./hyp_disambiguated_back.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d1cc9b77-86fc-4604-9d6c-6c6a3eea94c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished detokenizing.\n"
     ]
    }
   ],
   "source": [
    "# Detokenize text        \n",
    "from sacremoses import MosesPunctNormalizer\n",
    "from sacremoses import MosesTokenizer, MosesDetokenizer\n",
    "from __future__ import print_function\n",
    "\n",
    "md_en = MosesDetokenizer(lang='en')\n",
    "\n",
    "with open('hyp_original_back.txt', encoding='utf8') as fin, open('original_back.txt','w', encoding='utf8') as fout:\n",
    "    for line in fin:\n",
    "        tokens = md_en.detokenize(line.split(), return_str=True)\n",
    "        print(tokens, end='\\n', file=fout)\n",
    "        \n",
    "with open('hyp_disambiguated_back.txt', encoding='utf8') as fin, open('disambiguated_back.txt','w', encoding='utf8') as fout:\n",
    "    for line in fin:\n",
    "        tokens = md_en.detokenize(line.split(), return_str=True)\n",
    "        print(tokens, end='\\n', file=fout)\n",
    "\n",
    "print('Finished detokenizing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8a4d60-80fb-4ce1-b305-4dcaa5ddbbb2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Statistics on translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dab7a65c-57d3-4bd9-883c-b6166d8dc85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330\n",
      "330\n",
      "330\n"
     ]
    }
   ],
   "source": [
    "# List with original source sentences\n",
    "source = []\n",
    "with open('en_original.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        source.append(line.strip())\n",
    "        \n",
    "# List with disambiguated source sentences\n",
    "source_disambiguated = []\n",
    "with open('en_disambiguated.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        source_disambiguated.append(line.strip())\n",
    "    \n",
    "# List with nbest sentences for every source in original\n",
    "nbest_original = []\n",
    "counter = 0\n",
    "temp = []\n",
    "with open('hyp_original.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        temp.append(line.strip())\n",
    "        counter += 1\n",
    "        if (counter == 10):\n",
    "            nbest_original.append(temp)\n",
    "            counter = 0\n",
    "            temp = []\n",
    "            \n",
    "# List with nbest sentences for every source in disambiguated            \n",
    "nbest_modified = []\n",
    "with open('hyp_disambiguated.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        temp.append(line.strip())\n",
    "        counter += 1\n",
    "        if (counter == 10):\n",
    "            nbest_modified.append(temp)\n",
    "            counter = 0\n",
    "            temp = []\n",
    "            \n",
    "print(len(source))\n",
    "print(len(nbest_original))\n",
    "print(len(nbest_modified))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce374900-43dd-484f-bd18-8f8c05e524d4",
   "metadata": {},
   "source": [
    "## Count unique sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e76e4e7a-74ad-405a-8fac-1bfd927999ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.945454545454545\n"
     ]
    }
   ],
   "source": [
    "# Count unique sentences in source nbest list for each source sentence of original; 9.945454545454545\n",
    "# Value should be 10, because beam search generates 10 unique sentences\n",
    "for source_nbest in nbest_original:\n",
    "    num_values = len(set(source_nbest))\n",
    "    #print(num_values)\n",
    "    unique_sent.append(num_values)\n",
    "    \n",
    "#print(unique_sent)\n",
    "print(sum(unique_sent)/330) # average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c5cf0e5-b2e7-4ae6-9d2c-6bc0aa82fcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.954545454545455\n"
     ]
    }
   ],
   "source": [
    "# Count unique sentences in source nbest list for each source sentence of modified; 9.954545454545455\n",
    "unique_sent = []\n",
    "for source_nbest in nbest_modified:\n",
    "    num_values = len(set(source_nbest))\n",
    "    #print(num_values)\n",
    "    unique_sent.append(num_values)\n",
    "    \n",
    "#print(unique_sent)\n",
    "print(sum(unique_sent)/330) # average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176c0c73-c1d3-4ca9-9f3f-151c0e86f17f",
   "metadata": {},
   "source": [
    "## Count unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63153491-34b4-454f-84d0-786aef4793ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique words in source nbest list for each source sentence of original; 16.836363636363636\n",
    "import spacy\n",
    "\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "\n",
    "unique_words = []\n",
    "counter = 0\n",
    "for source_nbest in nbest_original:\n",
    "    words = set()\n",
    "    for sent in source_nbest:\n",
    "        tokens = sp(sent)\n",
    "        for token in tokens:\n",
    "            if token.text not in stopwords:    # checking whether the word is a stop word\n",
    "                words.add(token.text)\n",
    "    num_values = len(words)\n",
    "    unique_words.append(num_values)\n",
    "    \n",
    "    counter += 1\n",
    "    print(counter)\n",
    "    \n",
    "#print(unique_words)\n",
    "print(sum(unique_words)/330)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d3cf13-db7e-4ab4-8476-381617f88df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique words in source nbest list for each source sentence of modified; 17.64848484848485\n",
    "# !!! This is normal to generate more unique words, because the disambiguated sentences have more words in total\n",
    "import spacy\n",
    "\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "\n",
    "unique_words = []\n",
    "counter = 0\n",
    "for source_nbest in nbest_modified:\n",
    "    words = set()\n",
    "    for sent in source_nbest:\n",
    "        tokens = sp(sent)\n",
    "        for token in tokens:\n",
    "            if token.text not in stopwords:    # checking whether the word is a stop word\n",
    "                words.add(token.text)\n",
    "    num_values = len(words)\n",
    "    unique_words.append(num_values)\n",
    "    \n",
    "    counter += 1\n",
    "    print(counter)\n",
    "    \n",
    "#print(unique_words)\n",
    "print(sum(unique_words)/330)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95394217-96d3-4ea1-aa9b-65cec09c3be1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Statistics on backtranslations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "8b8b4177-38a5-4294-8c2a-619c63fab031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330\n",
      "330\n"
     ]
    }
   ],
   "source": [
    "# List with original source sentences\n",
    "source_original = []\n",
    "with open('en_original.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        source_original.append(line.strip())\n",
    "        \n",
    "# List with disambiguated source sentences\n",
    "source_disambiguated = []\n",
    "with open('en_disambiguated.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        source_disambiguated.append(line.strip())\n",
    "    \n",
    "# List with nbest sentences for every source in original \n",
    "nbest_original = []\n",
    "counter = 0\n",
    "temp = []\n",
    "with open('original_back.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        temp.append(line.strip())\n",
    "        counter += 1\n",
    "        if (counter == 100):\n",
    "            nbest_original.append(temp)\n",
    "            counter = 0\n",
    "            temp = []\n",
    "            \n",
    "# List with nbest sentences for every source in disambiguated\n",
    "nbest_disambiguated = []\n",
    "with open('disambiguated_back.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        temp.append(line.strip())\n",
    "        counter += 1\n",
    "        if (counter == 100):\n",
    "            nbest_disambiguated.append(temp)\n",
    "            counter = 0\n",
    "            temp = []\n",
    "            \n",
    "print(len(nbest_original))\n",
    "print(len(nbest_disambiguated))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f66cfb-d1bc-4b83-8f19-8ab4b21303db",
   "metadata": {},
   "source": [
    "## Source sentence reoccurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "ae8bfa24-2883-4d8c-9ce4-d13eb7ef02a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.575757575757576\n",
      "258\n"
     ]
    }
   ],
   "source": [
    "# Count how many times the source sentence occurs in the nbest list of original; 258\n",
    "results = []\n",
    "counter = 0\n",
    "for sent in source_original:\n",
    "    matches = 0\n",
    "    for target in nbest_original[counter]: \n",
    "        if (sent == target):\n",
    "            matches += 1\n",
    "    results.append(matches)  \n",
    "    counter += 1\n",
    "    \n",
    "print(sum(results)/330)\n",
    "print(sum(x > 0 for x in results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "b11b20be-122f-4a42-9c4f-e38242f831fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.903030303030303\n",
      "230\n"
     ]
    }
   ],
   "source": [
    "# Count how many times the source sentence occurs in the nbest list of disambiguated; 230\n",
    "results = []\n",
    "counter = 0\n",
    "for sent in source_disambiguated:\n",
    "    matches = 0\n",
    "    for target in nbest_disambiguated[counter]: \n",
    "        if (sent == target):\n",
    "            matches += 1\n",
    "    results.append(matches)  \n",
    "    counter += 1\n",
    "    \n",
    "print(sum(results)/330)\n",
    "print(sum(x > 0 for x in results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ecb949-c44c-42bd-8076-31893262c777",
   "metadata": {},
   "source": [
    "## Ambiguous source words reoccurrence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "76e85e14-a11e-4eb6-95d5-aa76aedc593b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['developer', 'mechanic', 'mover', 'assistant', 'chief', 'salesperson', 'lawyer', 'cook', 'mover', 'farmer', 'CEO', 'hairdresser', 'developer', 'driver', 'auditor', 'CEO', 'guard', 'assistant', 'assistant', 'auditor', 'salesperson', 'manager', 'physician', 'laborer', 'physician', 'hairdresser', 'developer', 'farmer', 'receptionist', 'manager', 'cleaner', 'mechanic', 'writer', 'worker', 'editor', 'analyst', 'carpenter', 'cook', 'carpenter', 'cleaner', 'laborer', 'mechanic', 'mechanic', 'cook', 'farmer', 'CEO', 'librarian', 'chief', 'developer', 'nurse', 'lawyer', 'developer', 'mover', 'mover', 'worker', 'secretary', 'CEO', 'carpenter', 'sheriff', 'mechanic', 'analyst', 'assistant', 'chief', 'janitor', 'manager', 'supervisor', 'chief', 'worker', 'salesperson', 'lawyer', 'developer', 'sheriff', 'janitor', 'laborer', 'driver', 'mover', 'developer', 'janitor', 'salesperson', 'chief', 'laborer', 'guard', 'nurse', 'worker', 'laborer', 'lawyer', 'CEO', 'laborer', 'laborer', 'nurse', 'manager', 'guard', 'developer', 'driver', 'manager', 'farmer', 'analyst', 'supervisor', 'laborer', 'carpenter', 'worker', 'manager', 'farmer', 'CEO', 'salesperson', 'driver', 'worker', 'supervisor', 'lawyer', 'analyst', 'supervisor', 'worker', 'CEO', 'CEO', 'salesperson', 'driver', 'farmer', 'guard', 'CEO', 'physician', 'manager', 'analyst', 'mover', 'CEO', 'laborer', 'farmer', 'sheriff', 'analyst', 'guard', 'mechanic', 'carpenter', 'sheriff', 'manager', 'sheriff', 'cook', 'mover', 'analyst', 'sheriff', 'salesperson', 'CEO', 'janitor', 'supervisor', 'developer', 'guard', 'driver', 'driver', 'chief', 'physician', 'sheriff', 'mechanic', 'developer', 'physician', 'mechanic', 'mover', 'chief', 'physician', 'farmer', 'salesperson', 'janitor', 'chief', 'lawyer', 'laborer', 'cook', 'analyst', 'guard', 'lawyer', 'CEO', 'carpenter', 'lawyer', 'manager', 'mover', 'farmer', 'farmer', 'guard', 'mover', 'guard', 'analyst', 'cook', 'driver', 'CEO', 'driver', 'salesperson', 'cook', 'lawyer', 'CEO', 'mechanic', 'physician', 'carpenter', 'supervisor', 'janitor', 'lawyer', 'worker', 'attendant', 'carpenter', 'carpenter', 'physician', 'sheriff', 'janitor', 'janitor', 'salesperson', 'counselor', 'secretary', 'supervisor', 'chief', 'guard', 'sheriff', 'mechanic', 'cleaner', 'sheriff', 'cleaner', 'baker', 'developer', 'clerk', 'worker', 'receptionist', 'salesperson', 'receptionist', 'accountant', 'manager', 'cook', 'supervisor', 'chief', 'supervisor', 'secretary', 'lawyer', 'auditor', 'analyst', 'guard', 'laborer', 'analyst', 'receptionist', 'receptionist', 'supervisor', 'clerk', 'chief', 'analyst', 'worker', 'guard', 'guard', 'developer', 'manager', 'mechanic', 'supervisor', 'housekeeper', 'supervisor', 'carpenter', 'mechanic', 'farmer', 'farmer', 'janitor', 'cook', 'driver', 'mechanic', 'mechanic', 'mover', 'carpenter', 'worker', 'supervisor', 'chief', 'janitor', 'analyst', 'sheriff', 'janitor', 'mover', 'developer', 'mechanic', 'editor', 'counselor', 'tailor', 'farmer', 'supervisor', 'manager', 'mover', 'laborer', 'housekeeper', 'baker', 'attendant', 'writer', 'cook', 'analyst', 'physician', 'driver', 'mover', 'driver', 'developer', 'chief', 'physician', 'janitor', 'chief', 'laborer', 'sheriff', 'chief', 'cook', 'salesperson', 'lawyer', 'farmer', 'cleaner', 'cook', 'laborer', 'cleaner', 'customer', 'manager', 'teenager', 'therapist', 'librarian', 'librarian', 'advisor', 'advisor', 'customer', 'bartender', 'patient', 'specialist', 'practitioner', 'practitioner', 'examiner', 'examiner', 'hairdresser', 'hairdresser', 'programmer', 'programmer', 'undergraduate', 'scientist', 'dietitian', 'dietitian', 'painter', 'painter', 'broker', 'broker', 'firefighter', 'firefighter']\n",
      "330\n",
      "330\n",
      "330\n"
     ]
    }
   ],
   "source": [
    "# List with source words\n",
    "words = set() # set forces uniqueness\n",
    "with open('words.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        words.add(line.strip())\n",
    "\n",
    "# Extract ambiguous words from source sentences\n",
    "ambiguous_words = [] \n",
    "with open('tok.en_original.en', 'r') as fin:\n",
    "    for line in fin:\n",
    "        tokens = line.split(' ')\n",
    "        for token in tokens:\n",
    "            if token in words:\n",
    "                ambiguous_words.append(token)\n",
    "                break\n",
    "        \n",
    "print(ambiguous_words)\n",
    "print(len(ambiguous_words))\n",
    "        \n",
    "# List with nbest sentences for every source\n",
    "nbest_original = []\n",
    "counter = 0\n",
    "temp = []\n",
    "with open('original_back.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        temp.append(line.strip())\n",
    "        counter += 1\n",
    "        if (counter == 100):\n",
    "            nbest_original.append(temp)\n",
    "            counter = 0\n",
    "            temp = []\n",
    "\n",
    "nbest_disambiguated = []\n",
    "with open('disambiguated_back.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        temp.append(line.strip())\n",
    "        counter += 1\n",
    "        if (counter == 100):\n",
    "            nbest_disambiguated.append(temp)\n",
    "            counter = 0\n",
    "            temp = []  \n",
    "\n",
    "print(len(nbest_original))\n",
    "print(len(nbest_modified))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "3346913e-ed3c-4444-b0a9-2cc0a4a24817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53, 100, 17, 72, 14, 3, 56, 81, 60, 73, 16, 55, 41, 100, 49, 64, 82, 100, 100, 46, 7, 74, 0, 0, 10, 46, 87, 74, 100, 100, 60, 95, 40, 70, 86, 100, 70, 78, 74, 81, 0, 98, 96, 78, 83, 29, 98, 25, 93, 100, 78, 52, 5, 0, 73, 92, 24, 80, 93, 100, 90, 66, 27, 35, 80, 35, 4, 48, 0, 66, 82, 88, 34, 0, 100, 80, 34, 43, 5, 15, 3, 85, 90, 64, 0, 77, 7, 0, 7, 70, 94, 98, 24, 95, 100, 94, 100, 97, 0, 72, 61, 100, 99, 36, 11, 99, 79, 61, 58, 100, 56, 54, 43, 1, 3, 100, 76, 53, 11, 13, 78, 96, 12, 10, 0, 99, 91, 100, 83, 100, 90, 85, 99, 90, 45, 2, 88, 96, 8, 37, 39, 67, 91, 89, 100, 100, 6, 10, 96, 91, 37, 5, 100, 9, 17, 11, 87, 11, 42, 10, 50, 1, 62, 100, 67, 56, 17, 79, 72, 75, 0, 77, 81, 95, 30, 62, 100, 57, 100, 19, 97, 9, 68, 53, 22, 99, 1, 79, 36, 21, 79, 68, 21, 86, 86, 2, 92, 26, 32, 6, 17, 60, 47, 37, 100, 100, 84, 75, 81, 75, 94, 35, 29, 61, 100, 6, 100, 83, 100, 76, 34, 13, 39, 75, 63, 46, 97, 91, 0, 100, 100, 100, 85, 28, 16, 100, 50, 55, 62, 46, 93, 100, 59, 85, 52, 75, 94, 96, 96, 27, 77, 100, 100, 97, 40, 74, 71, 44, 11, 34, 100, 100, 33, 32, 55, 100, 79, 4, 99, 85, 55, 55, 30, 3, 100, 74, 32, 43, 59, 94, 16, 100, 26, 100, 45, 68, 2, 39, 19, 0, 88, 31, 61, 1, 78, 58, 62, 65, 5, 76, 62, 24, 56, 8, 100, 99, 13, 4, 88, 36, 97, 1, 48, 98, 38, 99, 78, 79, 99, 100, 0, 0, 37, 42, 83, 85, 44, 32, 4, 0]\n",
      "58.10606060606061\n",
      "314\n"
     ]
    }
   ],
   "source": [
    "# Count how many times the source words occurs in the nbest list of original\n",
    "results = []\n",
    "counter = 0\n",
    "for word in ambiguous_words:\n",
    "    matches = 0\n",
    "    for target in nbest_original[counter]: \n",
    "        if (word in target.split(\" \")):\n",
    "            matches += 1\n",
    "    results.append(matches)  \n",
    "    counter += 1\n",
    "    \n",
    "print(results)\n",
    "print(sum(results)/330)\n",
    "print(sum(x > 0 for x in results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "94d3d860-88c4-4a08-a0ca-f8d5cca165eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63, 100, 32, 94, 1, 5, 51, 63, 100, 75, 24, 50, 48, 100, 32, 60, 84, 100, 100, 33, 1, 68, 17, 0, 8, 40, 100, 71, 100, 93, 68, 91, 68, 80, 98, 100, 72, 65, 72, 81, 1, 100, 93, 43, 80, 24, 100, 25, 97, 61, 75, 54, 0, 16, 76, 95, 27, 75, 93, 100, 96, 70, 18, 46, 83, 37, 0, 52, 2, 58, 91, 90, 43, 0, 100, 0, 65, 47, 6, 11, 1, 87, 61, 59, 0, 63, 5, 0, 4, 39, 98, 96, 80, 100, 100, 93, 100, 99, 0, 69, 69, 96, 98, 56, 11, 99, 78, 71, 52, 100, 47, 60, 52, 0, 4, 100, 78, 60, 16, 21, 88, 97, 27, 1, 1, 91, 89, 100, 92, 100, 80, 84, 93, 88, 28, 46, 95, 96, 5, 46, 51, 91, 85, 86, 100, 100, 10, 16, 97, 89, 99, 16, 100, 32, 8, 20, 76, 10, 48, 10, 44, 6, 39, 100, 71, 58, 29, 73, 74, 91, 0, 71, 72, 99, 0, 69, 100, 38, 100, 25, 100, 8, 57, 41, 37, 100, 13, 73, 47, 42, 63, 73, 17, 76, 82, 18, 95, 38, 29, 9, 19, 87, 58, 30, 99, 100, 95, 83, 82, 85, 97, 70, 8, 73, 100, 7, 100, 85, 95, 53, 36, 15, 46, 80, 57, 50, 100, 83, 1, 100, 100, 100, 79, 17, 12, 96, 63, 72, 69, 64, 94, 100, 68, 90, 60, 68, 90, 99, 99, 39, 61, 100, 100, 96, 55, 66, 74, 50, 8, 40, 99, 99, 34, 30, 66, 100, 93, 13, 97, 94, 65, 67, 50, 5, 100, 92, 23, 66, 38, 94, 15, 100, 41, 100, 57, 12, 7, 40, 3, 0, 95, 24, 43, 3, 49, 64, 72, 44, 1, 75, 77, 14, 48, 14, 100, 100, 13, 7, 95, 34, 99, 1, 100, 100, 80, 100, 63, 62, 97, 98, 1, 0, 38, 43, 94, 99, 47, 28, 15, 13]\n",
      "59.45757575757576\n",
      "317\n"
     ]
    }
   ],
   "source": [
    "# Count how many times the source words occurs in the nbest list of disambiguated\n",
    "results = []\n",
    "counter = 0\n",
    "for word in ambiguous_words:\n",
    "    matches = 0\n",
    "    for target in nbest_disambiguated[counter]: \n",
    "        if (word in target.split(\" \")):\n",
    "            matches += 1\n",
    "    results.append(matches)  \n",
    "    counter += 1\n",
    "    \n",
    "print(results)\n",
    "print(sum(results)/330)\n",
    "print(sum(x > 0 for x in results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628352f6-7bc2-4f3e-b4c9-72eddb35be6b",
   "metadata": {},
   "source": [
    "## Count unique sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e6780900-1cee-48f6-bd26-7046ef6b1076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.06060606060606\n"
     ]
    }
   ],
   "source": [
    "# Count unique sentences in source nbest list for each source sentence of original; 46.06060606060606\n",
    "unique_sent = []\n",
    "for source_nbest in nbest_original:\n",
    "    num_values = len(set(source_nbest))\n",
    "    #print(num_values)\n",
    "    unique_sent.append(num_values)\n",
    "    \n",
    "#print(unique_sent)\n",
    "print(sum(unique_sent)/330) # average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cbb3f87c-8a26-4e5b-afce-5014324f8ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.77272727272727\n"
     ]
    }
   ],
   "source": [
    "# Count unique sentences in source nbest list for each source sentence of modified; 51.77272727272727\n",
    "unique_sent = []\n",
    "for source_nbest in nbest_modified:\n",
    "    num_values = len(set(source_nbest))\n",
    "    #print(num_values)\n",
    "    unique_sent.append(num_values)\n",
    "    \n",
    "#print(unique_sent)\n",
    "print(sum(unique_sent)/330) # average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265064a1-379a-4b66-ad78-61dcd8735726",
   "metadata": {},
   "source": [
    "## Count unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e7ef2-1c50-489a-b011-8c2b530d9a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique words in source nbest list for each source sentence of original; 22.593939393939394\n",
    "import spacy\n",
    "\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "\n",
    "unique_words = []\n",
    "counter = 0\n",
    "for source_nbest in nbest_original:\n",
    "    words = set()\n",
    "    for sent in source_nbest:\n",
    "        tokens = sp(sent)\n",
    "        for token in tokens:\n",
    "            if token.text not in stopwords:    # checking whether the word is a stop word\n",
    "                words.add(token.text)\n",
    "    num_values = len(words)\n",
    "    unique_words.append(num_values)\n",
    "    \n",
    "    counter += 1\n",
    "    print(counter)\n",
    "    \n",
    "#print(unique_words)\n",
    "print(sum(unique_words)/330)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67691641-9d4a-4390-acb0-6cb693f3226a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique words in source nbest list for each source sentence of modified; 22.348484848484848\n",
    "import spacy\n",
    "\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "\n",
    "unique_words = []\n",
    "counter = 0\n",
    "for source_nbest in nbest_modified:\n",
    "    words = set()\n",
    "    for sent in source_nbest:\n",
    "        tokens = sp(sent)\n",
    "        for token in tokens:\n",
    "            if token.text not in stopwords:    # checking whether the word is a stop word\n",
    "                words.add(token.text)\n",
    "    num_values = len(words)\n",
    "    unique_words.append(num_values)\n",
    "    \n",
    "    counter += 1\n",
    "    print(counter)\n",
    "    \n",
    "#print(unique_words)\n",
    "print(sum(unique_words)/330)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a31ec1-6057-4efc-9cb5-0958d64c2bc2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Word alignement (source-translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9123d6e-caef-4b93-ae43-53cbde83624c",
   "metadata": {},
   "source": [
    "- Count how many unique ambiguous words are in total in source text\n",
    "- Extract the position of the first ambiguous word from each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "85f8a95c-7ac7-4b7b-ad4b-46b336c11aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'developer', 'laborer', 'auditor', 'receptionist', 'driver', 'undergraduate', 'secretary', 'bartender', 'dietitian', 'practitioner', 'tailor', 'salesperson', 'editor', 'carpenter', 'mechanic', 'cook', 'writer', 'housekeeper', 'advisor', 'therapist', 'analyst', 'baker', 'guard', 'teenager', 'janitor', 'mover', 'accountant', 'physician', 'painter', 'hairdresser', 'librarian', 'examiner', 'broker', 'firefighter', 'cleaner', 'worker', 'specialist', 'assistant', 'patient', 'chief', 'programmer', 'manager', 'clerk', 'lawyer', 'CEO', 'farmer', 'counselor', 'scientist', 'supervisor', 'attendant', 'sheriff', 'customer', 'nurse'}\n",
      "53\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 6, 1, 4, 1, 1, 1, 1, 1, 3, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "330\n"
     ]
    }
   ],
   "source": [
    "# List with source words\n",
    "words = set() # set forces uniqueness\n",
    "with open('words.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        words.add(line.strip())\n",
    "        \n",
    "ambiguous_words = set() # set forces uniqueness\n",
    "positions_ambiguous_words = []\n",
    "\n",
    "with open('tok.en_original.en', 'r') as fin:\n",
    "    for line in fin:\n",
    "        tokens = line.split(' ')\n",
    "        for token in tokens:\n",
    "            if token in words:\n",
    "                ambiguous_words.add(token)\n",
    "                position = tokens.index(token)\n",
    "                positions_ambiguous_words.append(position)\n",
    "                break\n",
    "        \n",
    "print(ambiguous_words)\n",
    "print(len(ambiguous_words))\n",
    "print(positions_ambiguous_words)\n",
    "print(len(positions_ambiguous_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26f2bbb-6aa4-47fa-89bd-3855b164c388",
   "metadata": {},
   "source": [
    "- Input to fast_align must be tokenized and aligned into parallel sentences. \n",
    "- Line is a source language sentence and its target language translation, separated by a triple pipe symbol with leading and trailing white space (|||)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "f69765e4-f622-46fa-b68b-06fb80f11f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330\n",
      "330\n"
     ]
    }
   ],
   "source": [
    "# List with original source sentences\n",
    "source = []\n",
    "with open('tok.en_original.en', 'r') as fin:\n",
    "    for line in fin:\n",
    "        source.append(line.strip())\n",
    "         \n",
    "# List with nbest sentences for every source in original \n",
    "nbest_original = []\n",
    "counter = 0\n",
    "temp = []\n",
    "with open('hyp_original.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        temp.append(line.strip())\n",
    "        counter += 1\n",
    "        if (counter == 10):\n",
    "            nbest_original.append(temp)\n",
    "            counter = 0\n",
    "            temp = []\n",
    "\n",
    "print(len(source))\n",
    "print(len(nbest_original))           \n",
    "        \n",
    "count = 0\n",
    "with open('original_source-target_en-de.txt', 'w') as fout:\n",
    "    while count < 330:\n",
    "        for hyp in nbest_original[count]:\n",
    "            print(source[count] + ' ||| ' + hyp, end='\\n', file=fout)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "58ac58b0-41db-444a-a187-dc4266a09551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330\n",
      "330\n"
     ]
    }
   ],
   "source": [
    "# List with disambiguated source sentences\n",
    "source = []\n",
    "with open('tok.en_disambiguated.en', 'r') as fin:\n",
    "    for line in fin:\n",
    "        source.append(line.strip())\n",
    "         \n",
    "# List with nbest sentences for every source in original \n",
    "nbest_disambiguated = []\n",
    "counter = 0\n",
    "temp = []\n",
    "with open('hyp_disambiguated.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        temp.append(line.strip())\n",
    "        counter += 1\n",
    "        if (counter == 10):\n",
    "            nbest_disambiguated.append(temp)\n",
    "            counter = 0\n",
    "            temp = []\n",
    "\n",
    "print(len(source))\n",
    "print(len(nbest_disambiguated))           \n",
    "        \n",
    "count = 0\n",
    "with open('disambiguated_source-target_en-de.txt', 'w') as fout:\n",
    "    while count < 330:\n",
    "        for hyp in nbest_disambiguated[count]:\n",
    "            print(source[count] + ' ||| ' + hyp, end='\\n', file=fout)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95e0a48-e74f-468a-b949-a9cc13a2a519",
   "metadata": {
    "tags": []
   },
   "source": [
    "## fast_align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1477d44-1efd-4dda-8549-8b29c438e408",
   "metadata": {},
   "outputs": [],
   "source": [
    "!$FAST_ALIGN -i original_source-target_en-de.txt -d -o -v > original_source-target_en-de_fast-aligned.txt\n",
    "!$FAST_ALIGN -i disambiguated_source-target_en-de.txt -d -o -v > disambiguated_source-target_en-de_fast-aligned.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "2c4ce87a-7b1d-4a97-b4d9-c446de1df198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329\n",
      "2.4711246200607904\n"
     ]
    }
   ],
   "source": [
    "# Extract target translated words to source words in original\n",
    "\n",
    "import re\n",
    "\n",
    "# List with original translations\n",
    "translations_original = []\n",
    "with open('hyp_original.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        translations_original.append(line.strip())\n",
    "\n",
    "              \n",
    "lineNumber = 0\n",
    "counter = 0\n",
    "indices = []\n",
    "with open('original_source-target_en-de_fast-aligned.txt', 'r') as alignments:\n",
    "    for line in alignments:\n",
    "        if (lineNumber == 10):\n",
    "            lineNumber = 0\n",
    "            counter += 1\n",
    "        position = positions_ambiguous_words[counter] # exact position of ambiguous word\n",
    "        regex = r\"\" + str(position) + r\"-(\\d)\"\n",
    "        if re.search(regex, line): \n",
    "            indices.append(int(re.search(regex, line).group(1)))\n",
    "        else:\n",
    "            indices.append(999)\n",
    "        lineNumber += 1\n",
    "        \n",
    "#print(len(indices))\n",
    "#print(indices)\n",
    "\n",
    "lineNumber = 0\n",
    "translations_ambiguous_words = [] # a list of set of translations to each ambiguous word in source\n",
    "translated_ambiguous_words = set() # set forces uniqueness\n",
    "for translation in translations_original:\n",
    "    if (lineNumber == 10):\n",
    "            lineNumber = 0\n",
    "            translations_ambiguous_words.append(translated_ambiguous_words)\n",
    "            translated_ambiguous_words = set()\n",
    "    tokens = translation.split(' ')\n",
    "    translation_index = translations_original.index(translation)\n",
    "    if indices[translation_index] != 999:\n",
    "        translated_ambiguous_words.add(tokens[indices[translation_index]])\n",
    "    lineNumber += 1\n",
    "    \n",
    "#print(translations_ambiguous_words)\n",
    "print(len(translations_ambiguous_words))\n",
    "\n",
    "unique_translations = 0\n",
    "for set_words in translations_ambiguous_words:\n",
    "    unique_translations += len(set_words)\n",
    "print(unique_translations/329)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "89ac1e4c-277c-4d1c-a336-409f6c777e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "329\n",
      "2.188449848024316\n"
     ]
    }
   ],
   "source": [
    "# Extract target translated words to source words in disambiguated\n",
    "\n",
    "import re\n",
    "\n",
    "# List with original translations\n",
    "translations_disambiguated = []\n",
    "with open('hyp_disambiguated.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        translations_disambiguated.append(line.strip())\n",
    "\n",
    "              \n",
    "lineNumber = 0\n",
    "counter = 0\n",
    "indices = []\n",
    "with open('disambiguated_source-target_en-de_fast-aligned.txt', 'r') as alignments:\n",
    "    for line in alignments:\n",
    "        if (lineNumber == 10):\n",
    "            lineNumber = 0\n",
    "            counter += 1\n",
    "        position = positions_ambiguous_words[counter] + 1 # exact position of ambiguous word; !!! add 1 because of gender word\n",
    "        regex = r\"\" + str(position) + r\"-(\\d)\"\n",
    "        if re.search(regex, line): \n",
    "            indices.append(int(re.search(regex, line).group(1)))\n",
    "        else:\n",
    "            indices.append(999)\n",
    "        lineNumber += 1\n",
    "        \n",
    "#print(len(indices))\n",
    "#print(indices)\n",
    "\n",
    "lineNumber = 0\n",
    "translations_ambiguous_words = [] # a list of set of translations to each ambiguous word in source\n",
    "translated_ambiguous_words = set() # set forces uniqueness\n",
    "for translation in translations_disambiguated:\n",
    "    if (lineNumber == 10):\n",
    "            lineNumber = 0\n",
    "            translations_ambiguous_words.append(translated_ambiguous_words)\n",
    "            translated_ambiguous_words = set()\n",
    "    tokens = translation.split(' ')\n",
    "    translation_index = translations_disambiguated.index(translation)\n",
    "    if indices[translation_index] != 999:\n",
    "        translated_ambiguous_words.add(tokens[indices[translation_index]])\n",
    "    lineNumber += 1\n",
    "    \n",
    "#print(translations_ambiguous_words)\n",
    "print(len(translations_ambiguous_words))\n",
    "\n",
    "unique_translations = 0\n",
    "for set_words in translations_ambiguous_words:\n",
    "    unique_translations += len(set_words)\n",
    "print(unique_translations/329)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7547be75-dfc4-46c3-ba3f-dfe56c4a3037",
   "metadata": {},
   "source": [
    "## awesome_align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7e5d0cfa-eb33-4a71-af0c-9fa94a473c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████████████████████████| 625/625 [00:00<00:00, 656kB/s]\n",
      "Downloading: 100%|███████████████████████████| 996k/996k [00:00<00:00, 1.31MB/s]\n",
      "Downloading: 100%|███████████████████████████| 714M/714M [02:13<00:00, 5.34MB/s]\n",
      "Loading the dataset...\n",
      "Extracting: 3300it [00:17, 192.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# ??? How to set model correctly\n",
    "# MODELS=\"/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble\"\n",
    "!awesome-align \\\n",
    "    --output_file \"original_source-target_en-de_awesome-aligned.txt\" \\\n",
    "    --data_file \"original_source-target_en-de.txt\" \\\n",
    "    --model_name_or_path bert-base-multilingual-cased \\\n",
    "    --extraction 'softmax' \\\n",
    "    --batch_size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9858f351-847d-4b0f-84ff-dde0dddfda7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dataset...\n",
      "Extracting: 3300it [00:06, 513.55it/s]\n"
     ]
    }
   ],
   "source": [
    "!awesome-align \\\n",
    "    --output_file \"disambiguated_source-target_en-de_awesome-aligned.txt\" \\\n",
    "    --data_file \"disambiguated_source-target_en-de.txt\" \\\n",
    "    --model_name_or_path bert-base-multilingual-cased \\\n",
    "    --extraction 'softmax' \\\n",
    "    --batch_size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "67dbd476-e0aa-4748-aac9-7fa91247661d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Entwickler', 'Bauunternehmer', 'Bauträger'}, {'Mechaniker'}, {'Umzugshelfer', 'Macher', 'Umzugsteilnehmer', 'Mover'}, {'Assistentin', 'Assistent'}, {'Chefin', 'Chef', 'Verwaltungschef', 'Häuptling'}, {'Verkäufer', 'Verkäuferin'}, {'Anwältin', 'Rechtsanwalt', 'Anwalt', 'Jurist', 'Rechtsanwältin'}, {'Koch', 'Köchin'}, {'Beweger', 'Umzugshelfer', 'Mover'}, {'Bauer', 'Landwirt', 'Bäuerin'}, {'Vorstandsvorsitzende', 'Chef', 'Vorstandschef', 'CEO', 'Geschäftsführerin', 'Firmenchef', 'Geschäftsführer'}, {'Frisör', 'Friseur', 'Friseurin'}, {'Bauunternehmerin', 'Bauträger', 'Bauherr', 'Entwickler', 'Bauunternehmer'}, {'Fahrer'}, {'Rechnungsprüfer', 'Prüfer', 'Wirtschaftsprüfer'}, {'Vorstandsvorsitzende', 'CEO', 'Geschäftsführer'}, {'Wärter', 'Wachmann', 'Wache'}, {'des', 'Assistent'}, {'des', 'Assistent'}, {'Rechnungsprüfer', 'Prüfer', 'Revisor', 'Kassenprüfer', 'Wirtschaftsprüfer'}, {'Verkäufer', 'Verkäuferin'}, {'Chef', 'Manager', 'Geschäftsführer'}, {'Arzt'}, {'Arbeiterin', 'Angestellte', 'Arbeiter'}, {'Ärztin', 'Arzt', 'Mediziner'}, {'Frisör', 'Friseur', 'Friseurin'}, {'Entwickler', 'Bauunternehmer'}, {'Bauer', 'Landwirt'}, {'Rezeptionistin', 'Rezeptionist', 'Empfangsdame', 'Empfangschef'}, {'Manager'}, {'Putzfrau', 'Putzmann', 'Reinigungskraft', 'Reiniger', 'Putzer'}, {'Mechaniker'}, {'Autor', 'Autorin', 'Schriftsteller'}, {'Bauarbeiter'}, {'Redaktion', 'Redakteur', 'Redakteurin', 'Herausgeber'}, {'Analytiker', 'Analyst'}, {'Tischler', 'Schreiner'}, {'Koch', 'Köchin'}, {'Tischler', 'Schreiner'}, {'Putzfrau', 'Putzmann', 'Reinigungskraft', 'Reiniger'}, {'Arbeiter'}, {'Mechaniker'}, {'Mechaniker'}, {'Koch', 'Köchin'}, {'Bauer', 'Landwirt'}, {'Vorstandsvorsitzende', 'Vorstandschef', 'Konzernchef', 'CEO', 'Firmenchef', 'Geschäftsführer'}, {'Bibliothekarin', 'Bibliothekar'}, {'Chefin', 'Chef', 'Häuptling'}, {'Entwickler'}, {'Krankenschwester'}, {'Anwalt'}, {'Entwickler', 'Bauunternehmer', 'Bauträger'}, {'Umzugshelfer', 'Zugführer', 'Macher', 'Fahrer', 'Umzugsteilnehmer', 'Mann', 'Täter'}, {'Assistenten', 'Zugführer', 'Autofahrer', 'Fahrer', 'Fahrerin'}, {'Bauarbeiterin', 'Bauarbeiter'}, {'Sekretär', 'Sekretärin'}, {'Vorstandsvorsitzende', 'Konzernchef', 'CEO', 'Firmenchef', 'Geschäftsführer'}, {'Tischler', 'Buchhalter', 'Schreiner'}, {'Sheriff'}, {'Mechaniker'}, {'Analytiker', 'Analyst'}, {'Assistentin', 'Mitarbeiterin', 'Mitarbeiter', 'Assistent'}, {'Chef', 'Leiter', 'Chefin', 'Verwaltungschef', 'Leiterin', 'Vorsitzende'}, {'Hausmeister'}, {'Manager', 'Verwalter', 'Geschäftsführer'}, {'Kontrolleur', 'Aufsicht', 'Vorgesetzte', 'Aufseher', 'Aufsichtsperson', 'Betreuer'}, {'Chef'}, {'Bauarbeiterin', 'Bauarbeiter'}, {'Verkäufer', 'Verkäuferin'}, {'Anwältin', 'Rechtsanwalt', 'Anwalt'}, {'Entwickler', 'Bauunternehmer'}, {'Sheriff'}, {'Hausverwalter', 'Hausmeister', 'Hausmeisterin'}, {'Arbeiter'}, {'Fahrer'}, {'Umzugshelfer', 'Mover'}, {'Entwickler', 'Bauunternehmer'}, {'Hausmeister'}, {'Verkäufer', 'Kassiererin', 'Verkäuferin'}, {'Chef', 'Chefin'}, {'Arbeiter'}, {'Wärter', 'Wächter', 'Wachmann', 'Wache'}, {'Schwester', 'Pflegerin'}, {'Bauarbeiter'}, {'Redakteur', 'Arbeiter'}, {'Rechtsanwalt', 'Anwalt', 'Jurist'}, {'Vorstandsvorsitzende', 'Vorsitzende', 'Geschäftsführer'}, {'Helfer', 'Hilfsarbeiter', 'Arbeiter'}, {'Helfer', 'Assistenten', 'Arbeiter'}, {'Pflegerin', 'Pfleger', 'Krankenschwester'}, {'Manager', 'Geschäftsführer'}, {'Wachmann', 'Wache'}, {'Entwickler', 'Bauunternehmer', 'Bauträger'}, {'Fahrer', 'Autofahrer'}, {'Manager'}, {'Bauer', 'Landwirt'}, {'Analytiker', 'Analyst', 'Analytikerin'}, {'Supervisor', 'Aufsichtsperson', 'Vorgesetzte'}, {'Arbeiter'}, {'Tischler', 'Schreiner'}, {'Bauarbeiter'}, {'Manager'}, {'Bauer', 'Landwirt'}, {'CEO', 'Vorstandsvorsitzende', 'Geschäftsführer'}, {'Verkäufer', 'Buchhalter', 'Verkäuferin'}, {'Fahrer'}, {'Bauarbeiter'}, {'Aufseher', 'Betreuer', 'Aufsicht', 'Vorgesetzte'}, {'Rechtsanwalt', 'Anwalt', 'Jurist'}, {'Analyst'}, {'Aufseher', 'Vorgesetzte', 'Betreuerin'}, {'Bauarbeiter'}, {'Vorstandsvorsitzende', 'Vorstandschef', 'CEO', 'Konzernchef', 'Firmenchef', 'Geschäftsführer'}, {'Geschäftsführer'}, {'Verkäufer', 'Verkäuferin'}, {'Fahrer'}, {'Bauer', 'Landwirt'}, {'Wachmann', 'Garde', 'Wächter', 'Wärterin', 'Wärter', 'Wache'}, {'Vorstandsvorsitzende', 'Firmenchef', 'Geschäftsführer'}, {'Ärztin', 'Arzt', 'Mediziner'}, {'Manager', 'Geschäftsführer'}, {'Analytiker', 'Analyst', 'Analysten'}, {'Umzugshelfer', 'Umzugsunternehmer', 'Mover'}, {'Vorstandsvorsitzende', 'Geschäftsführer'}, {'Hilfsarbeiter', 'Arbeiterin', 'Arbeiter'}, {'Bauer', 'Landwirt'}, {'Sheriff'}, {'Analyst'}, {'Wachmann', 'Wächter', 'Wärterin', 'Wärter', 'Wache'}, {'Mechaniker'}, {'Tischler', 'Zimmermann', 'Zimmerer', 'Schreiner', 'Friseurs'}, {'Sheriff'}, {'Managerin', 'Manager'}, {'Sheriff'}, {'Koch', 'Köchin'}, {'Umzugshelfer', 'Umzugsunternehmer', 'Macher', 'Täter', 'Umzugsspezialist'}, {'Analytiker', 'Analyst'}, {'Sheriff'}, {'Verkäufer', 'Verkäuferin'}, {'Vorstandsvorsitzende', 'CEO', 'Geschäftsführer'}, {'Hausmeister'}, {'Aufsichtsbeamte', 'Kontrolleur', 'Vorgesetzten', 'Vorgesetzte', 'Aufseher'}, {'Entwickler'}, {'Wärter', 'Wachmann', 'Wache'}, {'Fahrer'}, {'Fahrer'}, {'Chef', 'Schulleiter'}, {'Ärztin', 'Arzt'}, {'Sheriff'}, {'Mechaniker'}, {'Bauunternehmer', 'Bauträger'}, {'Ärztin', 'Arzt'}, {'Mechaniker'}, {'Beweger', 'Kläger', 'Antragsteller', 'Beschwerdeführer', 'Macher'}, {'Chef'}, {'Arzt', 'Ärztin'}, {'Bauer', 'Landwirt', 'Bäuerin'}, {'Verkäufer', 'Verkäuferin'}, {'Hausmeister'}, {'Chefin', 'Chef', 'Leiter'}, {'Anwältin', 'Rechtsanwalt', 'Anwalt'}, {'Planer', 'Arbeiter', 'Entwerfer'}, {'Koch', 'Köchin'}, {'Analytiker', 'Analyst', 'Analystin'}, {'Wachmann', 'Garde', 'Wächter', 'Gardist', 'Wärter', 'Wache'}, {'Anwältin', 'Juristin', 'Rechtsanwalt', 'Anwalt', 'Jurist'}, {'Vorstandsvorsitzende', 'Chef', 'Vorstandsvorsitzenden', 'CEO', 'Firmenchef', 'Geschäftsführer'}, {'Tischler', 'Schreiner'}, {'Anwältin', 'Rechtsanwalt', 'Anwalt', 'Jurist'}, {'Managerin', 'Verwalter', 'Manager', 'Verwalterin', 'Geschäftsführer'}, {'Täter'}, {'Bauer', 'Landwirt'}, {'Bauer', 'Landwirt'}, {'Wärter', 'Wachmann', 'Wache'}, {'Umzugshelfer', 'Mover', 'Umzugsunternehmer', 'Macher', 'Fahrer'}, {'Wärter', 'Wächter', 'Wachmann', 'Wache'}, {'Analytiker', 'Analyst'}, {'Koch', 'Köchin'}, {'Fahrer'}, {'Vorstandsvorsitzende', 'Konzernchef', 'Vorstandsvorsitzenden', 'Geschäftsführer'}, {'Fahrerin', 'Fahrer', 'Autofahrer'}, {'Verkäufer', 'Verkäuferin'}, {'Koch', 'Köchin'}, {'Anwältin', 'Rechtsanwalt', 'Anwalt', 'Jurist'}, {'Vorstandsvorsitzende', 'Chef', 'Vorstandschef', 'Konzernchef', 'CEO', 'Geschäftsführerin', 'Firmenchef', 'Geschäftsführer'}, {'Mechaniker'}, {'Arzt'}, {'Tischler', 'Schreiner'}, {'Betreuerin', 'Vorgesetzte', 'Aufseher', 'Aufsichtsperson', 'Betreuer'}, {'Hausmeister'}, {'Anwältin', 'Anwalt'}, {'Bauarbeiter'}, {'Begleiterin', 'Fahrdienstleiter', 'Betreuerin', 'Begleiter', 'Zugbegleiterin', 'Zugbegleiter'}, {'Tischler', 'Schreiner'}, {'Tischler', 'Schreiner'}, {'Ärztin', 'Arzt', 'Mediziner'}, {'Sheriff'}, {'Hausmeister'}, {'Hausmeister'}, {'Verkäufer', 'Verkäuferin'}, {'Betreuerin', 'Beraterin', 'Berater', 'Ratgeber', 'Betreuer'}, {'Sekretär', 'Sekretärin'}, {'Aufseher', 'Vorgesetzte'}, {'Chefin', 'Chef', 'Häuptling', 'Oberhaupt'}, {'Wärter', 'Wachmann', 'Wache'}, {'Sheriff'}, {'Mechaniker', 'Monteur', 'Mechanikerin'}, {'Putzfrau', 'Putzmann', 'Reinigungskraft'}, {'Sheriff'}, {'Putzfrau', 'Putzmann', 'Reinigungskraft'}, {'Bäcker'}, {'Entwickler', 'Bauunternehmer', 'Bauträger'}, {'Sachbearbeiterin', 'Büroangestellte', 'Angestellte', 'Sachbearbeiter', 'Beamte'}, {'Bauarbeiterin', 'Bauarbeiter'}, {'Rezeptionistin', 'Rezeptionist', 'Empfangsdame'}, {'Verkäufer', 'Verkäuferin'}, {'Rezeptionistin', 'Empfangsdame'}, {'Buchhalterin', 'Buchhalter', 'Steuerberater'}, {'Manager'}, {'Koch', 'Köchin'}, {'Vorgesetzte', 'Betreuerin'}, {'Chef', 'Vorsitzende'}, {'Supervisor', 'Bauleiter', 'Betreuerin', 'Vorgesetzte', 'Aufseher', 'Aufsichtsperson', 'Betreuer'}, {'Sekretär', 'Sekretärin'}, {'Rechtsanwalt', 'Anwalt'}, {'Auditor', 'Prüferin', 'Rechnungsprüfer', 'Prüfer', 'Revisor', 'Wirtschaftsprüfer', 'Rechnungshof', 'Wirtschaftsprüferin'}, {'Analytiker', 'Analyst', 'Analytikerin'}, {'Wärter', 'Wachmann', 'Wache'}, {'Arbeiterin', 'Arbeiter'}, {'Analytiker', 'Analyst'}, {'Rezeptionistin', 'Rezeptionist', 'Empfangsdame'}, {'Rezeptionistin', 'Rezeptionist', 'Empfangsdame'}, {'Supervisor', 'Betreuerin', 'Vorgesetzte', 'Betreuer', 'Supervisorin'}, {'Beamte', 'Angestellte', 'Sachbearbeiter', 'Sachbearbeiterin'}, {'Chef', 'Leiter', 'Chefin', 'Oberhaupt', 'Leiterin', 'Vorsitzende'}, {'Analyst'}, {'Bauarbeiter'}, {'Wachmann', 'Garde', 'Wächter', 'Wärterin', 'Wärter', 'Wache'}, {'Wachmann', 'Wächter', 'Wärterin', 'Wärter', 'Aufseher', 'Wache'}, {'Entwickler', 'Bauunternehmer', 'Bauträger', 'Bauherr'}, {'Manager', 'Geschäftsführer'}, {'Mechaniker'}, {'Aufsicht', 'Supervisor', 'Betreuerin', 'Vorgesetzte', 'Aufseher', 'Aufsichtsperson', 'Betreuer'}, {'Haushälterin', 'Hauswirtschafterin', 'Hausfrau'}, {'Supervisor', 'Betreuerin', 'Vorgesetzte', 'Aufseher', 'Betreuer'}, {'Tischler', 'Kassierer', 'Kassiererin', 'Zimmerer', 'Schreiner'}, {'Mechaniker', 'Monteur', 'Mechanikerin'}, {'Bauer', 'Landwirt'}, {'Bauer', 'Landwirt'}, {'Hausmeister', 'Bäcker'}, {'Koch', 'Köchin'}, {'Fahrer', 'Busfahrer'}, {'Mechaniker', '.'}, {'Mechaniker'}, {'Beweger', 'Macher', 'Umzugshelfer', 'Mover'}, {'Tischler', 'Zimmermann', 'Zimmerer', 'Schreiner'}, {'Bauarbeiter'}, {'Supervisor', 'Aufseher', 'Vorgesetzte'}, {'Chef', 'Chefin'}, {'Hausmeister'}, {'Analytiker', 'Analyst', 'Analytikerin', 'Analystin'}, {'Sheriff'}, {'Hausmeister'}, {'Beweger', 'Maschine', 'Mover', 'Zugführer', 'Umzugswagen', 'Macher', 'Fahrer', 'Täter'}, {'Entwickler', 'Bauunternehmer', 'Bauherr', 'Bauträger'}, {'Mechaniker'}, {'Herausgeber', 'Redakteur', 'Redakteurin'}, {'Anwältin', 'Verteidiger', 'Betreuerin', 'Verteidigerin', 'Berater', 'Beraterin', 'Anwalt'}, {'Schneider'}, {'Bauer', 'Landwirt'}, {'Betreuerin', 'Vorgesetzte', 'Aufseher', 'Aufsichtsperson', 'Betreuer'}, {'Manager', 'Verwalter', 'Geschäftsführer', 'Direktor'}, {'Beweger', 'Umzugshelfer', 'Mover', 'Krankenschwester', 'Macher'}, {'Arbeiter'}, {'Haushälterin'}, {'Bäckerin', 'Bäcker'}, {'Betreuerin', 'Betreuer', 'Begleiter', 'Begleiterin'}, {'Autor', 'Schriftstellerin', 'Autorin', 'Schriftsteller'}, {'Koch', 'Köchin'}, {'Analytiker', 'Analyst', 'Analytikerin', 'Analystin'}, {'Ärztin', 'Arzt', 'Mediziner'}, {'Fahrer'}, {'Macher', 'Fahrer', 'Beförderer', 'Mover'}, {'Fahrer'}, {'Bauunternehmer', 'Bauträger'}, {'Chef'}, {'Ärztin', 'Arzt'}, {'Hausmeister'}, {'Anführer', 'Chef', 'Zugführer', 'Leiter'}, {'Arbeiter'}, {'Sheriff'}, {'Chefredakteur', 'Chef'}, {'Koch'}, {'Verkäufer', 'Verkäuferin'}, {'Rechtsanwalt', 'Anwalt'}, {'Bauer'}, {'Putzfrau', 'Reinigungskraft'}, {'Koch', 'Putzfrau', 'Köchin'}, {'Arbeiterin', 'Arbeiter'}, {'Putzfrau', 'Putzmann', 'Reinigungskraft', 'Reiniger', 'Putzer'}, {'Kunde'}, {'Manager', 'Geschäftsführer'}, {'Jugendliche', 'Teenager'}, {'Therapeuten', 'Therapeutin'}, {'Bibliothekarin', 'Bibliothekar'}, {'Bibliothekarin', 'Bibliothekar'}, {'Beraterin', 'Berater'}, {'Beraterin', 'Berater'}, {'Kundin', 'Kunde'}, {'Barkeeper'}, {'Patientin', 'Patient'}, {'Spezialisten', 'Facharzt', 'Fachmann'}, {'Arzt', 'Praktizierende'}, {'Praktizierende'}, {'Ermittler', 'Gutachter', 'Prüfer'}, {'Prüfer'}, {'Frisör', 'Friseur', 'Friseurin'}, {'Frisör', 'Friseur', 'Friseurin'}, {'Programmierer'}, {'Programmierer'}, {'Studentin', 'Student'}, {'Wissenschaftler'}, {'Diätassistentin', 'Ernährungsberaterin'}, {'Diätassistentin', 'Ernährungsberaterin', 'Ernährungsberater'}, {'Maler'}, {'Maler'}, {'Broker', 'Makler'}, {'Broker', 'Makler', 'Maklerin', 'Vermittler'}, {'Feuerwehrleute', '.', 'Feuerwehr', 'Feuerwehrmann'}]\n",
      "2.574468085106383\n"
     ]
    }
   ],
   "source": [
    "# Extract target translated words to source words in original\n",
    "\n",
    "import re\n",
    "\n",
    "# List with original translations\n",
    "translations_original = []\n",
    "with open('hyp_original.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        translations_original.append(line.strip())\n",
    "\n",
    "              \n",
    "lineNumber = 0\n",
    "counter = 0\n",
    "indices = []\n",
    "with open('original_source-target_en-de_awesome-aligned.txt', 'r') as alignments:\n",
    "    for line in alignments:\n",
    "        if (lineNumber == 10):\n",
    "            lineNumber = 0\n",
    "            counter += 1\n",
    "        position = positions_ambiguous_words[counter] # exact position of ambiguous word\n",
    "        regex = r\"\" + str(position) + r\"-(\\d)\"\n",
    "        if re.search(regex, line): \n",
    "            indices.append(int(re.search(regex, line).group(1)))\n",
    "        else:\n",
    "            indices.append(999)\n",
    "        lineNumber += 1\n",
    "        \n",
    "#print(len(indices))\n",
    "#print(indices)\n",
    "\n",
    "lineNumber = 0\n",
    "translations_ambiguous_words = [] # a list of set of translations to each ambiguous word in source\n",
    "translated_ambiguous_words = set() # set forces uniqueness\n",
    "for translation in translations_original:\n",
    "    if (lineNumber == 10):\n",
    "            lineNumber = 0\n",
    "            translations_ambiguous_words.append(translated_ambiguous_words)\n",
    "            translated_ambiguous_words = set()\n",
    "    tokens = translation.split(' ')\n",
    "    translation_index = translations_original.index(translation)\n",
    "    if indices[translation_index] != 999:\n",
    "        translated_ambiguous_words.add(tokens[indices[translation_index]])\n",
    "    lineNumber += 1\n",
    "    \n",
    "#print(translations_ambiguous_words)\n",
    "print(translations_ambiguous_words)\n",
    "\n",
    "unique_translations = 0\n",
    "for set_words in translations_ambiguous_words:\n",
    "    unique_translations += len(set_words)\n",
    "print(unique_translations/329)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "4a1b191a-081d-4984-bdde-aae7f5b0808a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add results to file\n",
    "\n",
    "# List with original source sentences\n",
    "source = []\n",
    "with open('tok.en_original.en', 'r') as fin:\n",
    "    for line in fin:\n",
    "        source.append(line.strip())\n",
    "        \n",
    "ambiguous_words = []\n",
    "with open('tok.en_original.en', 'r') as fin:\n",
    "    for line in fin:\n",
    "        tokens = line.split(' ')\n",
    "        for token in tokens:\n",
    "            if token in words:\n",
    "                ambiguous_words.append(token)\n",
    "                break\n",
    "\n",
    "count = 0                \n",
    "with open('unique-words_translations_original.txt', 'w') as fout:\n",
    "    while count < 329:\n",
    "        print(source[count] + ' | ' + ambiguous_words[count] + ' | ' + str(translations_ambiguous_words[count]), end='\\n', file=fout)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "50ce4d32-09d2-426c-b1b0-33be3fa37c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Entwickler', 'Bauunternehmer'}, {'Mechaniker'}, {'Beweger', 'Umzugshelfer', 'Mover'}, {'Assistentin', 'Assistent'}, {'Chef', 'Chefin'}, {'Verkäufer', 'Verkäuferin'}, {'Anwältin', 'Mann', 'Rechtsanwalt', 'Anwalt', 'Jurist'}, {'Koch', 'Köchin'}, {'Beweger', 'Mover'}, {'Bauer', 'Landwirt'}, {'CEO', 'Vorstandsvorsitzende', 'Geschäftsführer'}, {'Friseur', 'Friseurin'}, {'Entwicklerin', 'Bauunternehmerin', 'Bauträger', 'Entwickler', 'Bauunternehmer'}, {'Fahrer'}, {'Auditor', 'Entwickler', 'Prüfer', 'Wirtschaftsprüfer'}, {'CEO', 'Geschäftsführer'}, {'Wärter', 'Wachmann', 'Garde', 'Wache'}, {'des', 'einer'}, {'des', 'einer'}, {'Revisor', 'Wachmann', 'Kassenprüfer', 'Prüfer'}, {'Verkäufer', 'Verkäuferin'}, {'Manager', 'Geschäftsführer'}, {'Arzt'}, {'Friseur', 'Arbeiter'}, {'Ärztin', 'Arzt'}, {'Frisör', 'Friseur', 'Friseurin'}, {'Entwickler'}, {'Bauer', 'Landwirt'}, {'Rezeptionistin', 'Empfangschef', 'Rezeptionist', 'Empfangsdame'}, {'Manager'}, {'Putzkraft', 'Putzfrau', 'Putzmann', 'Reinigungskraft', 'Reiniger', 'Putzer'}, {'Mechaniker'}, {'Autor', 'Autorin', 'Schriftsteller', 'Verfasser'}, {'Bauarbeiter'}, {'Herausgeber', 'Redakteur', 'Redakteurin'}, {'Analytiker', 'Analyst', 'Analytikerin'}, {'Tischler', 'Schreiner'}, {'Koch', 'Köchin'}, {'Tischler', 'Sachbearbeiter', 'Schreiner'}, {'Putzmann', 'Wachmann', 'Reinigungskraft', 'Putzfrau'}, {'Angestellte', 'Arbeiter'}, {'Mechaniker'}, {'Mechaniker'}, {'Koch'}, {'Bauer'}, {'Vorstandsvorsitzende', 'CEO', 'Konzernchef', 'Firmenchef', 'Geschäftsführer'}, {'Bibliothekarin', 'Bibliothekar'}, {'Chef', 'Häuptling', 'Oberhaupt'}, {'Entwickler'}, {'Krankenpfleger', 'Krankenschwester', 'Pfleger'}, {'Anwalt'}, {'Entwickler', 'Bauunternehmer', 'Bauträger', 'Entwicklerin'}, {'Kassierer', 'Kassiererin', 'Kassier', 'Mann', 'Täter'}, {'Beweger', 'Mover', 'Zugführer', 'Fahrer', 'Fahrerin', 'Assistenten', 'Täter'}, {'Bauarbeiterin', 'Bauarbeiter'}, {'Sekretärin', 'Sekretär', 'männliche'}, {'CEO', 'Vorstandsvorsitzende', 'Geschäftsführer'}, {'Tischler', 'Buchhalter', 'Tischlermeister'}, {'Sheriff'}, {'Mechaniker'}, {'Analytiker', 'Analyst', 'Analytikerin'}, {'Helfer', 'Assistentin', 'Mitarbeiter', 'Assistent'}, {'Chef', 'Chefin', 'Leiter', 'Verwaltungschef', 'Männerchef'}, {'Hausmeister'}, {'Manager', 'Geschäftsführer'}, {'Aufseher', 'Aufsichtsperson', 'Kontrolleur', 'Vorgesetzte'}, {'Chef', 'männliche'}, {'Bauarbeiter'}, {'Verkäufer', 'Angestellten', 'Verkäuferin'}, {'Rechtsanwalt', 'Anwalt'}, {'männliche'}, {'Sheriff'}, {'Hausmeister'}, {'männlichen', 'männliche'}, {'Fahrerin', 'Fahrer'}, {'Putzfrau', 'Umzugshelfer', 'Mann'}, {'Entwickler', 'Bauunternehmer'}, {'Hausmeister'}, {'Verkäufer', 'Kassiererin', 'Verkäuferin'}, {'Chef', 'Leiter'}, {'Arbeiter'}, {'Wachmann', 'Garde', 'Wache'}, {'Pfleger'}, {'Bauarbeiter'}, {'Redakteur', 'Arbeiter'}, {'Rechtsanwalt', 'Anwalt'}, {'Vorstandsvorsitzende', 'Geschäftsführer'}, {'Helfer', 'Assistenten', 'Hilfsarbeiter', 'Arbeiter'}, {'Gehilfen', 'Assistenten', 'Arbeiter', 'Helfer'}, {'Krankenpfleger', 'Pflegerin', 'Pfleger', 'Krankenschwester'}, {'Manager', 'Geschäftsführer'}, {'Wachmann', 'Wache'}, {'Entwickler', 'Bauunternehmer'}, {'Fahrer'}, {'männliche'}, {'Bauer', 'Landwirt'}, {'Analytiker'}, {'Supervisor', 'Vorgesetzte'}, {'Arbeiter'}, {'Tischler', 'Schreiner'}, {'Bauarbeiter'}, {'Manager', 'männliche', '.'}, {'Bauer', 'Landwirt'}, {'Vorstandsvorsitzende', 'CEO', 'Geschäftsführer'}, {'Verkäufer', 'Verkäuferin'}, {'Fahrerin', 'Fahrer'}, {'Bauarbeiterin', 'Bauarbeiter'}, {'Aufseher', 'Aufsichtsperson', 'Vorgesetzte'}, {'Rechtsanwalt', 'Anwalt'}, {'Analytiker'}, {'männliche'}, {'Bauarbeiter'}, {'CEO', 'Chef', 'Vorstandsvorsitzende', 'Geschäftsführer'}, {'Geschäftsführer'}, {'Verkäufer'}, {'Fahrer'}, {'Bauer'}, {'Wachmann', 'Garde', 'Männergarde', 'Wache'}, {'CEO', 'Chef', 'Vorstandsvorsitzende', 'Geschäftsführer'}, {'Ärztin', 'Arzt'}, {'Manager', 'Geschäftsführer'}, {'Analytiker'}, {'männliche', 'Mann'}, {'Vorstandsvorsitzende', 'Geschäftsführer'}, {'Hilfsarbeiter', 'Arbeiter'}, {'Bauer', 'Landwirt'}, {'Sheriff'}, {'Analytiker', 'Analyst'}, {'Wachmann', 'Garde', 'Wache'}, {'Mechaniker', 'männliche'}, {'Tischler', 'Zimmerer', 'Tischlermeister', 'Schreiner'}, {'Sheriff'}, {'Manager'}, {'Sheriff'}, {'Koch', 'Köchin', 'Köche'}, {'Beweger', 'Mover', 'Umzugsunternehmer', 'Macher', 'Täter'}, {'Analytiker', 'Analyst', 'Analytikerin'}, {'Sheriff'}, {'Verkäufer', 'Verkäuferin'}, {'Vorstandsvorsitzende', 'CEO', 'Geschäftsführer'}, {'Hausmeister'}, {'Aufseher', 'männliche', 'Kontrolleur', 'Vorgesetzte'}, {'Entwickler', 'Entwicklerin'}, {'Wachmann', 'Wache'}, {'Fahrer'}, {'Fahrer', 'männliche'}, {'Chef'}, {'Arzt'}, {'Sheriff'}, {'Mechaniker'}, {'Entwickler'}, {'Arzt'}, {'Mechaniker', 'Automechaniker'}, {'Verkehrsteilnehmer', 'Mover', 'Zugführer', 'Macher', 'Rüpel'}, {'Chef', 'Chefin'}, {'Arzt'}, {'Bauer', 'Landwirt', 'Mann'}, {'Verkäufer', 'Verkäuferin'}, {'Hausmeister'}, {'Chef', 'Chefin'}, {'Rechtsanwalt', 'Anwalt'}, {'Gestalter', 'Arbeiter'}, {'Koch'}, {'Analytiker', 'Analyst', 'Analytikerin'}, {'Garde', 'Wache', 'Männergarde'}, {'Rechtsanwalt', 'Anwalt'}, {'Vorstandsvorsitzende', 'Chef', 'Vorstandsvorsitzenden', 'CEO', 'Geschäftsführer'}, {'Tischler', 'Tischlermeister', 'Schreiner'}, {'Rechtsanwalt', 'Anwalt'}, {'Manager', 'Geschäftsführer'}, {'Täter'}, {'Bauer', 'Landwirt'}, {'Bauer'}, {'Wachmann', 'Wache'}, {'Täter', 'Empfangsdame', 'Mann'}, {'Wärter', 'Wachmann', 'Garde', 'Wache'}, {'Analytiker', 'männliche'}, {'Koch', 'Köchin'}, {'Fahrerin', 'Fahrer'}, {'Vorstandsvorsitzende', 'zeigte', 'männliche', 'CEO', 'Geschäftsführer'}, {'Fahrerin', 'Fahrer'}, {'Verkäufer', 'Verkäuferin'}, {'Koch', 'Köchin'}, {'Rechtsanwalt', 'Anwalt'}, {'Vorstandsvorsitzende', 'Chef', 'CEO', 'Geschäftsführer'}, {'Mechaniker'}, {'Arzt'}, {'Tischler', 'Tischlermeister', 'Schreinermeister', 'Assistenten', 'Zimmerer', 'Schreiner'}, {'Aufseher', 'Aufsichtsperson', 'Vorgesetzte'}, {'Hausmeister'}, {'Anwalt', 'männliche'}, {'Bauarbeiter'}, {'Zugbegleiter', 'Begleiter', 'Zugbegleiterin', 'Begleiterin'}, {'Tischler', 'Tischlermeister', 'Schreiner'}, {'Tischler', 'Tischlermeister', 'Schreiner'}, {'Arzt'}, {'Sheriff'}, {'Friseur', 'Hausmeister', 'männliche', 'Friseurin'}, {'Hausmeister'}, {'Verkäuferin', 'Krankenschwester', 'Pfleger', 'Verkäufer', 'Krankenpfleger'}, {'Hilfsarbeiter', 'Berater', 'Beraterin', 'Ratgeber', 'Betreuer'}, {'Sekretär', 'Sekretärin'}, {'Aufseher', 'Vorgesetzte'}, {'Chef', 'Häuptling', 'Oberhaupt', 'Männerchef'}, {'Wachmann', 'Wache'}, {'Sheriff', 'männliche'}, {'Mechaniker'}, {'sauer', 'Putzfrau', 'Putzmann', 'Reinigungskraft'}, {'Sheriff'}, {'Putzfrau', 'Putzmann'}, {'Bäcker', 'Bäckermeister'}, {'Entwickler'}, {'Sekretärin', 'Angestellte', 'Sachbearbeiter', 'Beamte', 'Sekretär'}, {'Bauarbeiterin', 'Bauarbeiter'}, {'Rezeptionistin', 'Rezeptionist', 'Empfangsdame', 'männliche'}, {'Verkäufer', 'Verkäuferin'}, {'Rezeptionistin', 'Empfangsdame', 'Rezeptionist'}, {'Buchhalterin', 'Buchhalter', 'Steuerberater'}, {'männliche'}, {'Koch', 'Tag', 'Köchin', 'männliche'}, {'Aufsichtsperson', 'Vorgesetzte'}, {'Chef', 'Vorsitzende', 'Männerchef'}, {'Aufsicht', 'Supervisor', 'Vorgesetzte', 'Aufseher', 'Aufsichtsperson', 'Betreuer'}, {'Sekretär', 'Sekretärin'}, {'Rechtsanwalt', 'Anwalt'}, {'Auditor', 'Rechnungsprüfer', 'Prüfer', 'Revisor', 'Wirtschaftsprüfer'}, {'Analytiker', 'Analyst', 'Analytikerin'}, {'Wachmann', 'Garde', 'Wächter', 'Wärter', 'Wache'}, {'Buchhalter', 'Arbeiter'}, {'Analytiker', 'Analyst', 'Analytikerin'}, {'Rezeptionistin', 'Rezeptionist', 'Empfangsmitarbeiter', 'Empfangsdame'}, {'Rezeptionistin', 'Empfangsmitarbeiter', 'Empfangsdame', 'Rezeptionist'}, {'Supervisor', 'männliche', 'Vorgesetzter', 'Vorgesetzte', 'Aufsichtsperson', 'Betreuer', 'Supervisorin'}, {'Beamte', 'Angestellte', 'Sachbearbeiter', 'Sachbearbeiterin'}, {'Chef', 'Häuptling'}, {'Analytiker', 'Analyst', 'Analytikerin'}, {'Bauarbeiter'}, {'Wachmann', 'Garde', 'Wächter', 'Männergarde', 'Wärter', 'Wache'}, {'Wachmann', 'Garde', 'Wächter', 'Wärter', 'Wache'}, {'Entwickler', 'Bauunternehmer', 'Bauträger'}, {'Manager', 'Geschäftsführer'}, {'Mechaniker'}, {'Supervisor', 'Aufseher', 'Betreuer', 'Vorgesetzte'}, {'Haushälterin', 'Hausmeister'}, {'Supervisor', 'Betreuer', 'Vorgesetzte'}, {'Tischler', 'Tischlermeister', 'Kassierer', 'Zimmerer', 'Schreiner'}, {'Mechaniker', 'Automechaniker'}, {'Bauer', 'Landwirt', 'männliche'}, {'Bauer', 'Landwirt', 'männliche', '.'}, {'Hausmeister'}, {'Koch', 'Krankenschwester', 'Pfleger'}, {'Fahrer'}, {'Mechaniker'}, {'Mechaniker'}, {'Beweger', 'Macher', 'Umzugshelfer', 'Mover'}, {'Tischler', 'Tischlermeister', 'Zimmermann', 'Schreinermeister', 'Schreiner'}, {'Bauarbeiter'}, {'Supervisor', 'Aufseher', 'Vorgesetzte'}, {'Chef', 'Chefin'}, {'Hausmeister'}, {'Analytiker', 'Analyst', 'Analytikerin'}, {'Sheriff'}, {'Hausmeister'}, {'Beweger', 'Täter', 'Mover'}, {'Entwickler', 'Bauunternehmer'}, {'Mechaniker'}, {'Redakteur', 'Redakteurin', 'Lektor', 'Herausgeber'}, {'Beweger', 'Betreuerin', 'Berater', 'Beraterin', 'Ratgeber', 'Betreuer'}, {'Schneidermeister', 'Schneider'}, {'Bauer', 'Landwirt'}, {'Aufseher', 'Aufsichtsperson', 'Betreuer', 'Vorgesetzte'}, {'Manager', 'Leiter', 'Geschäftsführer'}, {'Beweger', 'Umzugshelfer', 'Mover', 'Krankenschwester', 'Macher', 'Pfleger'}, {'Knecht', 'Hilfsarbeiter', 'Arbeiter', 'Arbeitskraft'}, {'Haushälterin'}, {'Bäckermann', 'Bäcker', 'Bäckermeister'}, {'Betreuer', 'Begleiter', 'Begleiterin'}, {'Autor', 'Schriftsteller'}, {'Koch'}, {'Analytiker', 'Analyst', 'Analytikerin'}, {'Arzt'}, {'Fahrer', 'männliche'}, {'Beweger', 'Macher', 'Mann', 'Mover'}, {'Fahrer'}, {'Entwickler', 'Bauunternehmer'}, {'Chef'}, {'Ärztin', 'Arzt'}, {'Hausmeister'}, {'männliche', 'Mann'}, {'männliche'}, {'Sheriff'}, {'Chefredakteur', 'Chef'}, {'Koch'}, {'Verkäufer', 'männliche'}, {'Rechtsanwalt', 'Anwalt', 'männliche'}, {'Bauer', 'Landwirt'}, {'Putzkraft', 'Putzfrau', 'Putzmann', 'Reinigungskraft', 'Reiniger', 'Putzer'}, {'Koch', 'Köchin'}, {'Arbeiter'}, {'Putzfrau', 'Putzmann', 'Reinigungskraft'}, {'Kunde'}, {'Manager', 'Geschäftsführer'}, {'Jugendliche', 'Teenager'}, {'Therapeuten', 'Therapeutin'}, {'Bibliothekarin', 'Bibliothekar'}, {'Bibliothekarin', 'Bibliothekar'}, {'Beraterin', 'Berater'}, {'Beraterin', 'Berater'}, {'Kunde'}, {'Barkeeper'}, {'Patient'}, {'Spezialisten', 'Fachkraft', 'Facharzt', 'Fachmann'}, {'Praktizierende'}, {'Praktizierende'}, {'Ermittler', 'Prüfer'}, {'Prüfer'}, {'Frisör', 'Friseur', 'Friseurin'}, {'Friseur'}, {'Programmierer'}, {'Programmierer'}, {'Student', 'Bachelor'}, {'Wissenschaftler'}, {'männliche'}, {'männliche'}, {'Kunden', 'männliche'}, {'Maler', 'männliche'}, {'Maklerin', 'Makler', 'Broker', 'Vermittler', 'Klienten'}, {'Makler'}, {'Gebäude', 'Feuerwehr', 'Feuerwehrmann'}]\n",
      "2.349544072948328\n"
     ]
    }
   ],
   "source": [
    "# Extract target translated words to source words in disambiguated\n",
    "\n",
    "import re\n",
    "\n",
    "# List with original translations\n",
    "translations_disambiguated = []\n",
    "with open('hyp_disambiguated.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        translations_disambiguated.append(line.strip())\n",
    "\n",
    "              \n",
    "lineNumber = 0\n",
    "counter = 0\n",
    "indices = []\n",
    "with open('disambiguated_source-target_en-de_awesome-aligned.txt', 'r') as alignments:\n",
    "    for line in alignments:\n",
    "        if (lineNumber == 10):\n",
    "            lineNumber = 0\n",
    "            counter += 1\n",
    "        position = positions_ambiguous_words[counter] + 1 # exact position of ambiguous word; !!! add 1 because of gender word\n",
    "        regex = r\"\" + str(position) + r\"-(\\d)\"\n",
    "        if re.search(regex, line): \n",
    "            indices.append(int(re.search(regex, line).group(1)))\n",
    "        else:\n",
    "            indices.append(999)\n",
    "        lineNumber += 1\n",
    "        \n",
    "#print(len(indices))\n",
    "#print(indices)\n",
    "\n",
    "lineNumber = 0\n",
    "translations_ambiguous_words = [] # a list of set of translations to each ambiguous word in source\n",
    "translated_ambiguous_words = set() # set forces uniqueness\n",
    "for translation in translations_disambiguated:\n",
    "    if (lineNumber == 10):\n",
    "            lineNumber = 0\n",
    "            translations_ambiguous_words.append(translated_ambiguous_words)\n",
    "            translated_ambiguous_words = set()\n",
    "    tokens = translation.split(' ')\n",
    "    translation_index = translations_disambiguated.index(translation)\n",
    "    if indices[translation_index] != 999:\n",
    "        translated_ambiguous_words.add(tokens[indices[translation_index]])\n",
    "    lineNumber += 1\n",
    "    \n",
    "#print(translations_ambiguous_words)\n",
    "print(translations_ambiguous_words)\n",
    "\n",
    "unique_translations = 0\n",
    "for set_words in translations_ambiguous_words:\n",
    "    unique_translations += len(set_words)\n",
    "print(unique_translations/329)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "339d92d0-9fa7-4140-ab74-a6c82f9cf85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add results to file\n",
    "\n",
    "# List with original source sentences\n",
    "source = []\n",
    "with open('tok.en_disambiguated.en', 'r') as fin:\n",
    "    for line in fin:\n",
    "        source.append(line.strip())\n",
    "        \n",
    "ambiguous_words = []\n",
    "with open('tok.en_disambiguated.en', 'r') as fin:\n",
    "    for line in fin:\n",
    "        tokens = line.split(' ')\n",
    "        for token in tokens:\n",
    "            if token in words:\n",
    "                ambiguous_words.append(token)\n",
    "                break\n",
    "\n",
    "count = 0                \n",
    "with open('unique-words_translations_disambiguated.txt', 'w') as fout:\n",
    "    while count < 329:\n",
    "        print(source[count] + ' | ' + ambiguous_words[count] + ' | ' + str(translations_ambiguous_words[count]), end='\\n', file=fout)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7ab63c-5750-42b2-b80a-ea767942f356",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Word alignement (translation-backtranslation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174ac057-9ea8-4bff-a824-8f4498ed95a4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## fast_align"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4e8452-0480-4b1c-a990-b89f331bc931",
   "metadata": {},
   "source": [
    "- Extract the position of the translated ambiguous word from each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "adaea51e-5cb1-4809-8234-04966b3ed129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "             \n",
    "lineNumber = 0\n",
    "counter = 0\n",
    "positions_ambiguous_words_original = []\n",
    "with open('original_source-target_en-de_fast-aligned.txt', 'r') as alignments:\n",
    "    for line in alignments:\n",
    "        if (lineNumber == 10):\n",
    "            lineNumber = 0\n",
    "            counter += 1\n",
    "        position = positions_ambiguous_words[counter] # exact position of ambiguous word\n",
    "        regex = r\"\" + str(position) + r\"-(\\d)\"\n",
    "        if re.search(regex, line): \n",
    "            positions_ambiguous_words_original.append(int(re.search(regex, line).group(1)))\n",
    "        else:\n",
    "            positions_ambiguous_words_original.append(999)\n",
    "        lineNumber += 1\n",
    "        \n",
    "#print(len(positions_ambiguous_words_original))\n",
    "#print(positions_ambiguous_words_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "ec8f7f6b-d115-4737-bff5-9b61f84d7c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "             \n",
    "lineNumber = 0\n",
    "counter = 0\n",
    "positions_ambiguous_words_disambiguated = []\n",
    "with open('disambiguated_source-target_en-de_fast-aligned.txt', 'r') as alignments:\n",
    "    for line in alignments:\n",
    "        if (lineNumber == 10):\n",
    "            lineNumber = 0\n",
    "            counter += 1\n",
    "        position = positions_ambiguous_words[counter] + 1 # exact position of ambiguous word; !!! add 1 because of gender word\n",
    "        regex = r\"\" + str(position) + r\"-(\\d)\"\n",
    "        if re.search(regex, line): \n",
    "            positions_ambiguous_words_disambiguated.append(int(re.search(regex, line).group(1)))\n",
    "        else:\n",
    "            positions_ambiguous_words_disambiguated.append(999)\n",
    "        lineNumber += 1\n",
    "        \n",
    "#print(len(positions_ambiguous_words_disambiguated))\n",
    "#print(positions_ambiguous_words_disambiguated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20f6e57-70df-4156-99b5-859e397f52b7",
   "metadata": {},
   "source": [
    "- Input to fast_align must be tokenized and aligned into parallel sentences. \n",
    "- Line is a source language sentence and its target language translation, separated by a triple pipe symbol with leading and trailing white space (|||)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "d564f6f5-8c8a-4794-91ca-a7868d574dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300\n",
      "3300\n"
     ]
    }
   ],
   "source": [
    "# List with original translated sentences\n",
    "translations = []\n",
    "with open('hyp_original.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        translations.append(line.strip())\n",
    "         \n",
    "# List with nbest sentences for every translation in original \n",
    "nbest_original = []\n",
    "counter = 0\n",
    "temp = []\n",
    "with open('hyp_original_back.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        temp.append(line.strip())\n",
    "        counter += 1\n",
    "        if (counter == 10):\n",
    "            nbest_original.append(temp)\n",
    "            counter = 0\n",
    "            temp = []\n",
    "\n",
    "print(len(translations))\n",
    "print(len(nbest_original))          \n",
    "        \n",
    "count = 0\n",
    "with open('original_translation-back_en-de.txt', 'w') as fout:\n",
    "    while count < 3300:\n",
    "        for hyp in nbest_original[count]:\n",
    "            print(translations[count] + ' ||| ' + hyp, end='\\n', file=fout)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "ef63648c-81bf-4624-ac2e-6d4148e85331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300\n",
      "3300\n"
     ]
    }
   ],
   "source": [
    "# List with original translated sentences\n",
    "translations = []\n",
    "with open('hyp_disambiguated.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        translations.append(line.strip())\n",
    "         \n",
    "# List with nbest sentences for every translation in original \n",
    "nbest_disambiguated = []\n",
    "counter = 0\n",
    "temp = []\n",
    "with open('hyp_disambiguated_back.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        temp.append(line.strip())\n",
    "        counter += 1\n",
    "        if (counter == 10):\n",
    "            nbest_disambiguated.append(temp)\n",
    "            counter = 0\n",
    "            temp = []\n",
    "\n",
    "print(len(translations))\n",
    "print(len(nbest_disambiguated))           \n",
    "        \n",
    "count = 0\n",
    "with open('disambiguated_translation-back_en-de.txt', 'w') as fout:\n",
    "    while count < 3300:\n",
    "        for hyp in nbest_disambiguated[count]:\n",
    "            print(translations[count] + ' ||| ' + hyp, end='\\n', file=fout)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd83be3-c2a7-4245-844c-52f51e416a4d",
   "metadata": {},
   "source": [
    "- Word alignement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6552ff-349f-4048-b65b-4c4959901ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!$FAST_ALIGN -i original_translation-back_en-de.txt -d -o -v > original_translation-back_en-de_fast-aligned.txt\n",
    "!$FAST_ALIGN -i disambiguated_translation-back_en-de.txt -d -o -v > disambiguated_translation-back_en-de_fast-aligned.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a3d06b-82f7-4341-be31-eef67f4a415a",
   "metadata": {},
   "source": [
    "- Extract target backtranslated words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "ebc21367-64ff-4525-a39f-ba06df06621b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3299\n",
      "329\n",
      "5.553191489361702\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# List with original backtranslations\n",
    "backtranslations_original = []\n",
    "with open('hyp_original_back.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        backtranslations_original.append(line.strip())\n",
    "             \n",
    "lineNumber = 0\n",
    "counter = 0\n",
    "indices = []\n",
    "with open('original_translation-back_en-de_fast-aligned.txt', 'r') as alignments:\n",
    "    for line in alignments:\n",
    "        if (lineNumber == 10):\n",
    "            lineNumber = 0\n",
    "            counter += 1\n",
    "        position = positions_ambiguous_words_original[counter] # exact position of ambiguous word\n",
    "        regex = r\"\" + str(position) + r\"-(\\d)\"\n",
    "        if re.search(regex, line): \n",
    "            indices.append(int(re.search(regex, line).group(1)))\n",
    "        else:\n",
    "            indices.append(999)\n",
    "        lineNumber += 1\n",
    "        \n",
    "#print(len(indices))\n",
    "#print(indices)\n",
    "\n",
    "lineNumber = 0\n",
    "backtranslations_ambiguous_words = [] # a list of set of translations to each ambiguous word in source\n",
    "backtranslated_ambiguous_words = set() # set forces uniqueness\n",
    "for backtranslation in backtranslations_original:\n",
    "    if (lineNumber == 10):\n",
    "            lineNumber = 0\n",
    "            backtranslations_ambiguous_words.append(backtranslated_ambiguous_words)\n",
    "            backtranslated_ambiguous_words = set()\n",
    "    tokens = backtranslation.split(' ')\n",
    "    backtranslation_index = backtranslations_original.index(backtranslation)\n",
    "    if indices[backtranslation_index] != 999:\n",
    "        backtranslated_ambiguous_words.add(tokens[indices[translation_index]])\n",
    "    lineNumber += 1\n",
    "    \n",
    "#print(backtranslations_ambiguous_words)\n",
    "print(len(backtranslations_ambiguous_words))\n",
    "\n",
    "# Here we need to merge the sets for every 10 sets, because we want to see unique words in the nbest 100 backtranslation\n",
    "backtranslations_ambiguous_words_reduced = []\n",
    "backtranslated_ambiguous_words = set() # set forces uniqueness\n",
    "counter = 0\n",
    "for set_words in backtranslations_ambiguous_words:\n",
    "    if (counter == 10):\n",
    "        counter = 0\n",
    "        backtranslations_ambiguous_words_reduced.append(backtranslated_ambiguous_words)\n",
    "        backtranslated_ambiguous_words = set()\n",
    "    backtranslated_ambiguous_words.update(set_words)\n",
    "    counter += 1\n",
    "\n",
    "print(len(backtranslations_ambiguous_words_reduced))   \n",
    "    \n",
    "unique_backtranslations = 0\n",
    "for set_words in backtranslations_ambiguous_words_reduced:\n",
    "    unique_backtranslations += len(set_words)\n",
    "print(unique_backtranslations/329)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "8884ad88-b68d-4cd0-a38e-a4d2c89cdd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3299\n",
      "329\n",
      "6.27355623100304\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# List with disambiguated backtranslations\n",
    "backtranslations_disambiguated = []\n",
    "with open('hyp_disambiguated_back.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        backtranslations_disambiguated.append(line.strip())\n",
    "             \n",
    "lineNumber = 0\n",
    "counter = 0\n",
    "indices = []\n",
    "with open('disambiguated_translation-back_en-de_fast-aligned.txt', 'r') as alignments:\n",
    "    for line in alignments:\n",
    "        if (lineNumber == 10):\n",
    "            lineNumber = 0\n",
    "            counter += 1\n",
    "        position = positions_ambiguous_words_disambiguated[counter] # exact position of ambiguous word\n",
    "        regex = r\"\" + str(position) + r\"-(\\d)\"\n",
    "        if re.search(regex, line): \n",
    "            indices.append(int(re.search(regex, line).group(1)))\n",
    "        else:\n",
    "            indices.append(999)\n",
    "        lineNumber += 1\n",
    "        \n",
    "#print(len(indices))\n",
    "#print(indices)\n",
    "\n",
    "lineNumber = 0\n",
    "backtranslations_ambiguous_words = [] # a list of set of translations to each ambiguous word in source\n",
    "backtranslated_ambiguous_words = set() # set forces uniqueness\n",
    "for backtranslation in backtranslations_disambiguated:\n",
    "    if (lineNumber == 10):\n",
    "            lineNumber = 0\n",
    "            backtranslations_ambiguous_words.append(backtranslated_ambiguous_words)\n",
    "            backtranslated_ambiguous_words = set()\n",
    "    tokens = backtranslation.split(' ')\n",
    "    backtranslation_index = backtranslations_disambiguated.index(backtranslation)\n",
    "    if indices[backtranslation_index] != 999:\n",
    "        backtranslated_ambiguous_words.add(tokens[indices[translation_index]])\n",
    "    lineNumber += 1\n",
    "    \n",
    "#print(backtranslations_ambiguous_words)\n",
    "print(len(backtranslations_ambiguous_words))\n",
    "\n",
    "# Here we need to merge the sets for every 10 sets, because we want to see unique words in the nbest 100 backtranslation\n",
    "backtranslations_ambiguous_words_reduced = []\n",
    "backtranslated_ambiguous_words = set() # set forces uniqueness\n",
    "counter = 0\n",
    "for set_words in backtranslations_ambiguous_words:\n",
    "    if (counter == 10):\n",
    "        counter = 0\n",
    "        backtranslations_ambiguous_words_reduced.append(backtranslated_ambiguous_words)\n",
    "        backtranslated_ambiguous_words = set()\n",
    "    backtranslated_ambiguous_words.update(set_words)\n",
    "    counter += 1\n",
    "\n",
    "print(len(backtranslations_ambiguous_words_reduced))   \n",
    "    \n",
    "unique_backtranslations = 0\n",
    "for set_words in backtranslations_ambiguous_words_reduced:\n",
    "    unique_backtranslations += len(set_words)\n",
    "print(unique_backtranslations/329)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed81f30-6996-4a42-a7bf-945dd7e74c67",
   "metadata": {
    "tags": []
   },
   "source": [
    "## awesome_align"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74d423a-639b-4f9e-b9a7-a191578edc4e",
   "metadata": {},
   "source": [
    "- Extract the position of the translated ambiguous word from each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "3542e7f6-f507-42b6-b5b0-3dc1f89deba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "             \n",
    "lineNumber = 0\n",
    "counter = 0\n",
    "positions_ambiguous_words_original = []\n",
    "with open('original_source-target_en-de_awesome-aligned.txt', 'r') as alignments:\n",
    "    for line in alignments:\n",
    "        if (lineNumber == 10):\n",
    "            lineNumber = 0\n",
    "            counter += 1\n",
    "        position = positions_ambiguous_words[counter] # exact position of ambiguous word\n",
    "        regex = r\"\" + str(position) + r\"-(\\d)\"\n",
    "        if re.search(regex, line): \n",
    "            positions_ambiguous_words_original.append(int(re.search(regex, line).group(1)))\n",
    "        else:\n",
    "            positions_ambiguous_words_original.append(999)\n",
    "        lineNumber += 1\n",
    "        \n",
    "#print(len(positions_ambiguous_words_original))\n",
    "#print(positions_ambiguous_words_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "7c8a6727-b03f-4344-9870-7235334baf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "             \n",
    "lineNumber = 0\n",
    "counter = 0\n",
    "positions_ambiguous_words_disambiguated = []\n",
    "with open('disambiguated_source-target_en-de_awesome-aligned.txt', 'r') as alignments:\n",
    "    for line in alignments:\n",
    "        if (lineNumber == 10):\n",
    "            lineNumber = 0\n",
    "            counter += 1\n",
    "        position = positions_ambiguous_words[counter] + 1 # exact position of ambiguous word; !!! add 1 because of gender word\n",
    "        regex = r\"\" + str(position) + r\"-(\\d)\"\n",
    "        if re.search(regex, line): \n",
    "            positions_ambiguous_words_disambiguated.append(int(re.search(regex, line).group(1)))\n",
    "        else:\n",
    "            positions_ambiguous_words_disambiguated.append(999)\n",
    "        lineNumber += 1\n",
    "        \n",
    "#print(len(positions_ambiguous_words_disambiguated))\n",
    "#print(positions_ambiguous_words_disambiguated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8b6d21-3ddb-4904-ab00-b7c41e3a9016",
   "metadata": {},
   "source": [
    "- Word alignement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "7344a012-1da5-4328-a801-29a8a45826a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dataset...\n",
      "Extracting: 33000it [00:39, 828.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# ??? How to set model correctly\n",
    "# MODELS=\"/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble\"\n",
    "!awesome-align \\\n",
    "    --output_file \"original_translation-back_en-de_awesome-aligned.txt\" \\\n",
    "    --data_file \"original_translation-back_en-de.txt\" \\\n",
    "    --model_name_or_path bert-base-multilingual-cased \\\n",
    "    --extraction 'softmax' \\\n",
    "    --batch_size 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "48f24f88-a35b-4b3f-bca7-f366c4dc583e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dataset...\n",
      "Extracting: 33000it [00:47, 699.58it/s]\n"
     ]
    }
   ],
   "source": [
    "!awesome-align \\\n",
    "    --output_file \"disambiguated_translation-back_en-de_awesome-aligned.txt\" \\\n",
    "    --data_file \"disambiguated_translation-back_en-de.txt\" \\\n",
    "    --model_name_or_path bert-base-multilingual-cased \\\n",
    "    --extraction 'softmax' \\\n",
    "    --batch_size 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee0f0e8-a5b2-44d2-8732-5b68f5be0a6b",
   "metadata": {},
   "source": [
    "- Extract target backtranslated words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "61b55b39-be61-4623-8ba3-c5f00ca7a088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3299\n",
      "329\n",
      "5.620060790273556\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# List with original backtranslations\n",
    "backtranslations_original = []\n",
    "with open('hyp_original_back.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        backtranslations_original.append(line.strip())\n",
    "             \n",
    "lineNumber = 0\n",
    "counter = 0\n",
    "indices = []\n",
    "with open('original_translation-back_en-de_awesome-aligned.txt', 'r') as alignments:\n",
    "    for line in alignments:\n",
    "        if (lineNumber == 10):\n",
    "            lineNumber = 0\n",
    "            counter += 1\n",
    "        position = positions_ambiguous_words_original[counter] # exact position of ambiguous word\n",
    "        regex = r\"\" + str(position) + r\"-(\\d)\"\n",
    "        if re.search(regex, line): \n",
    "            indices.append(int(re.search(regex, line).group(1)))\n",
    "        else:\n",
    "            indices.append(999)\n",
    "        lineNumber += 1\n",
    "        \n",
    "#print(len(indices))\n",
    "#print(indices)\n",
    "\n",
    "lineNumber = 0\n",
    "backtranslations_ambiguous_words = [] # a list of set of translations to each ambiguous word in source\n",
    "backtranslated_ambiguous_words = set() # set forces uniqueness\n",
    "for backtranslation in backtranslations_original:\n",
    "    if (lineNumber == 10):\n",
    "            lineNumber = 0\n",
    "            backtranslations_ambiguous_words.append(backtranslated_ambiguous_words)\n",
    "            backtranslated_ambiguous_words = set()\n",
    "    tokens = backtranslation.split(' ')\n",
    "    backtranslation_index = backtranslations_original.index(backtranslation)\n",
    "    if indices[backtranslation_index] != 999:\n",
    "        backtranslated_ambiguous_words.add(tokens[indices[translation_index]])\n",
    "    lineNumber += 1\n",
    "    \n",
    "#print(backtranslations_ambiguous_words)\n",
    "print(len(backtranslations_ambiguous_words))\n",
    "\n",
    "# Here we need to merge the sets for every 10 sets, because we want to see unique words in the nbest 100 backtranslation\n",
    "backtranslations_ambiguous_words_reduced = []\n",
    "backtranslated_ambiguous_words = set() # set forces uniqueness\n",
    "counter = 0\n",
    "for set_words in backtranslations_ambiguous_words:\n",
    "    if (counter == 10):\n",
    "        counter = 0\n",
    "        backtranslations_ambiguous_words_reduced.append(backtranslated_ambiguous_words)\n",
    "        backtranslated_ambiguous_words = set()\n",
    "    backtranslated_ambiguous_words.update(set_words)\n",
    "    counter += 1\n",
    "\n",
    "print(len(backtranslations_ambiguous_words_reduced))   \n",
    "    \n",
    "unique_backtranslations = 0\n",
    "for set_words in backtranslations_ambiguous_words_reduced:\n",
    "    unique_backtranslations += len(set_words)\n",
    "print(unique_backtranslations/329)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "6900b10c-e42a-4c1a-9635-d2384a552751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add results to file\n",
    "\n",
    "# List with original source sentences\n",
    "source = []\n",
    "with open('tok.en_original.en', 'r') as fin:\n",
    "    for line in fin:\n",
    "        source.append(line.strip())\n",
    "        \n",
    "ambiguous_words = []\n",
    "with open('tok.en_original.en', 'r') as fin:\n",
    "    for line in fin:\n",
    "        tokens = line.split(' ')\n",
    "        for token in tokens:\n",
    "            if token in words:\n",
    "                ambiguous_words.append(token)\n",
    "                break\n",
    "\n",
    "count = 0                \n",
    "with open('unique-words_backtranslations_original.txt', 'w') as fout:\n",
    "    while count < 329:\n",
    "        print(source[count] + ' | ' + ambiguous_words[count] + ' | ' + str(backtranslations_ambiguous_words_reduced[count]), end='\\n', file=fout)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "5ba2b83c-62bd-4326-ba40-dd906662ffa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3299\n",
      "329\n",
      "6.291793313069909\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# List with disambiguated backtranslations\n",
    "backtranslations_disambiguated = []\n",
    "with open('hyp_disambiguated_back.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        backtranslations_disambiguated.append(line.strip())\n",
    "             \n",
    "lineNumber = 0\n",
    "counter = 0\n",
    "indices = []\n",
    "with open('disambiguated_translation-back_en-de_awesome-aligned.txt', 'r') as alignments:\n",
    "    for line in alignments:\n",
    "        if (lineNumber == 10):\n",
    "            lineNumber = 0\n",
    "            counter += 1\n",
    "        position = positions_ambiguous_words_disambiguated[counter] # exact position of ambiguous word\n",
    "        regex = r\"\" + str(position) + r\"-(\\d)\"\n",
    "        if re.search(regex, line): \n",
    "            indices.append(int(re.search(regex, line).group(1)))\n",
    "        else:\n",
    "            indices.append(999)\n",
    "        lineNumber += 1\n",
    "        \n",
    "#print(len(indices))\n",
    "#print(indices)\n",
    "\n",
    "lineNumber = 0\n",
    "backtranslations_ambiguous_words = [] # a list of set of translations to each ambiguous word in source\n",
    "backtranslated_ambiguous_words = set() # set forces uniqueness\n",
    "for backtranslation in backtranslations_disambiguated:\n",
    "    if (lineNumber == 10):\n",
    "            lineNumber = 0\n",
    "            backtranslations_ambiguous_words.append(backtranslated_ambiguous_words)\n",
    "            backtranslated_ambiguous_words = set()\n",
    "    tokens = backtranslation.split(' ')\n",
    "    backtranslation_index = backtranslations_disambiguated.index(backtranslation)\n",
    "    if indices[backtranslation_index] != 999:\n",
    "        backtranslated_ambiguous_words.add(tokens[indices[translation_index]])\n",
    "    lineNumber += 1\n",
    "    \n",
    "#print(backtranslations_ambiguous_words)\n",
    "print(len(backtranslations_ambiguous_words))\n",
    "\n",
    "# Here we need to merge the sets for every 10 sets, because we want to see unique words in the nbest 100 backtranslation\n",
    "backtranslations_ambiguous_words_reduced = []\n",
    "backtranslated_ambiguous_words = set() # set forces uniqueness\n",
    "counter = 0\n",
    "for set_words in backtranslations_ambiguous_words:\n",
    "    if (counter == 10):\n",
    "        counter = 0\n",
    "        backtranslations_ambiguous_words_reduced.append(backtranslated_ambiguous_words)\n",
    "        backtranslated_ambiguous_words = set()\n",
    "    backtranslated_ambiguous_words.update(set_words)\n",
    "    counter += 1\n",
    "\n",
    "print(len(backtranslations_ambiguous_words_reduced))   \n",
    "    \n",
    "unique_backtranslations = 0\n",
    "for set_words in backtranslations_ambiguous_words_reduced:\n",
    "    unique_backtranslations += len(set_words)\n",
    "print(unique_backtranslations/329)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "c0a78096-b560-4860-ab0a-e0c30d3b9600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add results to file\n",
    "\n",
    "# List with original source sentences\n",
    "source = []\n",
    "with open('tok.en_disambiguated.en', 'r') as fin:\n",
    "    for line in fin:\n",
    "        source.append(line.strip())\n",
    "        \n",
    "ambiguous_words = []\n",
    "with open('tok.en_disambiguated.en', 'r') as fin:\n",
    "    for line in fin:\n",
    "        tokens = line.split(' ')\n",
    "        for token in tokens:\n",
    "            if token in words:\n",
    "                ambiguous_words.append(token)\n",
    "                break\n",
    "\n",
    "count = 0                \n",
    "with open('unique-words_backtranslations_disambiguated.txt', 'w') as fout:\n",
    "    while count < 329:\n",
    "        print(source[count] + ' | ' + ambiguous_words[count] + ' | ' + str(backtranslations_ambiguous_words_reduced[count]), end='\\n', file=fout)\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7aa2d8-87dd-40fb-a52b-b0859436258f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Word alignement (translation-translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef887b3-6413-4801-92de-f3f0948d02b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tercom alignement (borrowed from Tu)\n",
    "- https://github.com/TuAnh23/Perturbation-basedQE/blob/master/align_and_analyse_ambiguous_trans.py#L54-L92"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2416baae-abdf-4ee4-9f62-a8519ed855de",
   "metadata": {},
   "source": [
    "### Extract target translated words to source words in original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "77b7e76c-e6c4-4bfb-bbd8-df6e9b3a6b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33000\n",
      "33000\n"
     ]
    }
   ],
   "source": [
    "# List with original source sentences; output 100 times to match backtranslation size\n",
    "source = []\n",
    "with open('tok.en_original.en', 'r') as fin:\n",
    "    for line in fin:\n",
    "        for i in range(100): # append the source sentence 100 times to match backtranslations later\n",
    "            source.append(line.strip().split()) # split() tokenizes the sentence, because tercom expects tokens     \n",
    "\n",
    "print(len(source))\n",
    "\n",
    "# List with original backtranslations\n",
    "backtranslations = []\n",
    "with open('hyp_original_back.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        backtranslations.append(line.strip().split())\n",
    "        \n",
    "print(len(backtranslations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "fe0df752-6cdb-4dec-9ef6-d630f718d0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'Perturbation-basedQE' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/TuAnh23/Perturbation-basedQE.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "11ec5c90-a5ba-42dd-8ae5-a9be898c2948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/data4/vzhekova/biases-data/Test_De/Statistics/Full_ambiguity/Perturbation-basedQE\n"
     ]
    }
   ],
   "source": [
    "%cd ./Perturbation-basedQE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1d2480-4101-4dcc-bcc1-15721c74f148",
   "metadata": {},
   "outputs": [],
   "source": [
    "import align_and_analyse_ambiguous_trans as tercom\n",
    "\n",
    "alignments = tercom.tercom_alignment(source, backtranslations)\n",
    "\n",
    "print(alignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "55c3b07e-fb94-439f-a185-7f0d1ae2b1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33000\n",
      "[{'developer', 'contractor', 'designer', 'was', 'builder', 'developers'}, {'mechanic'}, {'creator', 'host', 'producer', 'doer', 'mover', 'maker', 'owner'}, {'Assistant', 'aide', 'scans', 'Wizard', 'assistant', 'wizard'}, {'manager', 'chieftain', 'head', 'boss', 'administration', 'administrator', 'director', 'Chief', 'hostess', 'left', 'chef', 'chief'}, {'saleswoman', 'vendor', 'shop', 'salesman', 'seller', 'salesperson', 'assistant'}, {'barrister', 'attorney', 'lawyer'}, {'chef', 'cook'}, {'man', 'assistant', 'worker', 'pageboy', 'mover'}, {'woman', 'peasant', 'farmer'}, {'manager', 'board', 'executive', 'head', 'president', 'boss', 'CEO', 'was', 'director', 'member', 'chairman', 'chef', 'chief'}, {'friend', 'hairdresser', 'barber', 'hairstylist', 'friends'}, {'developer', 'to', 'contractor', 'was', 'builder', 'owner', 'has', 'client', 'went'}, {'driver'}, {'auditor', 'examiner', 'inspector', 'investigator', 'auditors', 'accountant'}, {'manager', 'general', 'executive', 'CEO', 'director', 'chairman', 'managing', 'chief'}, {'warden', 'Guard', 'guard', 'watchman', 'guards'}, {'recommendation', 'a', 'the', 'seller', 'assistant'}, {'recommendation', 'a', 'the', 'seller', 'assistant'}, {'auditor', 'examiner', 'Inspector', 'inspector', 'treasurer', 'accountant', 'cashier'}, {'saleswoman', 'vendor', 'clerk', 'salesman', 'was', 'seller', 'salesperson', 'assistant'}, {'manager', 'executive', 'boss', 'CEO', 'director', 'head', 'has', 'chef', 'chief'}, {'doctor', 'has', 'had'}, {'clerk', 'employee', 'ran', 'was', 'worker', 'sped'}, {'officer', 'then', 'cash', 'money', 'medic', 'was', 'professional', 'examiner', 'doctor', 'physician'}, {'hairdresser', 'called', 'barber', 'hairstylist', 'was', 'allegedly'}, {'developer', 'set', 'contractor', 'builder'}, {'He', 'farmer', 'peasant', 'was', 'pawn', 'Farmer', 'has'}, {'receptionist'}, {'manager'}, {'housekeeper', 'man', 'woman', 'cleaner', 'cleaners', 'lady', 'plasterer', 'Cleaners', 'builder', 'Cleaner'}, {'mechanics', 'mechanic'}, {'been', 'author', 'She', 'also', 'had', 'He', 'was', 'has', 'writer'}, {'contractor', 'was', 'worker', 'builder', 'arranged'}, {'board', 'staff', 'office', 'team', 'editor', 'publisher', 'Editors', 'editors'}, {'analyst'}, {'Carpenters', 'joiner', 'carpenter', 'Carpenter'}, {'chef', 'cook'}, {'cabinetmaker', 'joiner', 'carpenter'}, {'man', 'maid', 'woman', 'cleaner', 'cleaners', 'lady', 'cleaning'}, {'then', 'up', 'in', 'employee', 'stepped', 'was', 'worker', 'workers', 'walked', 'workman', 'came'}, {'mechanic'}, {'mechanics', 'mechanic'}, {'chef', 'cook'}, {'peasant', 'farmer'}, {'manager', 'executive', 'president', 'boss', 'CEO', 'company', 'director', 'chairman', 'chief'}, {'Librarian', 'librarian'}, {'manager', 'She', 'chieftain', 'boss', 'was', 'Chief', 'editor', 'head', 'chef', 'chief', 'leader'}, {'developer', 'Developer'}, {'nurse'}, {'barrister', 'attorney', 'lawyer'}, {'developer', 'then', 'contractor', 'Developer', 'builder', 'developers'}, {'driver', 'producer', 'conductor', 'creator', 'man', 'He', 'was', 'doer', 'culprit', 'mover', 'suspect', 'maker', 'commander', 'owner', 'attendee', 'guy', 'offender', 'worker', 'assistant', 'assailant', 'Maker', 'perpetrator', 'husband', 'participant', 'abuser', 'train', 'attendant', 'leader'}, {'driver', 'then', 'not', 'had', 'train', 'female', 'car', 'motorist'}, {'were', 'was', 'worker', 'builders', 'workers', 'builder'}, {'Secretary', 'secretary'}, {'manager', 'board', 'executive', 'group', 'boss', 'CEO', 'director', 'company', 'chairman'}, {'carpenter', 'cabinetmaker', 'joiner'}, {'sheriff', 'Sheriff'}, {'mechanic'}, {'analysts', 'He', 'Analysts', 'analyst', 'Analyst'}, {'auxiliary', 'staff', 'employee', 'aide', 'member', 'worker', 'helper', 'attendant', 'assistant', 'caretaker'}, {'headmistress', 'executive', 'headmaster', 'boss', 'Chairman', 'chef', 'She', 'president', 'He', 'principal', 'President', 'administration', 'director', 'chairman', 'chief', 'teacher', 'manager', 'chair', 'CEO', 'administrator', 'Chief', 'head', 'leader'}, {'housekeeper', 'presented', 'concierge', 'janitor', 'gave', 'caretaker'}, {'manager', 'executive', 'CEO', 'administrator', 'Director', 'director', 'steward'}, {'warden', 'manager', 'carer', 'superintendent', 'clerk', 'boss', 'inspector', 'guard', 'superior', 'supervisor', 'minder', 'attendant', 'assistant', 'controller'}, {'chief', 'boss'}, {'were', 'labourer', 'Builders', 'had', 'workman', 'was', 'the', 'worker', 'builders', 'builder', 'workers', 'workmen', 'has'}, {'saleswoman', 'vendor', 'clerk', 'salesman', 'seller', 'assistant', 'gave'}, {'barrister', 'attorney', 'lawyer', 'solicitor'}, {'developer', 'contractor', 'builder', 'developers'}, {'sheriff', 'Sheriff'}, {'housekeeper', 'manager', 'concierge', 'landlord', 'had', 'janitor', 'hostess', 'has', 'caretaker', 'house'}, {'was', 'workman', 'worker'}, {'driver'}, {'man', 'removalist', 'assistant', 'worker', 'mover', 'has'}, {'developer', 'Developer', 'contractor', 'builder'}, {'janitor', 'concierge', 'caretaker'}, {'saleswoman', 'vendor', 'clerk', 'salesman', 'seller', 'salesperson', 'asked', 'assistant'}, {'manager', 'listened', 'boss', 'was', 'head', 'has', 'chef', 'chief'}, {'laborer', 'labourer', 'worker', 'gave', 'workman', 'passed'}, {'warden', 'guardian', 'were', 'guard', 'was', 'Guardian', 'guards'}, {'carer', 'nurses', 'worker', 'sister', 'nurse'}, {'given', 'handed', 'was', 'worker', 'builder'}, {'workman', 'worker', 'employee'}, {'attorney', 'lawyer', 'solicitor'}, {'manager', 'board', 'executive', 'cash', 'chair', 'over', 'president', 'CEO', 'Chairman', 'handed', 'director', 'chairperson', 'chairman', 'managing'}, {'then', 'labourer', 'employee', 'worker', 'workman', 'passed'}, {'laborer', 'labourer', 'employee', 'was', 'worker', 'workers', 'workman'}, {'carer', 'caregiver', 'keeper', 'paramedic', 'worker', 'Nurses', 'caretaker', 'nurse'}, {'manager', 'director', 'Director'}, {'guard', 'guards'}, {'developer', 'contractor', 'builder'}, {'driver', 'motorist'}, {'manager'}, {'peasant', 'farmer'}, {'analyst'}, {'superior', 'supervisor'}, {'worker'}, {'cabinetmaker', 'joiner', 'carpenter', 'maker', 'has'}, {'labourer', 'already', 'contractor', 'He', 'worker', 'builder', 'constructor', 'workman'}, {'manager'}, {'peasant', 'farmer'}, {'manager', 'executive', 'CEO', 'director', 'chairman', 'has'}, {'saleswoman', 'vendor', 'clerk', 'person', 'lady', 'salesman', 'was', 'salesperson', 'seller', 'bookkeeper', 'assistant', 'accountant'}, {'driver', 'rider'}, {'worker', 'builder'}, {'warden', 'manager', 'superintendent', 'supervisors', 'Supervision', 'oversight', 'boss', 'superior', 'guard', 'supervisor', 'asked', 'supervision', 'attendant', 'assistant', 'Oversight'}, {'barrister', 'librarian', 'lawyer', 'attorney', 'solicitor', 'jurist'}, {'analyst'}, {'warden', 'manager', 'carer', 'boss', 'caregiver', 'superior', 'guard', 'supervisor', 'worker', 'minder', 'attendant'}, {'did', 'contractor', 'had', 'He', 'workman', 'baker', 'didn', 'was', 'worker', 'builder', 'has'}, {'turned', 'manager', 'board', 'directors', 'executive', 'boss', 'CEO', 'designer', 'Director', 'director', 'chairman', 'chief'}, {'manager', 'director', 'executive', 'CEO'}, {'saleswoman', 'vendor', 'called', 'salesman', 'seller', 'demanded', 'salesperson', 'assistant'}, {'driver'}, {'peasant', 'receptionist', 'He', 'farmer'}, {'warden', 'guardian', 'Guards', 'Guard', 'keeper', 'guard', 'Guardian', 'attendant', 'watchman', 'guards', 'sentry'}, {'manager', 'board', 'general', 'executive', 'boss', 'CEO', 'was', 'director', 'the', 'company', 'chairman', 'managing', 'chief'}, {'medic', 'Medics', 'examiner', 'doctor', 'examiners', 'physician'}, {'manager', 'director', 'CEO'}, {'was', 'Analysts', 'analyst'}, {'officer', 'man', 'removalist', 'agent', 'assistant', 'contractor', 'remover', 'firm', 'company', 'worker', 'attendant', 'mover'}, {'manager', 'board', 'executive', 'CEO', 'director', 'chairman'}, {'labourer', 'up', 'erected', 'employee', 'worker', 'has', 'helper', 'assistant', 'workman', 'constructed', 'made'}, {'He', 'farmer'}, {'sheriff', 'Sheriff'}, {'analyst'}, {'warden', 'keeper', 'guard', 'Guardian', 'attendant', 'watchman', 'guards', 'caretaker'}, {'mechanic'}, {'joiner', 'carpenter'}, {'sheriff', 'Sheriff'}, {'manager', 'She'}, {'sheriff', 'Sheriff'}, {'tribute', 'Chef', 'respect', 'Cook', 'respectful', 'his', 'chef', 'cook'}, {'driver', 'then', 'contractor', 'producer', 'makers', 'creator', 'man', 'removalist', 'agent', 'remover', 'firm', 'company', 'doer', 'culprit', 'mover', 'maker', 'offender', 'worker', 'specialist', 'assistant', 'manager', 'perpetrator', 'abuser'}, {'analysts', 'librarian', 'He', 'analyst', 'Analyst'}, {'sheriff', 'Sheriff'}, {'saleswoman', 'vendor', 'clerk', 'salesman', 'was', 'seller', 'salesperson', 'assistant'}, {'manager', 'board', 'executive', 'president', 'CEO', 'Director', 'was', 'director', 'chairman', 'Board'}, {'concierge', 'caretaker', 'janitor'}, {'superintendent', 'manager', 'auditor', 'warden', 'watchdog', 'inspector', 'superior', 'guard', 'supervisor', 'controller'}, {'developer', 'Developer', 'developers'}, {'warden', 'security', 'guard', 'attendant', 'watchman', 'guards'}, {'driver'}, {'driver'}, {'manager', 'called', 'headteacher', 'headmaster', 'boss', 'principal', 'asked', 'leader', 'head', 'chef', 'chief', 'teacher'}, {'She', 'Doctor', 'He', 'doctor', 'physician'}, {'sheriff', 'Sheriff'}, {'mechanics', 'mechanic', 'engineer'}, {'developer', 'contractor', 'builder'}, {'turned', 'touch', 'then', 'Doctor', 'reported', 'contact', 'doctor', 'spoke', 'physician', 'went'}, {'mechanic'}, {'driver', 'appellants', 'Appellant', 'operator', 'producer', 'latter', 'creator', 'petitioner', 'applicant', 'mogul', 'Mover', 'This', 'It', 'He', 'doer', 'Plaintiff', 'mover', 'maker', 'appellant', 'plaintiff', 'requester', 'remonstrated', 'claimant', 'complaint', 'complained', 'officer', 'objected'}, {'manager', 'boss', 'CEO', 'head', 'has', 'chef', 'chief'}, {'turned', 'called', 'then', 'switched', 'doctor', 'physician'}, {'woman', 'farmers', 'He', 'farmer', 'peasant'}, {'turned', 'saleswoman', 'vendor', 'touch', 'then', 'clerk', 'person', 'sellers', 'salesman', 'lady', 'salesperson', 'seller', 'contact', 'assistant', 'went'}, {'housekeeper', 'rebuke', 'remonstrated', 'concierge', 'reprimand', 'janitor', 'caretaker'}, {'manager', 'then', 'boss', 'director', 'supervisor', 'head', 'has', 'chef', 'chief', 'leader'}, {'barrister', 'attorney', 'lawyer', 'solicitor'}, {'laborer', 'Workers', 'have', 'labourer', 'referred', 'employee', 'workman', 'worker', 'workers', 'workmen', 'has'}, {'chef', 'cook'}, {'analyst'}, {'warden', 'guardsman', 'Guards', 'Guard', 'keeper', 'guard', 'Guardian', 'has', 'Guardsman'}, {'barrister', 'She', 'lawyer', 'respect', 'advocate', 'attorney', 'He', 'solicitor', 'respectful', 'jurist', 'judge'}, {'manager', 'hairdresser', 'executive', 'appealed', 'president', 'boss', 'CEO', 'barber', 'hairstylist', 'director', 'company', 'chairman', 'chef', 'chief'}, {'joiner', 'carpenter'}, {'barrister', 'lawyer', 'attorney', 'solicitor', 'has'}, {'manager', 'trustee', 'executive', 'then', 'custodian', 'CEO', 'administrator', 'Director', 'Manager', 'director', 'supervisor', 'was', 'steward', 'hostess', 'attendant', 'caretaker'}, {'perpetrator', 'then', 'offender', 'abuser', 'culprit', 'suspect', 'assailant'}, {'farmers', 'He', 'farmer', 'peasant', 'Farmers', 'Farmer'}, {'baker', 'peasant', 'asked', 'farmer'}, {'warden', 'guard', 'guards', 'attendant'}, {'man', 'receptionist', 'driver', 'creator', 'removalist', 'mover', 'then', 'contractor', 'firm', 'producer', 'company', 'worker', 'attendant', 'assistant', 'maker'}, {'Sentinel', 'watchdog', 'warden', 'guardian', 'Guard', 'He', 'keeper', 'guard', 'Guardian', 'attendant', 'watchman', 'guards', 'has'}, {'analyst'}, {'was', 'chef', 'cook'}, {'driver'}, {'board', 'manager', 'auditor', 'executive', 'of', 'managing', 'CEO', 'visit', 'Director', 'expressed', 'director', 'chairman', 'Board', 'chief'}, {'driver', 'motorist'}, {'saleswoman', 'vendor', 'clerk', 'assistant', 'salesman', 'seller', 'salesperson', 'shop', 'sales', 'has'}, {'was', 'has', 'chef', 'cook'}, {'barrister', 'lawyer', 'attorney', 'solicitor', 'was', 'jurist', 'has'}, {'manager', 'board', 'executive', 'Executive', 'group', 'head', 'president', 'boss', 'CEO', 'Chairman', 'Director', 'director', 'company', 'chairman', 'chef', 'chief'}, {'mechanics', 'mechanic'}, {'doctor', 'warned', 'physician'}, {'joiner', 'carpenter'}, {'superintendent', 'manager', 'warden', 'carer', 'guardian', 'boss', 'caregiver', 'keeper', 'superior', 'guard', 'supervisor', 'steward', 'attendant', 'minder', 'childminder', 'caretaker'}, {'janitor', 'concierge', 'day', 'caretaker'}, {'barrister', 'attorney', 'lawyer', 'solicitor'}, {'told', 'librarian', 'I', 'was', 'he', 'worker', 'builder'}, {'driver', 'operator', 'conductor', 'steward', 'childminder', 'caregiver', 'was', 'caretaker', 'companion', 'guide', 'escort', 'worker', 'minder', 'assistant', 'manager', 'carer', 'stewardess', 'supervisor', 'train', 'attendant', 'passenger', 'dispatcher'}, {'cabinetmaker', 'Carpenter', 'joiner', 'carpenter', 'maker'}, {'cabinetmaker', 'Carpenter', 'joiner', 'carpenter', 'maker'}, {'medic', 'professional', 'examiner', 'doctor', 'physician'}, {'sheriff', 'Sheriff'}, {'been', 'concierge', 'a', 'was', 'janitor', 'has', 'caretaker'}, {'housekeeper', 'then', 'concierge', 'doorman', 'janitor', 'attendant', 'held', 'caretaker'}, {'saleswoman', 'vendor', 'clerk', 'person', 'representative', 'salesman', 'lady', 'salesperson', 'seller', 'assistant'}, {'childminder', 'advisor', 'counsellor', 'caregiver', 'aide', 'was', 'has', 'caretaker', 'guide', 'worker', 'minder', 'assistant', 'carer', 'adviser', 'counselor', 'consultant', 'supervisor', 'Counselor', 'attendant'}, {'clerk', 'secretary'}, {'warden', 'manager', 'boss', 'was', 'superior', 'supervisor', 'guard', 'attendant'}, {'manager', 'headmistress', 'to', 'sought', 'chieftain', 'state', 'boss', 'visit', 'Head', 'was', 'Chief', 'head', 'chef', 'chief', 'leader', 'went'}, {'guard'}, {'sheriff'}, {'engineer', 'assembler', 'mechanics', 'technician', 'assemblyman', 'plumber', 'fitter', 'installer', 'mechanic'}, {'cleaner', 'man', 'cleaners', 'lady'}, {'sheriff', 'Sheriff'}, {'man', 'cleaner', 'cleaners', 'cleaning', 'lady'}, {'baker', 'worker', 'bakery'}, {'developer', 'receptionist', 'contractor', 'builder'}, {'caseworker', 'officer', 'servant', 'clerk', 'Employees', 'official', 'employees', 'employee', 'member', 'worker', 'cashier'}, {'particularly', 'contractor', 'especially', 'worker', 'builders', 'builder', 'greatly', 'workers', 'workman'}, {'receptionist'}, {'saleswoman', 'vendor', 'not', 'did', '&apos;t', 'salesman', 'salesperson', 'seller', 'displeased', 'assistant'}, {'receptionist'}, {'turned', 'advisor', 'adviser', 'taxman', 'consultant', 'bookkeeper', 'accountant'}, {'manager'}, {'cooks', 'the', 'chef', 'cook'}, {'manager', 'carer', 'boss', 'caregiver', 'superior', 'supervisor', 'minder', 'attendant', 'assistant'}, {'manager', 'chair', 'head', 'president', 'boss', 'Chair', 'Chairman', 'chairperson', 'President', 'Chief', 'chairman', 'chef', 'chief', 'leader'}, {'superintendent', 'custodian', 'boss', 'overseer', 'warden', 'guardian', 'advisor', 'She', 'Supervisor', 'He', 'caregiver', 'superior', 'guard', 'caretaker', 'worker', 'minder', 'assistant', 'chief', 'manager', 'carer', 'supervisor', 'hostess', 'attendant'}, {'Secretary', 'clerk', 'secretary'}, {'barrister', 'attorney', 'lawyer'}, {'auditor', 'examiner', 'of', 'Auditors', 'inspector', 'accountant'}, {'Analyst', 'analyst'}, {'warden', 'were', 'was', 'guard', 'attendant', 'guards'}, {'then', 'Workers', 'workwoman', 'labourer', 'employee', 'worker', 'workers', 'workmen', 'workman'}, {'analyst'}, {'receptionist'}, {'receptionist'}, {'supervisor'}, {'officer', 'caseworker', 'saleswoman', 'to', 'clerk', 'staff', 'official', 'administrator', 'employee', 'consultant', 'was', 'member', 'worker', 'assistant', 'cashier', 'went'}, {'superintendent', 'headmistress', 'then', 'headmaster', 'boss', 'Chairman', 'chef', 'She', 'president', 'He', 'principal', 'President', 'Head', 'director', 'chairman', 'chief', 'officer', 'manager', 'chair', 'supervisor', 'Chief', 'chairperson', 'head', 'leader', 'nurse'}, {'analyst'}, {'receptionist', 'took', 'was', 'worker', 'builder'}, {'guardian', 'watchdog', 'man', 'warden', 'Guards', 'Guard', 'keeper', 'guard', 'Guardian', 'attendant', 'watchman', 'guards', 'caretaker'}, {'warden', 'watchdog', 'man', 'superintendent', 'overseer', 'keeper', 'guard', 'Guardian', 'supervisor', 'attendant', 'watchman', 'guards', 'caretaker'}, {'developer', 'contractor', 'was', 'builder', 'owner', 'client'}, {'manager', 'director', 'Director', 'CEO'}, {'mechanic'}, {'warden', 'manager', 'carer', 'supervisors', 'boss', 'superior', 'guard', 'supervisor', 'minder', 'attendant', 'assistant', 'Supervisors'}, {'housekeeper', 'housewife', 'hostess', 'landlady', 'caretaker'}, {'superintendent', 'manager', 'carer', 'warden', 'counsellor', 'counselor', 'caregiver', 'consultant', 'superior', 'guard', 'supervisor', 'minder', 'attendant', 'assistant'}, {'cabinet', 'carpenter', 'Carpenter'}, {'plumber', 'assemblyman', 'mechanic', 'fitter'}, {'peasant', 'farmer'}, {'peasant', 'farmer'}, {'housekeeper', 'Caretaker', 'concierge', 'baker', 'thinks', 'janitor', 'caretaker'}, {'chef', 'cook'}, {'driver', 'bus'}, {'was', 'is', '&apos;s', 'mechanic'}, {'mechanics', 'mechanic'}, {'officer', 'man', 'removalist', 'mover', 'assistant', 'was', 'producer', 'worker', 'creator', 'maker'}, {'cabinetmaker', 'Carpenter', 'joiner', 'tailor', 'carpenter', 'maker', 'has'}, {'workers', 'worker', 'builder'}, {'warden', 'superintendent', 'manager', 'Supervisor', 'boss', 'Superior', 'guard', 'superior', 'supervisor', 'overseer', 'chief'}, {'manager', 'hired', 'boss', 'was', 'hostess', 'head', 'chef', 'chief'}, {'concierge', 'was', 'caretaker', 'janitor'}, {'analyst'}, {'sheriff'}, {'housekeeper', 'concierge', 'doorman', 'janitor', 'caretaker'}, {'driver', 'then', 'attacker', 'producer', 'makers', 'creator', 'aircraft', 'mower', 'engine', 'Mover', 'It', 'He', 'doer', 'culprit', 'mover', 'commander', 'maker', 'car', 'met', 'machine', 'rider', 'offender', 'agitator', 'van', 'Maker', 'assailant', 'perpetrator', 'plane', 'movers', 'truck', 'float', 'leader'}, {'developer', 'building', 'contractor', 'a', 'property', 'builder', 'filed', 'owner', 'client', 'developers'}, {'the', 'mechanic'}, {'had', 'Editor', 'editor', 'publisher', 'has'}, {'barrister', 'carer', 'lawyer', 'adviser', 'counsellor', 'attorney', 'defense', 'counselor', 'caregiver', 'consultant', 'aide', 'supervisor', 'defender', 'minder', 'defence'}, {'tailor', 'Tailor'}, {'stepped', 'peasant', 'in', 'farmer'}, {'warden', 'manager', 'carer', 'caregiver', 'maintainer', 'superior', 'guard', 'supervisor', 'worker', 'minder', 'attendant', 'childminder'}, {'headmistress', 'executive', 'custodian', 'headmaster', 'steward', 'was', 'principal', 'caretaker', 'Director', 'director', 'chief', 'manager', 'trustee', 'CEO', 'administrator', 'governor', 'supervisor', 'sacked', 'headteacher'}, {'driver', 'ambulance', 'removal', 'operator', 'producer', 'conductor', 'creator', 'mower', 'man', 'doer', 'mover', 'maker', 'car', 'the', 'worker', 'assistant', 'van', 'platoon', 'Maker', 'patient', 'move', 'relocation', 'procession', 'truck', 'train', 'float', 'leader', 'nurse'}, {'laborer', 'labourer', 'guilty', 'money', 'tailor', 'was', 'indebted', 'worker', 'workers', 'something', 'it', 'workman'}, {'housekeeper'}, {'Baker', 'bakery', 'baker', 'worker', 'sheriff'}, {'carer', 'companion', 'guide', 'escort', 'supervisor', 'minder', 'attendant', 'assistant'}, {'She', 'has', 'author', 'writer'}, {'chef', 'cook'}, {'She', 'analysts', 'analyst'}, {'medic', 'checked', 'examiner', 'doctor', 'physician'}, {'driver'}, {'mower', 'carrier', 'driver', 'mover', 'transporter', 'rider', 'designer', 'creators', 'movers', 'producer', 'makers', 'creator', 'manufacturer', 'maker', 'Maker'}, {'driver'}, {'developer', 'contractor', 'was', 'property', 'builder', 'negotiated'}, {'called', 'chief', 'boss'}, {'Doctor', 'doctor', 'physician'}, {'janitor', 'concierge', 'caretaker'}, {'manager', 'driver', 'boss', 'supervisor', 'train', 'chief', 'leader'}, {'workman', 'worker'}, {'sheriff', 'Sheriff'}, {'boss', 'Chief', 'editor', 'head', 'chief'}, {'was', 'chef', 'cook'}, {'saleswoman', 'vendor', 'salesman', 'seller', 'salesperson', 'assistant'}, {'barrister', 'attorney', 'lawyer', 'solicitor'}, {'often', 'frequently', 'farmer', 'peasant', 'the'}, {'not', 'cleaner', '&apos;t', 'lady', 't', 'cook'}, {'does', 'not', 'cleaner', '&apos;t', 'doesn', 't', 'chef', 'cook'}, {'laborer', 'Workers', 'labourer', 'employee', 'worker', 'will', 'workman'}, {'man', 'person', 'woman', 'cleaner', 'cleaners', 'lady', 'plasterer', 'worker'}, {'customer', 'client'}, {'manager', 'them', 'to', 'talk', 'interview', 'him', 'director', 'conversation', 'speak', 'chat'}, {'man', 'adolescent', 'woman', 'youth', 'teenager', 'youngster', 'teen'}, {'trusted', 'therapists', 'someone', 'therapist', 'entrusted', 'somebody'}, {'librarian'}, {'Librarian', 'librarian'}, {'advisor', 'adviser', 'counsellor', 'counselor', 'consultant', 'aide', 'has'}, {'advisor', 'adviser', 'counsellor', 'counselor', 'consultant', 'was', 'aide'}, {'customer', 'client'}, {'barman', 'tip', 'given', 'bartender', 'left', 'gave'}, {'She', 'patient', 'He'}, {'consultant', 'expert', 'specialist'}, {'doctor', 'Practitioner', 'practitioner', 'physician'}, {'Practitioner', 'practitioner'}, {'coroner', 'examiner', 'investigator', 'Investigators'}, {'examiner'}, {'barber', 'hairdresser', 'hairstylist'}, {'hairdresser', 'dresser', 'Someone', 'barber', 'hairstylist', 'was', 'stylist', 'has'}, {'coder', 'programmer'}, {'programmer'}, {'then', 'student'}, {'academic', 'researcher', 'scientists', 'scientist', 'him', 'scholar'}, {'dietitian', 'dietician', 'nutritionist'}, {'dietitian', 'dietician', 'nutritionist'}, {'painter', 'He', 'artist'}, {'painter', 'He', 'artist'}, {'broker', 'real', 'realtor', 'agent', 'brokerage'}, {'broker', 'real', 'realtor', 'agent', 'middleman', 'intermediary', 'has', 'Realtor', 'mediator'}, {'were', 'firefighter', 'service', 'have', 'brigade', 'department', 'fireman', 'crews', 'firefighters', 'Firefighters'}]\n",
      "329\n",
      "6.103343465045593\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#print(positions_ambiguous_words)\n",
    "\n",
    "lineNumber = 0\n",
    "counter = 0\n",
    "indices = []\n",
    "for align in alignments:\n",
    "    if (lineNumber == 100):\n",
    "        lineNumber = 0\n",
    "        counter += 1\n",
    "    position = positions_ambiguous_words[counter] # exact position of ambiguous word\n",
    "    indices.append([item[1] for item in (item for item in align if not(pd.isna(item[0]))) if item[0] == position][0])\n",
    "    lineNumber += 1\n",
    "\n",
    "print(len(indices))\n",
    "\n",
    "lineNumber = 0\n",
    "translations_ambiguous_words = [] # a list of set of translations to each ambiguous word in source\n",
    "translated_ambiguous_words = set() # set forces uniqueness\n",
    "for backtranslation in backtranslations:\n",
    "    if (lineNumber == 100):\n",
    "        translations_ambiguous_words.append(translated_ambiguous_words)\n",
    "        lineNumber = 0\n",
    "        translated_ambiguous_words = set()\n",
    "    backtranslation_index = backtranslations.index(backtranslation)\n",
    "    if not(pd.isna(indices[backtranslation_index])):\n",
    "        translated_ambiguous_words.add(backtranslation[indices[backtranslation_index]])\n",
    "    lineNumber += 1\n",
    "    \n",
    "print(translations_ambiguous_words)\n",
    "print(len(translations_ambiguous_words))\n",
    "\n",
    "unique_translations = 0\n",
    "for set_words in translations_ambiguous_words:\n",
    "    unique_translations += len(set_words)\n",
    "print(unique_translations/329)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be6fc6e-1e3c-41b3-8b38-aacd4210525d",
   "metadata": {},
   "source": [
    "### Extract target translated words to source words in disambiguated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "2b38e68b-9ead-4e71-a3d1-e09bb3531514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/data4/vzhekova/biases-data/Test_De/Statistics/Full_ambiguity\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "94c4ea19-21c6-4437-a68d-93ff98ef8ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33000\n",
      "33000\n"
     ]
    }
   ],
   "source": [
    "# List with original source sentences; output 100 times to match backtranslation size\n",
    "source = []\n",
    "with open('tok.en_disambiguated.en', 'r') as fin:\n",
    "    for line in fin:\n",
    "        for i in range(100): # append the source sentence 100 times to match backtranslations later\n",
    "            source.append(line.strip().split()) # split() tokenizes the sentence, because tercom expects tokens     \n",
    "\n",
    "print(len(source))\n",
    "\n",
    "# List with original backtranslations\n",
    "backtranslations = []\n",
    "with open('hyp_disambiguated_back.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        backtranslations.append(line.strip().split())\n",
    "        \n",
    "print(len(backtranslations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "895a67a1-d4cf-4a60-9ffa-fae2e75d2f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/data4/vzhekova/biases-data/Test_De/Statistics/Full_ambiguity/Perturbation-basedQE\n"
     ]
    }
   ],
   "source": [
    "%cd ./Perturbation-basedQE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "87286b7b-b25c-493e-b2b4-fbb0b6bfa8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import align_and_analyse_ambiguous_trans as tercom\n",
    "\n",
    "alignments = tercom.tercom_alignment(source, backtranslations)\n",
    "\n",
    "print(alignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "da6c3475-7b8a-44b9-8eda-56a93757d56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33000\n",
      "[{'developer', 'engineer', 'contractor', 'designer', 'was', 'builder', 'constructor', 'developers'}, {'handed', 'mechanic'}, {'mover'}, {'assistant', 'wizard'}, {'manager', 'tip', 'boss', 'head', 'tipped', 'chef', 'chief'}, {'saleswoman', 'vendor', 'librarian', 'salesman', 'seller', 'salesperson', 'assistant'}, {'barrister', 'man', 'lawyer', 'attorney', 'was'}, {'was', 'has', 'chef', 'cook'}, {'mover'}, {'peasant', 'farmer'}, {'manager', 'board', 'helping', 'executive', 'CEO', 'was', 'director', 'member', 'chairman'}, {'friend', 'hairdresser', 'became', 'barber', 'hairstylist', 'friends', 'made'}, {'developer', 'to', 'contractor', 'designer', 'was', 'builder', 'went'}, {'driver'}, {'Auditor', 'auditor', 'accountant', 'prover', 'reviewer', 'tester', 'inspector', 'investigator', 'auditors', 'examiner', 'verifier'}, {'manager', 'director', 'executive', 'CEO'}, {'warden', 'Guard', 'guard', 'attendant', 'guards'}, {'assistant', 'from', 'recommendation'}, {'assistant', 'from', 'recommendation'}, {'auditor', 'reviewer', 'inspector', 'examiner', 'cashier'}, {'saleswoman', 'vendor', 'salesman', 'was', 'seller', 'salesperson', 'assistant'}, {'manager', 'executive', 'then', 'CEO', 'director', 'sacked', 'managing'}, {'doctor', 'has', 'then', 'physician'}, {'man', 'raced', 'ran', 'was', 'worker', 'sped'}, {'man', 'husband', 'money', 'owes', 'doctor', 'physician'}, {'hairdresser', 'called', 'barber', 'hairstylist', 'was'}, {'developer'}, {'He', 'farmer', 'peasant', 'was', 'pawn', 'Farmer'}, {'hello', 'receptionist'}, {'manager', 'executive'}, {'housekeeper', 'man', 'woman', 'cleaner', 'cleanser', 'cleaners', 'lady'}, {'mechanics', 'then', 'mechanic'}, {'author', 'writers', 'had', 'novelist', 'was', 'has', 'writer'}, {'arranged', 'worker', 'builder', 'construction', 'set'}, {'publisher', 'editor'}, {'analyst'}, {'carpenters', 'is', 'joiner', 'carpenter'}, {'chef', 'cook'}, {'maker', 'cabinetmaker', 'joiner', 'carpenter'}, {'man', 'maid', 'woman', 'cleaner', 'cleaners', 'lady', 'shouted'}, {'laborer', 'top', 'then', 'labourer', 'in', 'up', 'employee', 'stepped', 'was', 'worker', 'walked', 'workman'}, {'mechanic', 'says'}, {'mechanics', 'mechanic', 'greeted'}, {'introduces', 'brings', 'teaches', 'chef', 'cook'}, {'peasant', 'farmer'}, {'manager', 'executive', 'boss', 'CEO', 'director', 'chairman', 'managing', 'has'}, {'librarian'}, {'would', 'chieftain', 'boss', 'was', 'lead', 'chiefs', 'Chief', 'head', 'chef', 'chief', 'leader'}, {'developer'}, {'carer', 'paramedics', 'then', 'driver', 'away', 'keeper', 'caregiver', 'ran', 'paramedic', 'worker', 'nurses', 'minder', 'attendant', 'off', 'caretaker', 'nurse'}, {'barrister', 'man', '&apos;s', 'lawyer', 'attorney'}, {'developer', 'engineer', 'then', 'contractor', 'designer', 'Developer', 'builder', 'developers'}, {'perpetrator', 'man', 'then', 'husband', 'guy', 'bought', 'He', 'offender', 'was', 'the', 'suspect', 'assailant', 'cashier'}, {'perpetrator', 'driver', 'operator', 'offender', 'conductor', 'mover', 'motorist', 'leader'}, {'were', 'was', 'worker', 'builders', 'workers', 'builder'}, {'Secretary', 'clerk', 'secretary'}, {'manager', 'executive', 'CEO', 'was', 'director'}, {'joiner', 'carpenter'}, {'cover', 'took', 'Sheriff', 'was', 'custody', 'protective', 'sheriff'}, {'was', 'mechanic'}, {'analysts', 'analyst'}, {'servant', 'staffer', 'staff', 'employee', 'aide', 'member', 'worker', 'sidekick', 'helper', 'attendant', 'assistant'}, {'manager', 'executive', 'boss', 'administration', 'administrator', 'director', 'principal', 'supervisor', 'head', 'chef', 'chief', 'leader'}, {'housekeeper', 'presented', 'concierge', 'janitor', 'book', 'caretaker'}, {'manager', 'director', 'executive', 'CEO'}, {'warden', 'manager', 'clerk', 'boss', 'inspector', 'superior', 'guard', 'supervisor', 'minder', 'attendant', 'steward', 'controller'}, {'boss', 'ruled'}, {'were', 'labourer', 'Builders', 'was', 'worker', 'builders', 'builder', 'workers', 'workmen', 'workman'}, {'saleswoman', 'vendor', 'money', 'salesman', 'seller', 'salesperson', 'assistant'}, {'barrister', '&apos;s', 'lawyer', 'attorney', 'solicitor', 'explained'}, {'developer', 'contractor', 'librarian', 'builder'}, {'sheriff', 'Sheriff'}, {'housekeeper', 'concierge', 'had', 'janitor', 'caretaker'}, {'was', 'worker', 'employee'}, {'was', 'driver'}, {'officer', 'man', 'then', 'removalist', 'husband', 'He', 'was', 'worker', 'attendant', 'assistant'}, {'developer', 'Developer', 'contractor', 'builder'}, {'housekeeper', 'concierge', 'was', 'janitor', 'caretaker'}, {'saleswoman', 'vendor', 'clerk', 'salesman', 'seller', 'salesperson', 'asked', 'assistant'}, {'manager', 'listened', 'boss', 'was', 'conductor', 'supervisor', 'head', 'has', 'chef', 'chief', 'leader', 'could'}, {'laborer', 'labourer', 'handed', 'worker', 'held', 'hammer', 'workman'}, {'Guard', 'guard', 'were', 'guards'}, {'carer', 'then', 'nurses', 'was', 'paramedic', 'worker', 'carpenter', 'caretaker', 'nurse'}, {'handed', 'passed', 'worker', 'builder'}, {'passed', 'worker', 'then', 'employee'}, {'barrister', 'attorney', 'lawyer', 'solicitor'}, {'manager', 'executive', 'cash', 'over', 'CEO', 'director', 'chairman'}, {'then', 'labourer', 'employee', 'handed', 'worker', 'helper', 'held', 'hammer', 'workman'}, {'laborer', 'labourer', 'employee', 'was', 'worker', 'workman'}, {'carer', 'paramedics', 'keeper', 'caregiver', 'paramedic', 'worker', 'Nurses', 'Paramedics', 'caretaker', 'nurse'}, {'manager', 'director', 'executive'}, {'guard', 'attendant'}, {'developer', 'contractor', 'builder'}, {'driver'}, {'manager'}, {'peasant', 'farmer'}, {'analyst'}, {'superior', 'supervisor'}, {'worker'}, {'has', 'cabinetmaker', 'joiner', 'carpenter'}, {'contractor', 'He', 'was', 'worker', 'builder', 'workers', 'workman'}, {'manager', 'executive'}, {'peasant', 'farmer'}, {'manager', 'executive', 'CEO'}, {'saleswoman', 'vendor', 'shopkeeper', 'clerk', 'person', 'salesman', 'lady', 'seller', 'salesperson', 'assistant', 'salesmen'}, {'rider', 'driver', 'then'}, {'worker', 'builder'}, {'guardian', 'manager', 'warden', 'librarian', 'boss', 'superior', 'guard', 'supervisor', 'overseer'}, {'barrister', 'librarian', 'lawyer', 'advocate', 'attorney', 'solicitor'}, {'analyst'}, {'warden', 'manager', 'boss', 'superior', 'guard', 'supervisor', 'attendant'}, {'contractor', 'had', 'He', 'workman', 'baker', 'worker', 'builder', 'has'}, {'turned', 'manager', 'executive', 'boss', 'CEO', 'director', 'chairman', 'has', 'chef'}, {'manager', 'director', 'executive'}, {'vendor', 'called', 'shopkeeper', 'salesman', 'seller', 'worker', 'salesperson', 'demanded', 'assistant'}, {'driver'}, {'receptionist', 'his', 'farmer', 'peasant', 'pawn', 'builder'}, {'guardsman', 'Guards', 'Guard', 'guard', 'attendant', 'guards', 'sentry'}, {'manager', 'general', 'executive', 'boss', 'CEO', 'business', 'was', 'director', 'used', 'managing', 'chef', 'chief'}, {'examiner', 'doctor', 'physician'}, {'manager', 'director', 'executive', 'CEO'}, {'analysts', 'analyst'}, {'driver', 'contractor', 'operator', 'producer', 'conductor', 'creator', 'man', 'removalist', 'remover', 'employee', 'firm', 'company', 'doer', 'mover', 'commander', 'maker', 'worker', 'assistant', 'agitator', 'husband', 'attendant', 'leader'}, {'manager', 'executive', 'then', 'CEO', 'director'}, {'laborer', 'librarian', 'bookshelf', 'labourer', 'worker', 'helper', 'assistant', 'workman', 'set', 'bookcase'}, {'peasant', 'farmer'}, {'sheriff', 'was', 'then', 'Sheriff'}, {'analyst'}, {'Guard', 'guard', 'security', 'guards'}, {'mechanic'}, {'maker', 'joiner', 'carpenter'}, {'also', 'then', 'office', 'Sheriff', 'a', 'sheriff', 'filed', 'has', 'lodged'}, {'manager', 'executive'}, {'confides', 'Sheriff', 'relies', 'sheriff', 'confidence', 'has'}, {'to', 'respect', 'have', 'chefs', 'respectful', 'should', 'cooks', 'must', 'chef', 'cook'}, {'driver', 'then', 'contractor', 'operator', 'producer', 'creator', 'man', 'removalist', 'agent', 'remover', 'employee', 'firm', 'was', 'company', 'doer', 'mover', 'maker', 'took', 'offender', 'worker', 'agitator', 'assailant', 'perpetrator', 'manager', 'movers', 'abuser'}, {'Analyst', 'analysts', 'analyst'}, {'sheriff', 'is', 'Sheriff'}, {'saleswoman', 'vendor', 'clerk', 'salesman', 'was', 'seller', 'salesperson', 'assistant'}, {'manager', 'executive', 'CEO', 'director', 'editor', 'chairman', 'has'}, {'was', 'caretaker', 'cleared', 'janitor'}, {'controller', 'supervisor', 'inspector'}, {'developer', 'engineer', 'turned', 'designer', 'maintainer', 'Developer', 'editor', 'contributor', 'writer', 'developers'}, {'told', 'librarian', 'was', 'guard', 'attendant', 'guards'}, {'driver'}, {'driver'}, {'manager', 'called', 'boss', 'teacher', 'principal', 'asked', 'head', 'chef', 'chief', 'leader'}, {'wrote', 'Doctor', 'He', 'the', 'doctor', 'physician'}, {'sheriff', 'was', 'Sheriff'}, {'mechanics', 'then', 'mechanic', 'engineer'}, {'developer', 'developers'}, {'turned', 'touch', 'then', 'Doctor', 'contact', 'doctor', 'physician', 'went'}, {'was', 'mechanic'}, {'man', 'user', 'driver', 'maker', 'creator', 'remonstrated', 'operator', 'bully', 'producer', 'doer', 'mover', 'examiner', 'commander', 'passenger', 'leader'}, {'manager', 'then', 'boss', 'head', 'has', 'chef', 'chief'}, {'doctor', 'then', 'physician'}, {'man', 'then', 'husband', 'guy', 'farmers', 'He', 'farmer', 'peasant', 'a', 'pawn'}, {'turned', 'saleswoman', 'vendor', 'shopkeeper', 'clerk', 'representative', 'person', 'then', 'sellers', 'reported', 'salesman', 'lady', 'salesperson', 'seller', 'shopper', 'assistant'}, {'housekeeper', 'turned', 'concierge', 'remonstrated', 'janitor', 'caretaker'}, {'manager', 'then', 'boss', 'has', 'chef', 'chief'}, {'barrister', 'lawyer', 'advocate', 'attorney', 'solicitor', 'counsel'}, {'laborer', 'been', 'labourer', 'employee', 'workman', 'worker', 'has'}, {'struck', 'chef', 'cook'}, {'analyst'}, {'guardian', 'Guards', 'Guard', 'guard', 'sentry'}, {'barrister', 'lawyer', 'advocate', 'attorney', 'solicitor', 'respectful', 'was', 'counsel'}, {'manager', 'executive', 'appealed', 'boss', 'CEO', 'director', 'chairman', 'chef'}, {'carpenter', 'cabinetmaker', 'joiner'}, {'barrister', 'lawyer', 'attorney', 'solicitor', 'has'}, {'manager', 'executive', 'then', 'CEO', 'was', 'director'}, {'perpetrator', 'assailant', 'offender'}, {'Farmer', 'He', 'farmer', 'peasant', 'Farmers', 'editor', 'pawn', 'writer'}, {'farmer', 'baker', 'peasant', 'was', 'asked'}, {'guard', 'guards'}, {'perpetrator', 'man', 'receptionist', 'then', 'husband', 'guy', 'He', 'offender', 'attacker', 'abuser', 'suspect', 'assailant'}, {'guardian', 'warden', 'Guards', 'custodian', 'Guard', 'guard', 'Guardian', 'attendant', 'watchman', 'guards', 'caretaker'}, {'analyst'}, {'was', 'chef', 'cook'}, {'driver'}, {'manager', 'director', 'executive', 'CEO'}, {'driver'}, {'saleswoman', 'vendor', 'assistant', 'salesman', 'seller', 'salesperson', 'shop', 'sales'}, {'was', 'chef', 'cook'}, {'barrister', 'lawyer', 'advocate', 'attorney', 'solicitor', 'was', 'counsel'}, {'board', 'manager', 'executive', 'head', 'boss', 'CEO', 'was', 'director', 'walked', 'chairman', 'chef', 'chief'}, {'mechanic'}, {'doctor', 'physician'}, {'was', 'joiner', 'carpenter'}, {'warden', 'guardian', 'carer', 'manager', 'superintendent', 'custodian', 'boss', 'keeper', 'superior', 'guard', 'supervisor', 'steward', 'attendant', 'minder', 'overseer', 'caretaker'}, {'janitor', 'newspapers', 'day', 'caretaker'}, {'barrister', 'attorney', 'lawyer', 'solicitor'}, {'told', 'worker', 'librarian', 'builder'}, {'companion', 'driver', 'guide', 'then', 'escort', 'conductor', 'train', 'attendant', 'steward', 'passenger'}, {'cabinetmaker', 'Carpenter', 'joiner', 'master', 'is', 'carpenter', 'will'}, {'cabinetmaker', 'Carpenter', 'for', 'joiner', 'master', 'is', 'carpenter', 'will'}, {'doctor', 'physician'}, {'sheriff', 'Sheriff'}, {'janitor', 'a', 'caretaker'}, {'housekeeper', 'then', 'concierge', 'doorman', 'janitor', 'attendant', 'caretaker'}, {'saleswoman', 'vendor', 'clerk', 'shopkeeper', 'person', 'representative', 'then', 'lady', 'salesman', 'seller', 'salesperson', 'worker', 'assistant', 'thank'}, {'carer', 'advisor', 'adviser', 'guide', 'counsellor', 'counselor', 'caregiver', 'consultant', 'was', 'aide', 'supervisor', 'minder', 'attendant', 'has', 'caretaker'}, {'clerk', 'secretary'}, {'warden', 'manager', 'receptionist', 'boss', 'superior', 'guard', 'supervisor', 'was', 'attendant'}, {'manager', 'men', 'to', 'chieftain', 'state', 'boss', 'a', 'was', 'Chief', 'head', 'chef', 'chief', 'leader', 'went'}, {'guardian', 'guard'}, {'sheriff'}, {'mechanics', 'then', 'mechanic', 'engineer'}, {'cleaner', 'man', 'cleaners', 'lady'}, {'also', 'office', 'Sheriff', 'was', 'sheriff', 'critical'}, {'cleaner', 'man', 'lady'}, {'baker', 'was', 'bakers', 'bakery'}, {'developer', 'engineer', 'receptionist'}, {'officer', 'caseworker', 'servant', 'Secretary', 'clerk', 'staff', 'secretary', 'official', 'employees', 'employee', 'officers', 'member', 'worker', 'cashier'}, {'marvels', 'contractor', 'much', 'is', 'worker', 'builder', 'greatly'}, {'receptionist'}, {'saleswoman', 'vendor', 'not', '&apos;t', 'salesman', 'salesperson', 'seller', 'assistant'}, {'receptionist'}, {'advisor', 'then', 'adviser', 'consultant', 'accountants', 'bookkeeper', 'accountant'}, {'manager', 'executive'}, {'cooks', 'chef', 'cook'}, {'guardian', 'manager', 'superiors', 'custodian', 'boss', 'superior', 'guard', 'supervisor', 'minder', 'attendant', 'caretaker'}, {'manager', 'men', 'then', 'chair', 'president', 'boss', 'Chairman', 'chairperson', 'President', 'head', 'chairman', 'chef', 'chief', 'leader'}, {'superintendent', 'supervisors', 'executive', 'custodian', 'boss', 'steward', 'overseer', 'warden', 'guardian', 'caregiver', 'superior', 'guard', 'attendee', 'caretaker', 'superiors', 'minder', 'assistant', 'manager', 'carer', 'supervisor', 'supervision', 'attendant'}, {'clerk', 'secretary'}, {'barrister', 'lawyer', 'attorney', 'solicitor', 'counsel'}, {'examiner', 'auditor', 'accountant', 'inspector'}, {'went', 'analyst'}, {'warden', 'guardian', 'were', 'Guard', 'guard', 'was', 'attendant', 'guards'}, {'laborer', 'then', 'labourer', 'employees', 'referred', 'employee', 'worker', 'workers', 'workmen', 'workman', 'shouted'}, {'analyst'}, {'receptionist'}, {'receptionist'}, {'superior', 'supervisor'}, {'officer', 'caseworker', 'saleswoman', 'to', 'clerk', 'staff', 'official', 'administrator', 'employee', 'consultant', 'was', 'member', 'worker', 'assistant', 'cashier', 'went'}, {'officer', 'manager', 'then', 'executive', 'chieftain', 'boss', 'He', 'principal', 'Chief', 'chiefs', 'head', 'commander', 'chef', 'chief', 'leader'}, {'analysts', 'analyst'}, {'contractor', 'receptionist', 'worker', 'builder'}, {'warden', 'guardian', 'custodian', 'Guard', 'guard', 'Guardian', 'attendant', 'watchman', 'guards', 'caretaker'}, {'warden', 'guardian', 'custodian', 'Guard', 'guard', 'attendant', 'guards', 'caretaker'}, {'developer', 'engineer', 'were', 'contractor', 'was', 'builder', 'developers'}, {'manager', 'director', 'executive', 'CEO'}, {'is', 'mechanic'}, {'warden', 'manager', 'carer', 'boss', 'superior', 'guard', 'supervisor', 'minder', 'attendant'}, {'janitor', 'housekeeper', 'pointed', 'caretaker'}, {'guardian', 'manager', 'carer', 'boss', 'caregiver', 'superior', 'supervisor', 'minder', 'attendant'}, {'Carpenter', 's', 'carpentry', 'master', 'cabinet', 'carpenter'}, {'guy', 'was', 'man', 'mechanic'}, {'farmer'}, {'farmer'}, {'housekeeper', 'concierge', 'baker', 'janitor', 'caretaker'}, {'chef', 'cook'}, {'was', 'driver'}, {'been', '&apos;s', 'kept', 'was', 'is', 'has', 'mechanic'}, {'mechanics', 'mechanic'}, {'man', 'creator', 'removalist', 'assistant', 'was', 'agitator', 'producer', 'worker', 'attendant', 'mover'}, {'cabinetmaker', 'Carpenter', 'joiner', 'master', 'carpenter', 'came'}, {'workers', 'worker', 'builder'}, {'superintendent', 'manager', 'warden', 'superiors', 'executive', 'boss', 'superior', 'guard', 'supervisor', 'attendant', 'overseer', 'chief'}, {'manager', 'hired', 'boss', 'was', 'chef', 'chief'}, {'concierge', 'was', 'caretaker', 'janitor'}, {'will', 'is', 'analysts', 'analyst'}, {'sheriff', 'Sheriff'}, {'housekeeper', 'concierge', 'doorman', 'janitor', 'caretaker'}, {'perpetrator', 'man', 'then', 'driver', 'lashed', 'offender', 'movers', 'abuser', 'agitator', 'attacker', 'culprit', 'mover', 'slammed', 'assailant'}, {'developer', 'engineer', 'contractor', 'builder', 'developers'}, {'was', 'mechanic'}, {'reader', 'publisher', 'had', 'editor'}, {'carer', 'adviser', 'counsellor', 'counselor', 'caregiver', 'consultant', 'aide', 'supervisor', 'minder', 'attendant'}, {'tailor', 'dressmaker'}, {'then', 'up', 'in', 'trod', 'farmer', 'stepped', 'peasant', 'pawn', 'on'}, {'warden', 'guardian', 'carer', 'manager', 'boss', 'caregiver', 'superior', 'guard', 'supervisor', 'minder', 'attendant'}, {'manager', 'executive', 'librarian', 'headmaster', 'CEO', 'was', 'director', 'principal', 'supervisor', 'head', 'chief', 'leader', 'sacked'}, {'man', 'removal', 'creator', 'husband', 'assistant', 'producer', 'doer', 'worker', 'mover', 'maker', 'Maker'}, {'laborer', 'owed', 'force', 'helper', 'workers', 'slave', 'guilty', 'employee', 'aide', 'was', 'indebted', 'workmen', 'manservant', 'labourer', 'worker', 'something', 'assistant', 'laborers', 'servant', 'farmer', 'workforce', 'workman'}, {'housekeeper'}, {'baker', 'man', 'Baker', 'bakery'}, {'carer', 'companion', '&apos;s', 'escort', 'supervisor', 'minder', 'attendant'}, {'author', 'has', 'writer', 'He'}, {'chef', 'cook'}, {'analysts', 'analyst'}, {'was', 'doctor', 'Doctors', 'physician'}, {'driver', 'then'}, {'model', 'photographer', 'man', 'driver', 'creator', 'husband', 'He', 'rider', 'designer', 'creators', 'movers', 'producer', 'agitator', 'makers', 'mover', 'maker', 'Maker'}, {'driver'}, {'developer', 'contractor', 'designer', 'was', 'builder'}, {'called', 'chief', 'boss'}, {'doctor', 'physician'}, {'janitor', 'housekeeper', 'concierge', 'caretaker'}, {'manager', 'man', 'driver', 'guide', 'boss', 'superior', 'conductor', 'supervisor', 'ringleader', 'captain', 'chief', 'leader'}, {'was', 'worker'}, {'sheriff', 'called', 'Sheriff'}, {'boss', 'chief', 'editor'}, {'did', 'was', 'chef', 'cook'}, {'vendor', 'seller', 'salesperson', 'salesman'}, {'barrister', '&apos;s', 'lawyer', 'attorney', 'solicitor', 'the'}, {'often', 'peasant', 'frequently', 'farmer'}, {'man', 'not', 'cleaner', '&apos;t', 'lady', 'don'}, {'does', 'not', '&apos;t', 'doesn', 'chef', 'cook'}, {'laborer', 'labourer', 'employee', 'worker', 'workers', 'workman'}, {'man', 'woman', 'cleaner', 'cleaners', 'lady', 'worker'}, {'customer', 'client'}, {'manager', 'them', 'executive', 'CEO', 'talk', 'interview', 'him', 'conversation', 'chat'}, {'man', 'adolescent', 'then', 'juvenile', 'entrusted', 'youth', 'teenager', 'boy', 'teen', 'male'}, {'in', 'therapists', 'someone', 'therapist'}, {'librarian'}, {'librarian'}, {'advisor', 'adviser', 'counsellor', 'counselor', 'consultant', 'has'}, {'advisor', 'adviser', 'counsellor', 'counselor', 'consultant', 'was', 'aide'}, {'customer', 'client'}, {'barman', 'to', 'tip', 'given', 'bartender', 'for'}, {'has', 'patient'}, {'consultant', 'specialist', 'professional', 'male', 'expert', 'specialists'}, {'practitioner'}, {'practitioner'}, {'investigator', 'examiner'}, {'examiner'}, {'stylist', 'hairdresser', 'hairstylist', 'barber'}, {'hairdresser', 'dresser', 'barber', 'hairstylist', 'the', 'stylist', 'hairdressers'}, {'coder', 'programmer'}, {'programmers', 'coder', 'programmer'}, {'bachelor', 'undergraduate', 'then', 'student', 'Bachelor', 'was'}, {'academic', 'researcher', 'scientists', 'scientist', 'him'}, {'dietitian', 'dietician', 'nutritionist'}, {'dietitian', 'dietician', 'nutritionist'}, {'painter', 'artist'}, {'painter', 'artist'}, {'broker', 'realtor', 'agent', 'intermediary', 'mediator'}, {'broker', 'real', 'realtor', 'agent', 'estate', 'named'}, {'were', 'firefighter', 'service', 'brigade', 'department', 'fireman', 'Firefighter', 'crews', 'firefighters', 'Firefighters'}]\n",
      "329\n",
      "5.492401215805471\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#print(positions_ambiguous_words)\n",
    "\n",
    "lineNumber = 0\n",
    "counter = 0\n",
    "indices = []\n",
    "for align in alignments:\n",
    "    if (lineNumber == 100):\n",
    "        lineNumber = 0\n",
    "        counter += 1\n",
    "    position = positions_ambiguous_words[counter] + 1 # exact position of ambiguous word; skip gender word\n",
    "    indices.append([item[1] for item in (item for item in align if not(pd.isna(item[0]))) if item[0] == position][0])\n",
    "    lineNumber += 1\n",
    "\n",
    "print(len(indices))\n",
    "\n",
    "lineNumber = 0\n",
    "translations_ambiguous_words = [] # a list of set of translations to each ambiguous word in source\n",
    "translated_ambiguous_words = set() # set forces uniqueness\n",
    "for backtranslation in backtranslations:\n",
    "    if (lineNumber == 100):\n",
    "        translations_ambiguous_words.append(translated_ambiguous_words)\n",
    "        lineNumber = 0\n",
    "        translated_ambiguous_words = set()\n",
    "    backtranslation_index = backtranslations.index(backtranslation)\n",
    "    if not(pd.isna(indices[backtranslation_index])):\n",
    "        translated_ambiguous_words.add(backtranslation[indices[backtranslation_index]])\n",
    "    lineNumber += 1\n",
    "    \n",
    "print(translations_ambiguous_words)\n",
    "print(len(translations_ambiguous_words))\n",
    "\n",
    "unique_translations = 0\n",
    "for set_words in translations_ambiguous_words:\n",
    "    unique_translations += len(set_words)\n",
    "print(unique_translations/329)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ed5a47-8fd1-44cb-839b-1f203060d165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
