{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cdda832e-2b3e-461f-824b-c21333c568d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.enabled = False \n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "PATH=\"/export/data4/vzhekova/biases-data/Test_De/Statistics/BERT/Sampling\"\n",
    "FASTBPE=\"/home/vzhekova/fastBPE/fast\" # path to the fastBPE tool\n",
    "FAST_ALIGN=\"/home/vzhekova/fast_align/build/fast_align\" # path to the fast_align tool\n",
    "TERCOM = \"/export/data4/vzhekova/biases-data/Test_De/Statistics/Full_ambiguity_male/Perturbation-basedQE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69abd178-8491-49cc-b0f8-10d934456800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# check if we can connect to the GPU with PyTorch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.current_device()\n",
    "    print('Current device:', torch.cuda.get_device_name(device))\n",
    "else:\n",
    "    print('Failed to find GPU. Will use CPU.')\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04b7cd22-fef2-4c78-ae6a-1ca52b8dec8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/data4/vzhekova/biases-data/Test_De/Statistics/BERT/Sampling\n"
     ]
    }
   ],
   "source": [
    "%cd $PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f7ca5f-b68b-471f-a2ce-099326bc7e7c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Translation English-German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "60f5c7a3-9565-415c-951a-5615e36f6e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished tokenizing.\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "from sacremoses import MosesPunctNormalizer\n",
    "from sacremoses import MosesTokenizer, MosesDetokenizer\n",
    "from __future__ import print_function\n",
    "\n",
    "mpn = MosesPunctNormalizer()\n",
    "mt_en = MosesTokenizer(lang='en')\n",
    "md_en = MosesDetokenizer(lang='en')\n",
    "\n",
    "with open('en_original.txt') as fin, open('tok.en_original.en','w') as fout:\n",
    "    for line in fin:\n",
    "        tokens = mt_en.tokenize(mpn.normalize(line), return_str=True)\n",
    "        print(tokens, end='\\n', file=fout) \n",
    "\n",
    "print('Finished tokenizing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "51e307f4-4cd9-435c-8f5b-ef71ccba6837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading codes from bpecodes.en ...\n",
      "Read 30000 codes from the codes file.\n",
      "Loading vocabulary from tok.en_original.en ...\n",
      "Read 245 words (147 unique) from text file.\n",
      "Applying BPE to tok.en_original.en ...\n",
      "Modified 245 words from text file.\n",
      "Finished subword.\n"
     ]
    }
   ],
   "source": [
    "# Dividing text into subword units\n",
    "\n",
    "!$FASTBPE applybpe bpe.en_original.en tok.en_original.en bpecodes.en\n",
    "\n",
    "print('Finished subword.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "bc583ff2-8071-4860-bb1b-83bd491f5e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-09 15:10:42 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin_original_en-de', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=True, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='en', srcdict='/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/dict.en.txt', suppress_crashes=False, target_lang='de', task='translation', tensorboard_logdir=None, testpref='bpe.en_original', tgtdict='/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/dict.de.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=8)\n",
      "2023-10-09 15:10:42 | INFO | fairseq_cli.preprocess | [en] Dictionary: 42024 types\n",
      "2023-10-09 15:10:42 | INFO | fairseq_cli.preprocess | [en] bpe.en_original.en: 10 sents, 295 tokens, 0.0% replaced (by <unk>)\n",
      "2023-10-09 15:10:42 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin_original_en-de\n",
      "Finished preprocessing.\n"
     ]
    }
   ],
   "source": [
    "# Binarize text\n",
    "!fairseq-preprocess \\\n",
    "    --source-lang en \\\n",
    "    --target-lang de \\\n",
    "    --testpref bpe.en_original \\\n",
    "    --only-source \\\n",
    "    --srcdict /export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/dict.en.txt \\\n",
    "    --tgtdict /export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/dict.de.txt \\\n",
    "    --destdir data-bin_original_en-de \\\n",
    "    --workers 8\n",
    "\n",
    "print('Finished preprocessing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c19e718-e81a-43a6-bfbd-bd85db379f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-26 10:57:56 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model1.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model2.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model3.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model4.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 4, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 4, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 50, 'beam_mt': 0, 'nbest': 50, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': True, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 0.9, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}, 'task': {'_name': 'translation', 'data': 'data-bin_original_en-de', 'source_lang': 'en', 'target_lang': 'de', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-10-26 10:57:56 | INFO | fairseq.tasks.translation | [en] dictionary: 42024 types\n",
      "2023-10-26 10:57:56 | INFO | fairseq.tasks.translation | [de] dictionary: 42024 types\n",
      "2023-10-26 10:57:56 | INFO | fairseq_cli.generate | loading model(s) from /export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model1.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model2.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model3.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model4.pt\n",
      "2023-10-26 10:58:31 | INFO | fairseq.data.data_utils | loaded 10 examples from: data-bin_original_en-de/test.en-de.en\n",
      "2023-10-26 10:58:31 | INFO | fairseq.tasks.translation | data-bin_original_en-de test en-de 10 examples\n",
      "2023-10-26 10:59:04 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2023-10-26 10:59:04 | INFO | fairseq_cli.generate | Translated 10 sentences (280 tokens) in 28.4s (0.35 sentences/s, 9.86 tokens/s)\n",
      "Finished translation.\n"
     ]
    }
   ],
   "source": [
    "MODELS=\"/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble\"\n",
    "\n",
    "# Generate translations\n",
    "!fairseq-generate data-bin_original_en-de  \\\n",
    "    --task translation \\\n",
    "    --source-lang en \\\n",
    "    --target-lang de \\\n",
    "    --path $MODELS/model1.pt:$MODELS/model2.pt:$MODELS/model3.pt:$MODELS/model4.pt \\\n",
    "    --sampling \\\n",
    "    --temperature 0.9 \\\n",
    "    --beam 50 \\\n",
    "    --nbest 50 \\\n",
    "    --batch-size 4 \\\n",
    "    --memory-efficient-fp16 \\\n",
    "    --remove-bpe > original_en-de.decode_Beam_10.log\n",
    "\n",
    "print('Finished translation.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dbb5ab07-b223-43cb-b556-8efc0a65774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'LC_ALL=C sort -V' sorts the results in natural order \n",
    "!grep ^H original_en-de.decode_Beam_10.log | LC_ALL=C sort -V | sed 's/^H-//g' | cut -f 3 | sed 's/ @@//g' > ./hyp_original_50.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a15bf7e-4f56-43db-a03e-df26e7e57ed1",
   "metadata": {},
   "source": [
    "## Extract 10 unique sentences for every source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "47d427e0-5768-4b5b-b6bf-7920163375a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# List with nbest sentences for every source in original\n",
    "nbest_original = []\n",
    "counter = 0\n",
    "temp = []\n",
    "with open('hyp_original_50.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        temp.append(line.strip())\n",
    "        counter += 1\n",
    "        if (counter == 50):\n",
    "            nbest_original.append(temp)\n",
    "            counter = 0\n",
    "            temp = []\n",
    "\n",
    "#print(nbest_original)\n",
    "\n",
    "sent_hyp = []\n",
    "for elem in nbest_original:\n",
    "    unique_sent = set()\n",
    "    for sent in elem:\n",
    "        unique_sent.add(sent)\n",
    "        if (len(unique_sent) == 10):\n",
    "            sent_hyp.extend(list(unique_sent))\n",
    "            break\n",
    "        \n",
    "print (len(sent_hyp))\n",
    "\n",
    "with open('hyp_original.txt','w') as fout:\n",
    "    for sent in sent_hyp:\n",
    "        print(sent, end='\\n', file=fout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c991ccb1-fe5f-43ec-a705-cb23f7501d49",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Backtranslation German-English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9dca07e1-6f67-405a-bd11-b104b24b8ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading codes from bpecodes.de ...\n",
      "Read 30000 codes from the codes file.\n",
      "Loading vocabulary from hyp_original.txt ...\n",
      "Read 2189 words (363 unique) from text file.\n",
      "Applying BPE to hyp_original.txt ...\n",
      "Modified 2189 words from text file.\n",
      "Finished subword.\n"
     ]
    }
   ],
   "source": [
    "# Dividing tokenized text into subword units\n",
    "\n",
    "!$FASTBPE applybpe bpe.hyp_original.de hyp_original.txt bpecodes.de\n",
    "\n",
    "print('Finished subword.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc5c8273-dcab-4968-b1b0-daad6cf9ac84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-26 11:07:24 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin_original_de-en', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=True, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='de', srcdict='/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/dict.de.txt', suppress_crashes=False, target_lang='en', task='translation', tensorboard_logdir=None, testpref='bpe.hyp_original', tgtdict='/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/dict.en.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=8)\n",
      "2023-10-26 11:07:24 | INFO | fairseq_cli.preprocess | [de] Dictionary: 42024 types\n",
      "2023-10-26 11:07:24 | INFO | fairseq_cli.preprocess | [de] bpe.hyp_original.de: 100 sents, 2828 tokens, 0.0354% replaced (by <unk>)\n",
      "2023-10-26 11:07:24 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin_original_de-en\n",
      "Finished preprocessing.\n"
     ]
    }
   ],
   "source": [
    "!fairseq-preprocess \\\n",
    "    --source-lang de \\\n",
    "    --target-lang en \\\n",
    "    --only-source \\\n",
    "    --testpref bpe.hyp_original \\\n",
    "    --srcdict /export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/dict.de.txt \\\n",
    "    --tgtdict /export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/dict.en.txt \\\n",
    "    --destdir data-bin_original_de-en \\\n",
    "    --workers 8\n",
    "\n",
    "print('Finished preprocessing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0d3103e1-be7b-4282-8285-17fe87c4b724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-26 11:19:32 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model1.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model2.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model3.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model4.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 4, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 4, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 100, 'beam_mt': 0, 'nbest': 100, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': True, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 0.8, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}, 'task': {'_name': 'translation', 'data': 'data-bin_original_de-en', 'source_lang': 'de', 'target_lang': 'en', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-10-26 11:19:32 | INFO | fairseq.tasks.translation | [de] dictionary: 42024 types\n",
      "2023-10-26 11:19:32 | INFO | fairseq.tasks.translation | [en] dictionary: 42024 types\n",
      "2023-10-26 11:19:32 | INFO | fairseq_cli.generate | loading model(s) from /export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model1.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model2.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model3.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model4.pt\n",
      "2023-10-26 11:20:08 | INFO | fairseq.data.data_utils | loaded 100 examples from: data-bin_original_de-en/test.de-en.de\n",
      "2023-10-26 11:20:08 | INFO | fairseq.tasks.translation | data-bin_original_de-en test de-en 100 examples\n",
      "2023-10-26 11:22:14 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2023-10-26 11:22:14 | INFO | fairseq_cli.generate | Translated 100 sentences (2,486 tokens) in 104.4s (0.96 sentences/s, 23.81 tokens/s)\n",
      "Finished translation.\n"
     ]
    }
   ],
   "source": [
    "MODELS=\"/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble\"\n",
    "\n",
    "# Generate backtranslations\n",
    "!fairseq-generate data-bin_original_de-en  \\\n",
    "    --task translation \\\n",
    "    --source-lang de \\\n",
    "    --target-lang en \\\n",
    "    --path $MODELS/model1.pt:$MODELS/model2.pt:$MODELS/model3.pt:$MODELS/model4.pt \\\n",
    "    --sampling \\\n",
    "    --beam 50 \\\n",
    "    --nbest 50 \\\n",
    "    --batch-size 4 \\\n",
    "    --memory-efficient-fp16 \\\n",
    "    --remove-bpe > original_de-en.decode_Beam_10_backtranslation.log\n",
    "\n",
    "print('Finished translation.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "07101bae-8870-4068-bcc1-28604d30f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'LC_ALL=C sort -V' sorts the results in natural order \n",
    "!grep ^H original_de-en.decode_Beam_10_backtranslation.log | LC_ALL=C sort -V | sed 's/^H-//g' | cut -f 3 | sed 's/ @@//g' > ./hyp_original_back_50.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92796834-c2ff-4d40-9b76-ab53c17a84c9",
   "metadata": {},
   "source": [
    "## Extract 10 unique sentences for every source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6c663929-9df2-492b-b167-3cd4a1449521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "# List with nbest sentences for every source in original\n",
    "nbest_original = []\n",
    "counter = 0\n",
    "temp = []\n",
    "with open('hyp_original_back_50.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        temp.append(line.strip())\n",
    "        counter += 1\n",
    "        if (counter == 50):\n",
    "            nbest_original.append(temp)\n",
    "            counter = 0\n",
    "            temp = []\n",
    "\n",
    "#print(nbest_original)\n",
    "\n",
    "sent_hyp = []\n",
    "for elem in nbest_original:\n",
    "    unique_sent = set()\n",
    "    for sent in elem:\n",
    "        unique_sent.add(sent)\n",
    "        if (len(unique_sent) == 10):\n",
    "            sent_hyp.extend(list(unique_sent))\n",
    "            break\n",
    "        \n",
    "print (len(sent_hyp))\n",
    "\n",
    "with open('hyp_original_back.txt','w') as fout:\n",
    "    for sent in sent_hyp:\n",
    "        print(sent, end='\\n', file=fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "34a2b3ca-bd4e-4cd4-83a0-5331803af816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished detokenizing.\n"
     ]
    }
   ],
   "source": [
    "# Detokenize text        \n",
    "from sacremoses import MosesPunctNormalizer\n",
    "from sacremoses import MosesTokenizer, MosesDetokenizer\n",
    "from __future__ import print_function\n",
    "\n",
    "md_en = MosesDetokenizer(lang='en')\n",
    "\n",
    "with open('hyp_original_back.txt', encoding='utf8') as fin, open('original_back.txt','w', encoding='utf8') as fout:\n",
    "    for line in fin:\n",
    "        tokens = md_en.detokenize(line.split(), return_str=True)\n",
    "        print(tokens, end='\\n', file=fout)\n",
    "\n",
    "print('Finished detokenizing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aefd5e-b839-436a-9f92-68c9bdde9d33",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Statistics on translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c8ef7eb2-e55e-4bd2-b22b-f9d06e9508bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# List with original source sentences\n",
    "source = []\n",
    "with open('en_original.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        source.append(line.strip())\n",
    "          \n",
    "# List with nbest sentences for every source in original\n",
    "nbest_original = []\n",
    "counter = 0\n",
    "temp = []\n",
    "with open('hyp_original.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        temp.append(line.strip())\n",
    "        counter += 1\n",
    "        if (counter == 10):\n",
    "            nbest_original.append(temp)\n",
    "            counter = 0\n",
    "            temp = []\n",
    "            \n",
    "print(len(source))\n",
    "print(len(nbest_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5db24268-9dd2-44fa-a743-7c12826a7c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique sentences in source nbest list for each source sentence\n",
    "def count_unique_sentences(nbest_sentences):\n",
    "    unique_sent = []\n",
    "    for source_nbest in nbest_sentences:\n",
    "        num_values = len(set(source_nbest))\n",
    "        #print(num_values)\n",
    "        unique_sent.append(num_values)\n",
    "\n",
    "    #print(unique_sent)\n",
    "    return unique_sent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b5b7dc62-f469-454e-8c74-22b36f4abcb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 10, 10, 10, 10, 10, 10, 10, 10, 10]\n"
     ]
    }
   ],
   "source": [
    "# Value should be 10, because beam search generates 10 unique sentences\n",
    "print(count_unique_sentences(nbest_original))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0538a059-9919-4b6e-8f93-b0f88e92fc90",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Statistics on backtranslations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "839ccdf2-a396-403c-8400-9748ed0f3fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# List with original source sentences\n",
    "source = []\n",
    "with open('en_original.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        source.append(line.strip())      \n",
    "    \n",
    "# List with nbest sentences for every source in original \n",
    "nbest_original = []\n",
    "counter = 0\n",
    "temp = []\n",
    "with open('original_back.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        temp.append(line.strip())\n",
    "        counter += 1\n",
    "        if (counter == 100):\n",
    "            nbest_original.append(temp)\n",
    "            counter = 0\n",
    "            temp = []\n",
    "            \n",
    "print(len(nbest_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "177c95d7-17a4-4abf-a987-e97f074a0cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[66, 78, 98, 100, 100, 100, 100, 100, 100, 100]\n"
     ]
    }
   ],
   "source": [
    "print(count_unique_sentences(nbest_original))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c76762c-a0e5-4a47-bdb8-1920e4e74ff2",
   "metadata": {},
   "source": [
    "## Average results from masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bab5258d-b2fe-4926-997c-8ba9ac894904",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '[96'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munique_1st.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fin:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m fin:\n\u001b[0;32m----> 4\u001b[0m         unique_1st\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;28mint\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)])    \n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(unique_1st)\n\u001b[1;32m      8\u001b[0m unique_2nd \u001b[38;5;241m=\u001b[39m []\n",
      "Cell \u001b[0;32mIn[30], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munique_1st.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fin:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m fin:\n\u001b[0;32m----> 4\u001b[0m         unique_1st\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m line\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)])    \n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(unique_1st)\n\u001b[1;32m      8\u001b[0m unique_2nd \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '[96'"
     ]
    }
   ],
   "source": [
    "unique_1st = []\n",
    "with open('unique_1st.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        unique_1st.append([int(i) for i in line.strip().split(\",\")])    \n",
    "        \n",
    "print(unique_1st)\n",
    "\n",
    "unique_2nd = []\n",
    "with open('unique_2nd.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        unique_2nd.append([int(i) for i in line.strip().split(\",\")])    \n",
    "        \n",
    "print(unique_2nd)\n",
    "\n",
    "unique_3rd = []\n",
    "with open('unique_3rd.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        unique_3rd.append([int(i) for i in line.strip().split(\",\")])    \n",
    "        \n",
    "print(unique_3rd)\n",
    "\n",
    "unique_4th = []\n",
    "with open('unique_3rd.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        unique_4th.append([int(i) for i in line.strip().split(\",\")])    \n",
    "        \n",
    "print(unique_4th)\n",
    "\n",
    "unique_5th = []\n",
    "with open('unique_3rd.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        unique_5th.append([int(i) for i in line.strip().split(\",\")])    \n",
    "        \n",
    "print(unique_5th)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "5d417c77-bcf1-4195-b714-c9396040fa3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[38.4, 55.0, 46.0, 30.4, 49.4, 27.2, 24.8, 42.8, 30.2], [54.8, 68.2, 65.2, 65.2, 60.8, 71.8, 63.0, 60.6, 61.2, 37.2, 71.2], [70.0, 68.4, 68.8, 80.8, 68.6, 70.4, 65.4, 64.0, 75.0, 72.2, 65.4, 79.0, 69.4, 71.0, 63.6, 76.6, 74.4, 70.0, 78.4, 69.2, 74.2], [64.8, 54.8, 53.8, 49.0, 56.8, 56.0, 52.8, 59.6, 57.8, 45.2, 56.4, 58.4, 51.0, 52.8, 55.0, 60.0, 56.8, 36.2, 56.0, 55.8, 49.8], [38.2, 35.2, 27.8, 29.4, 26.8, 32.8, 26.8, 42.4, 28.4, 50.0, 26.8, 25.8, 34.0, 24.4, 39.6, 31.0, 37.8, 30.4, 43.8, 32.0, 40.8, 36.4, 24.8, 40.4, 47.4, 50.2, 33.0], [64.8, 62.8, 72.2, 52.0, 65.6, 60.6, 67.4, 58.8, 68.2, 65.6, 59.6, 58.2, 69.6, 67.4, 69.4, 49.8, 57.4, 65.8, 68.2, 72.4, 56.0, 71.0, 67.8, 59.8, 50.6, 68.6, 72.2, 61.2, 52.6, 60.0], [62.8, 66.2, 68.6, 64.8, 67.4, 65.2, 73.6, 55.6, 61.6, 73.8, 64.8, 55.2, 69.8, 71.2, 65.0, 54.0, 67.4, 78.6, 56.8, 73.0, 92.8, 75.0, 82.2, 77.8, 67.8, 69.4, 83.8], [40.6, 52.6, 45.0, 46.6, 47.4, 35.2, 48.0, 39.0, 44.6, 47.6, 41.4, 46.2, 69.0, 39.2, 44.0, 36.4, 43.6, 45.8, 46.8, 31.6, 43.8, 36.8, 35.8, 49.0, 37.8, 47.2, 49.8, 54.0, 40.8, 45.8, 43.4, 45.4, 31.0, 43.8, 41.8, 42.4, 44.4, 34.2, 36.2, 50.2], [31.4, 44.4, 45.2, 30.2, 35.4, 35.2, 33.8, 36.4, 38.8, 29.8, 32.6, 36.8, 33.2, 37.2, 30.0, 32.0, 35.4, 19.6, 19.2, 35.8], [44.0, 46.4, 31.0, 48.2, 39.2, 44.8, 33.4, 38.0, 43.4, 54.4, 56.6, 66.2, 39.0, 46.8, 59.2, 52.2, 41.6, 74.2, 52.8, 50.2, 46.8, 54.6, 41.0, 49.2, 75.8, 36.0, 34.4, 38.4, 32.8, 40.0, 39.8, 40.6, 34.2, 31.2, 34.2, 39.0, 32.2, 42.0, 47.0]]\n"
     ]
    }
   ],
   "source": [
    "unique_average_5 = []\n",
    "for i in range(0, len(source)):\n",
    "    #print(list(zip(unique_1st[i], unique_2nd[i], unique_3rd[i], unique_4th[i], unique_5th[i])))\n",
    "    average = map(lambda x: (x[0] + x[1] + x[2] + x[3] + x[4])/5, zip(unique_1st[i], unique_2nd[i], unique_3rd[i], unique_4th[i], unique_5th[i]))\n",
    "    unique_average_5.append(list(average))\n",
    "\n",
    "print(unique_average_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "2a6969c3-9ce7-4a95-8461-85f90d302294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36.666666666666664, 57.0, 42.0, 32.0, 45.666666666666664, 26.666666666666668, 27.333333333333332, 38.666666666666664, 31.0], [55.333333333333336, 67.66666666666667, 64.66666666666667, 64.66666666666667, 61.333333333333336, 70.33333333333333, 63.0, 61.666666666666664, 64.0, 35.333333333333336, 70.0], [71.33333333333333, 73.33333333333333, 68.66666666666667, 82.0, 71.66666666666667, 75.33333333333333, 65.66666666666667, 66.66666666666667, 76.33333333333333, 72.33333333333333, 65.0, 77.66666666666667, 64.33333333333333, 59.666666666666664, 60.666666666666664, 74.33333333333333, 74.66666666666667, 69.33333333333333, 78.0, 70.0, 73.66666666666667], [62.0, 53.333333333333336, 51.666666666666664, 50.333333333333336, 52.666666666666664, 51.333333333333336, 52.0, 57.333333333333336, 55.666666666666664, 44.0, 61.333333333333336, 59.333333333333336, 50.333333333333336, 50.0, 57.0, 61.333333333333336, 54.0, 35.666666666666664, 55.333333333333336, 55.0, 49.666666666666664], [40.333333333333336, 34.0, 27.0, 30.333333333333332, 28.666666666666668, 30.0, 26.666666666666668, 34.666666666666664, 30.0, 48.0, 26.666666666666668, 25.0, 30.666666666666668, 25.333333333333332, 36.0, 29.0, 35.0, 27.333333333333332, 44.333333333333336, 30.666666666666668, 39.333333333333336, 34.0, 25.333333333333332, 40.0, 38.333333333333336, 51.666666666666664, 30.333333333333332], [62.666666666666664, 60.0, 72.33333333333333, 54.0, 64.0, 66.33333333333333, 68.33333333333333, 57.333333333333336, 68.33333333333333, 64.66666666666667, 62.0, 63.666666666666664, 66.66666666666667, 69.0, 69.0, 58.333333333333336, 63.0, 65.0, 69.0, 71.33333333333333, 54.666666666666664, 69.0, 66.33333333333333, 63.0, 50.333333333333336, 66.33333333333333, 71.0, 60.0, 59.666666666666664, 62.0], [66.0, 63.666666666666664, 69.0, 66.0, 67.0, 66.66666666666667, 74.0, 58.0, 60.0, 71.0, 70.0, 60.0, 63.666666666666664, 69.33333333333333, 63.0, 55.333333333333336, 70.33333333333333, 75.0, 63.333333333333336, 66.33333333333333, 88.66666666666667, 73.0, 77.0, 83.0, 66.33333333333333, 65.0, 79.66666666666667], [38.333333333333336, 52.333333333333336, 49.0, 45.0, 44.333333333333336, 36.666666666666664, 43.333333333333336, 41.0, 45.666666666666664, 46.666666666666664, 44.333333333333336, 43.0, 57.666666666666664, 38.666666666666664, 45.333333333333336, 37.333333333333336, 45.333333333333336, 42.333333333333336, 45.333333333333336, 33.333333333333336, 43.0, 39.333333333333336, 33.0, 49.0, 37.0, 47.333333333333336, 46.333333333333336, 50.666666666666664, 43.333333333333336, 46.333333333333336, 42.333333333333336, 44.333333333333336, 31.0, 45.0, 43.0, 41.333333333333336, 43.333333333333336, 35.666666666666664, 35.666666666666664, 48.333333333333336], [35.666666666666664, 48.0, 47.333333333333336, 34.333333333333336, 34.333333333333336, 38.0, 32.333333333333336, 35.333333333333336, 38.666666666666664, 29.0, 32.333333333333336, 36.0, 32.666666666666664, 34.666666666666664, 32.0, 32.666666666666664, 34.333333333333336, 20.666666666666668, 18.666666666666668, 33.666666666666664], [46.0, 41.333333333333336, 31.666666666666668, 44.333333333333336, 36.666666666666664, 50.0, 34.333333333333336, 38.0, 43.0, 61.333333333333336, 55.666666666666664, 56.333333333333336, 40.333333333333336, 49.333333333333336, 54.0, 55.666666666666664, 40.666666666666664, 69.0, 51.333333333333336, 49.0, 45.333333333333336, 49.666666666666664, 39.666666666666664, 52.0, 74.33333333333333, 36.666666666666664, 33.333333333333336, 38.0, 34.0, 39.333333333333336, 37.666666666666664, 41.666666666666664, 35.0, 31.333333333333332, 33.666666666666664, 35.666666666666664, 35.0, 35.333333333333336, 45.0]]\n"
     ]
    }
   ],
   "source": [
    "unique_average_3 = []\n",
    "for i in range(0, len(source)):\n",
    "    #print(list(zip(unique_1st[i], unique_2nd[i], unique_3rd[i])))\n",
    "    average = map(lambda x: (x[0] + x[1] + x[2])/3, zip(unique_1st[i], unique_2nd[i], unique_3rd[i]))\n",
    "    unique_average_3.append(list(average))\n",
    "\n",
    "print(unique_average_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "9c3597e4-7ab2-43a7-af4c-fe5adb00f578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39, 66, 38, 35, 50, 32, 32, 35, 32], [58, 70, 64, 64, 66, 74, 63, 63, 72, 38, 74], [77, 89, 70, 84, 77, 95, 68, 72, 79, 77, 66, 84, 61, 53, 63, 75, 76, 69, 91, 74, 78], [64, 54, 58, 54, 58, 47, 58, 58, 58, 46, 69, 63, 58, 61, 61, 68, 58, 40, 58, 55, 57], [44, 39, 26, 34, 36, 27, 27, 26, 38, 48, 27, 26, 27, 27, 37, 27, 36, 26, 45, 32, 49, 36, 27, 45, 28, 67, 28], [76, 70, 75, 70, 70, 75, 80, 70, 70, 71, 70, 71, 70, 72, 70, 70, 70, 74, 70, 70, 70, 70, 70, 67, 54, 67, 72, 67, 70, 67], [70, 70, 73, 68, 70, 70, 82, 70, 65, 77, 83, 76, 56, 70, 70, 62, 78, 71, 73, 70, 97, 71, 71, 90, 69, 70, 79], [44, 56, 58, 46, 41, 40, 40, 47, 54, 48, 56, 40, 47, 41, 52, 40, 52, 40, 47, 49, 44, 50, 40, 51, 42, 55, 63, 50, 47, 48, 46, 49, 41, 53, 50, 40, 44, 40, 40, 52], [45, 53, 63, 48, 35, 46, 31, 37, 39, 29, 33, 39, 32, 32, 38, 36, 35, 24, 19, 31], [53, 35, 35, 44, 35, 65, 36, 41, 50, 74, 56, 53, 48, 63, 48, 69, 44, 90, 64, 60, 52, 52, 41, 64, 73, 40, 35, 40, 38, 45, 35, 44, 37, 35, 35, 35, 39, 29, 51]]\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "unique_median = []\n",
    "for i in range(0, len(source)):\n",
    "    med = map(lambda x: statistics.median([x[0], x[1], x[2] + x[3] + x[4]]), zip(unique_1st[i], unique_2nd[i], unique_3rd[i], unique_4th[i], unique_5th[i]))\n",
    "    unique_median.append(list(med))\n",
    "\n",
    "print(unique_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745a4cb7-84a0-467a-b148-caa1a7663821",
   "metadata": {},
   "source": [
    "## Subtract original sentences value from average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "e56a5670-5ecd-4f4c-97fa-1cdd8ba75697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32, 63, 68, 61, 26, 67, 70, 46, 31, 48]\n"
     ]
    }
   ],
   "source": [
    "unique_original = count_unique_sentences(nbest_original)\n",
    "\n",
    "print(unique_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "b12e0eaa-5027-4f32-9389-249f330acb27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.67, 25.0, 10.0, 0.0, 13.67, 5.33, 4.67, 6.67, 1.0]\n",
      "['So', 'now', 'Thomson', 'becomes', 'the', 'more', 'likely', 'suspect', '.']\n",
      ",\n",
      "james\n",
      "david\n",
      "peter\n",
      "john\n",
      "(25.0, 1, 'now')\n",
      "\n",
      "[7.67, 4.67, 1.67, 1.67, 1.67, 7.33, 0.0, 1.33, 1.0, 27.67, 7.0]\n",
      "['There', 'was', 'one', 'black', 'professor', 'and', 'one', 'black', 'assistant', 'dean', '.']\n",
      "man\n",
      "woman\n",
      "girl\n",
      "guy\n",
      "boy\n",
      "(27.67, 9, 'dean')\n",
      "\n",
      "[3.33, 5.33, 0.67, 14.0, 3.67, 7.33, 2.33, 1.33, 8.33, 4.33, 3.0, 9.67, 3.67, 8.33, 7.33, 6.33, 6.67, 1.33, 10.0, 2.0, 5.67]\n",
      "['We', 'have', 'our', 'cognitive', 'biases', ',', 'so', 'that', 'I', 'can', 'take', 'a', 'perfect', 'history', 'on', 'a', 'patient', 'with', 'chest', 'pain', '.']\n",
      "own\n",
      "usual\n",
      "research\n",
      "same\n",
      "personal\n",
      "(14.0, 3, 'cognitive')\n",
      "\n",
      "[1.0, 7.67, 9.33, 10.67, 8.33, 9.67, 9.0, 3.67, 5.33, 17.0, 0.33, 1.67, 10.67, 11.0, 4.0, 0.33, 7.0, 25.33, 5.67, 6.0, 11.33]\n",
      "['That', '&apos;s', 'the', 'officer', 'who', 'emailed', 'me', 'back', ',', 'saying', 'I', 'think', 'you', 'can', 'have', 'a', 'few', 'classes', 'with', 'us', '.']\n",
      "words\n",
      "drinks\n",
      "minutes\n",
      "questions\n",
      "meetings\n",
      "(25.33, 17, 'classes')\n",
      "\n",
      "[14.33, 8.0, 1.0, 4.33, 2.67, 4.0, 0.67, 8.67, 4.0, 22.0, 0.67, 1.0, 4.67, 0.67, 10.0, 3.0, 9.0, 1.33, 18.33, 4.67, 13.33, 8.0, 0.67, 14.0, 12.33, 25.67, 4.33]\n",
      "['Steve', ',', 'a', 'physician', ',', 'told', 'me', 'about', 'a', 'doctor', 'that', 'he', 'worked', 'with', 'who', 'was', 'never', 'very', 'respectful', ',', 'especially', 'to', 'junior', 'staff', 'and', 'nurses', '.']\n",
      "patients\n",
      "students\n",
      "doctors\n",
      "staff\n",
      "employees\n",
      "(25.67, 25, 'nurses')\n",
      "\n",
      "[4.33, 7.0, 5.33, 13.0, 3.0, 0.67, 1.33, 9.67, 1.33, 2.33, 5.0, 3.33, 0.33, 2.0, 2.0, 8.67, 4.0, 2.0, 2.0, 4.33, 12.33, 2.0, 0.67, 4.0, 16.67, 0.67, 4.0, 7.0, 7.33, 5.0]\n",
      "['What', 'do', 'you', 'think', 'a', 'batting', 'average', 'for', 'a', 'cardiac', 'surgeon', 'or', 'a', 'nurse', 'practitioner', 'or', 'an', 'orthopedic', 'surgeon', ',', 'an', 'OBGYN', ',', 'a', 'paramedic', 'is', 'supposed', 'to', 'be', '?']\n",
      "man\n",
      "woman\n",
      "girl\n",
      "guy\n",
      "boy\n",
      "(16.67, 24, 'paramedic')\n",
      "\n",
      "[4.0, 6.33, 1.0, 4.0, 3.0, 3.33, 4.0, 12.0, 10.0, 1.0, 0.0, 10.0, 6.33, 0.67, 7.0, 14.67, 0.33, 5.0, 6.67, 3.67, 18.67, 3.0, 7.0, 13.0, 3.67, 5.0, 9.67]\n",
      "['Fortunately', 'for', 'Mama', 'Jane', 'and', 'her', 'friend', ',', 'a', 'donor', 'had', 'provided', 'treatment', 'so', 'that', 'we', 'could', 'take', 'them', 'to', 'the', 'nearest', 'hospital', 'three', 'hours', 'away', '.']\n",
      "the\n",
      "our\n",
      "their\n",
      "a\n",
      "my\n",
      "(18.67, 20, 'the')\n",
      "\n",
      "[7.67, 6.33, 3.0, 1.0, 1.67, 9.33, 2.67, 5.0, 0.33, 0.67, 1.67, 3.0, 11.67, 7.33, 0.67, 8.67, 0.67, 3.67, 0.67, 12.67, 3.0, 6.67, 13.0, 3.0, 9.0, 1.33, 0.33, 4.67, 2.67, 0.33, 3.67, 1.67, 15.0, 1.0, 3.0, 4.67, 2.67, 10.33, 10.33, 2.33]\n",
      "['The', 'three', 'words', 'are', ':', 'Do', 'you', 'remember', '?', '&quot;', 'Do', 'you', 'remember', 'that', 'patient', 'you', 'sent', 'home', '?', '&quot;', 'the', 'other', 'nurse', 'asked', 'matter-of-factly', '.', '&quot;', 'Well', 'she', '&apos;s', 'back', ',', '&quot;', 'in', 'just', 'that', 'tone', 'of', 'voice', '.']\n",
      "but\n",
      "and\n",
      "even\n",
      "not\n",
      "still\n",
      "(15.0, 32, '&quot;')\n",
      "\n",
      "[4.67, 17.0, 16.33, 3.33, 3.33, 7.0, 1.33, 4.33, 7.67, 2.0, 1.33, 5.0, 1.67, 3.67, 1.0, 1.67, 3.33, 10.33, 12.33, 2.67]\n",
      "['This', 'one', 'comes', 'from', 'a', 'note', 'that', 'a', 'student', 'sent', 'me', 'after', 'I', 'gave', 'a', 'lecture', 'about', 'arousal', 'nonconcordance', '.']\n",
      "name\n",
      "quote\n",
      "title\n",
      "nickname\n",
      "information\n",
      "(17.0, 1, 'one')\n",
      "\n",
      "[2.0, 6.67, 16.33, 3.67, 11.33, 2.0, 13.67, 10.0, 5.0, 13.33, 7.67, 8.33, 7.67, 1.33, 6.0, 7.67, 7.33, 21.0, 3.33, 1.0, 2.67, 1.67, 8.33, 4.0, 26.33, 11.33, 14.67, 10.0, 14.0, 8.67, 10.33, 6.33, 13.0, 16.67, 14.33, 12.33, 13.0, 12.67, 3.0]\n",
      "['At', 'the', 'end', 'of', 'a', 'conference', 'in', 'a', 'hotel', 'lobby', 'once', ',', 'I', '&apos;m', 'literally', 'on', 'my', 'way', 'out', 'the', 'door', 'and', 'a', 'colleague', 'chases', 'me', 'down', '.', '&quot;', 'Emily', ',', 'I', 'just', 'have', 'a', 'really', 'quick', 'question', '.']\n",
      "knocked\n",
      "turns\n",
      "waved\n",
      "turned\n",
      "chasing\n",
      "(26.33, 24, 'chases')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List with original source sentences\n",
    "samples = []\n",
    "with open('tok.en_original.en', 'r') as fin:\n",
    "    for line in fin:\n",
    "        samples.append(line.strip().split(\" \"))\n",
    "\n",
    "unique_result = []\n",
    "for c in range(0, len(unique_original)):\n",
    "    subtracted = [round(abs(el - unique_original[c]), 2) for el in unique_average_3[c]] # calculate the absolute value\n",
    "    print(subtracted)\n",
    "    unique_result.append(subtracted)\n",
    "    print(samples[c])\n",
    "    idx = subtracted.index(max(subtracted)) # extracting the largest difference\n",
    "    \n",
    "    #Extract replacement words\n",
    "    with open('1st/sen' + str(c+1) + '.txt','r') as fin:\n",
    "        for i, line in enumerate(fin):\n",
    "            if i == idx:\n",
    "                print(line.strip().split(\" \")[idx])\n",
    "                \n",
    "    with open('2nd/sen' + str(c+1) + '.txt','r') as fin:\n",
    "        for i, line in enumerate(fin):\n",
    "            if i == idx:\n",
    "                print(line.strip().split(\" \")[idx])\n",
    "                \n",
    "    with open('3rd/sen' + str(c+1) + '.txt','r') as fin:\n",
    "        for i, line in enumerate(fin):\n",
    "            if i == idx:\n",
    "                print(line.strip().split(\" \")[idx])\n",
    "                \n",
    "    with open('4th/sen' + str(c+1) + '.txt','r') as fin:\n",
    "        for i, line in enumerate(fin):\n",
    "            if i == idx:\n",
    "                print(line.strip().split(\" \")[idx])\n",
    "                \n",
    "    with open('5th/sen' + str(c+1) + '.txt','r') as fin:\n",
    "        for i, line in enumerate(fin):\n",
    "            if i == idx:\n",
    "                print(line.strip().split(\" \")[idx])\n",
    "                \n",
    "    print((max(subtracted), idx, samples[c][idx]), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e109d0-878b-4db6-9afe-29d1f4f5e2f4",
   "metadata": {},
   "source": [
    "- Extract 5 best from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "9e0e8329-b962-4dc2-8549-ef1c6e295691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.67, 25.0, 10.0, 0.0, 13.67, 5.33, 4.67, 6.67, 1.0]\n",
      "['So', 'now', 'Thomson', 'becomes', 'the', 'more', 'likely', 'suspect', '.']\n",
      "([25.0, 13.67, 10.0, 6.67, 5.33], [1, 4, 2, 7, 5], ['now', 'the', 'Thomson', 'suspect', 'more'])\n",
      "\n",
      "[7.67, 4.67, 1.67, 1.67, 1.67, 7.33, 0.0, 1.33, 1.0, 27.67, 7.0]\n",
      "['There', 'was', 'one', 'black', 'professor', 'and', 'one', 'black', 'assistant', 'dean', '.']\n",
      "([27.67, 7.67, 7.33, 7.0, 4.67], [9, 0, 5, 10, 1], ['dean', 'There', 'and', '.', 'was'])\n",
      "\n",
      "[3.33, 5.33, 0.67, 14.0, 3.67, 7.33, 2.33, 1.33, 8.33, 4.33, 3.0, 9.67, 3.67, 8.33, 7.33, 6.33, 6.67, 1.33, 10.0, 2.0, 5.67]\n",
      "['We', 'have', 'our', 'cognitive', 'biases', ',', 'so', 'that', 'I', 'can', 'take', 'a', 'perfect', 'history', 'on', 'a', 'patient', 'with', 'chest', 'pain', '.']\n",
      "([14.0, 10.0, 9.67, 8.33, 8.33], [3, 18, 11, 8, 8], ['cognitive', 'chest', 'a', 'I', 'I'])\n",
      "\n",
      "[1.0, 7.67, 9.33, 10.67, 8.33, 9.67, 9.0, 3.67, 5.33, 17.0, 0.33, 1.67, 10.67, 11.0, 4.0, 0.33, 7.0, 25.33, 5.67, 6.0, 11.33]\n",
      "['That', '&apos;s', 'the', 'officer', 'who', 'emailed', 'me', 'back', ',', 'saying', 'I', 'think', 'you', 'can', 'have', 'a', 'few', 'classes', 'with', 'us', '.']\n",
      "([25.33, 17.0, 11.33, 11.0, 10.67], [17, 9, 20, 13, 3], ['classes', 'saying', '.', 'can', 'officer'])\n",
      "\n",
      "[14.33, 8.0, 1.0, 4.33, 2.67, 4.0, 0.67, 8.67, 4.0, 22.0, 0.67, 1.0, 4.67, 0.67, 10.0, 3.0, 9.0, 1.33, 18.33, 4.67, 13.33, 8.0, 0.67, 14.0, 12.33, 25.67, 4.33]\n",
      "['Steve', ',', 'a', 'physician', ',', 'told', 'me', 'about', 'a', 'doctor', 'that', 'he', 'worked', 'with', 'who', 'was', 'never', 'very', 'respectful', ',', 'especially', 'to', 'junior', 'staff', 'and', 'nurses', '.']\n",
      "([25.67, 22.0, 18.33, 14.33, 14.0], [25, 9, 18, 0, 23], ['nurses', 'doctor', 'respectful', 'Steve', 'staff'])\n",
      "\n",
      "[4.33, 7.0, 5.33, 13.0, 3.0, 0.67, 1.33, 9.67, 1.33, 2.33, 5.0, 3.33, 0.33, 2.0, 2.0, 8.67, 4.0, 2.0, 2.0, 4.33, 12.33, 2.0, 0.67, 4.0, 16.67, 0.67, 4.0, 7.0, 7.33, 5.0]\n",
      "['What', 'do', 'you', 'think', 'a', 'batting', 'average', 'for', 'a', 'cardiac', 'surgeon', 'or', 'a', 'nurse', 'practitioner', 'or', 'an', 'orthopedic', 'surgeon', ',', 'an', 'OBGYN', ',', 'a', 'paramedic', 'is', 'supposed', 'to', 'be', '?']\n",
      "([16.67, 13.0, 12.33, 9.67, 8.67], [24, 3, 20, 7, 15], ['paramedic', 'think', 'an', 'for', 'or'])\n",
      "\n",
      "[4.0, 6.33, 1.0, 4.0, 3.0, 3.33, 4.0, 12.0, 10.0, 1.0, 0.0, 10.0, 6.33, 0.67, 7.0, 14.67, 0.33, 5.0, 6.67, 3.67, 18.67, 3.0, 7.0, 13.0, 3.67, 5.0, 9.67]\n",
      "['Fortunately', 'for', 'Mama', 'Jane', 'and', 'her', 'friend', ',', 'a', 'donor', 'had', 'provided', 'treatment', 'so', 'that', 'we', 'could', 'take', 'them', 'to', 'the', 'nearest', 'hospital', 'three', 'hours', 'away', '.']\n",
      "([18.67, 14.67, 13.0, 12.0, 10.0], [20, 15, 23, 7, 8], ['the', 'we', 'three', ',', 'a'])\n",
      "\n",
      "[7.67, 6.33, 3.0, 1.0, 1.67, 9.33, 2.67, 5.0, 0.33, 0.67, 1.67, 3.0, 11.67, 7.33, 0.67, 8.67, 0.67, 3.67, 0.67, 12.67, 3.0, 6.67, 13.0, 3.0, 9.0, 1.33, 0.33, 4.67, 2.67, 0.33, 3.67, 1.67, 15.0, 1.0, 3.0, 4.67, 2.67, 10.33, 10.33, 2.33]\n",
      "['The', 'three', 'words', 'are', ':', 'Do', 'you', 'remember', '?', '&quot;', 'Do', 'you', 'remember', 'that', 'patient', 'you', 'sent', 'home', '?', '&quot;', 'the', 'other', 'nurse', 'asked', 'matter-of-factly', '.', '&quot;', 'Well', 'she', '&apos;s', 'back', ',', '&quot;', 'in', 'just', 'that', 'tone', 'of', 'voice', '.']\n",
      "([15.0, 13.0, 12.67, 11.67, 10.33], [32, 22, 19, 12, 37], ['&quot;', 'nurse', '&quot;', 'remember', 'of'])\n",
      "\n",
      "[4.67, 17.0, 16.33, 3.33, 3.33, 7.0, 1.33, 4.33, 7.67, 2.0, 1.33, 5.0, 1.67, 3.67, 1.0, 1.67, 3.33, 10.33, 12.33, 2.67]\n",
      "['This', 'one', 'comes', 'from', 'a', 'note', 'that', 'a', 'student', 'sent', 'me', 'after', 'I', 'gave', 'a', 'lecture', 'about', 'arousal', 'nonconcordance', '.']\n",
      "([17.0, 16.33, 12.33, 10.33, 7.67], [1, 2, 18, 17, 8], ['one', 'comes', 'nonconcordance', 'arousal', 'student'])\n",
      "\n",
      "[2.0, 6.67, 16.33, 3.67, 11.33, 2.0, 13.67, 10.0, 5.0, 13.33, 7.67, 8.33, 7.67, 1.33, 6.0, 7.67, 7.33, 21.0, 3.33, 1.0, 2.67, 1.67, 8.33, 4.0, 26.33, 11.33, 14.67, 10.0, 14.0, 8.67, 10.33, 6.33, 13.0, 16.67, 14.33, 12.33, 13.0, 12.67, 3.0]\n",
      "['At', 'the', 'end', 'of', 'a', 'conference', 'in', 'a', 'hotel', 'lobby', 'once', ',', 'I', '&apos;m', 'literally', 'on', 'my', 'way', 'out', 'the', 'door', 'and', 'a', 'colleague', 'chases', 'me', 'down', '.', '&quot;', 'Emily', ',', 'I', 'just', 'have', 'a', 'really', 'quick', 'question', '.']\n",
      "([26.33, 21.0, 16.67, 16.33, 14.67], [24, 17, 33, 2, 26], ['chases', 'way', 'have', 'end', 'down'])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List with original source sentences\n",
    "samples = []\n",
    "with open('tok.en_original.en', 'r') as fin:\n",
    "    for line in fin:\n",
    "        samples.append(line.strip().split(\" \"))\n",
    "\n",
    "unique_result = []\n",
    "for c in range(0, len(unique_original)):\n",
    "    subtracted = [round(abs(el - unique_original[c]), 2) for el in unique_average_3[c]] # calculate the absolute value\n",
    "    print(subtracted)\n",
    "    unique_result.append(subtracted)\n",
    "    print(samples[c])\n",
    "    \n",
    "    subtracted_sorted = sorted(subtracted, reverse=True)\n",
    "    best_5 = subtracted_sorted[:5] # extracting the 5 largest differences\n",
    "    idx_5 = [subtracted.index(i) for i in best_5]\n",
    "    result_5 = [samples[c][idx] for idx in idx_5]\n",
    "    \n",
    "#     #Extract replacement words\n",
    "#     with open('1st/sen' + str(c+1) + '.txt','r') as fin:\n",
    "#         for i, line in enumerate(fin):\n",
    "#             if i == idx:\n",
    "#                 print(line.strip().split(\" \")[idx])\n",
    "                \n",
    "#     with open('2nd/sen' + str(c+1) + '.txt','r') as fin:\n",
    "#         for i, line in enumerate(fin):\n",
    "#             if i == idx:\n",
    "#                 print(line.strip().split(\" \")[idx])\n",
    "                \n",
    "#     with open('3rd/sen' + str(c+1) + '.txt','r') as fin:\n",
    "#         for i, line in enumerate(fin):\n",
    "#             if i == idx:\n",
    "#                 print(line.strip().split(\" \")[idx])\n",
    "                \n",
    "#     with open('4th/sen' + str(c+1) + '.txt','r') as fin:\n",
    "#         for i, line in enumerate(fin):\n",
    "#             if i == idx:\n",
    "#                 print(line.strip().split(\" \")[idx])\n",
    "                \n",
    "#     with open('5th/sen' + str(c+1) + '.txt','r') as fin:\n",
    "#         for i, line in enumerate(fin):\n",
    "#             if i == idx:\n",
    "#                 print(line.strip().split(\" \")[idx])\n",
    "                \n",
    "    print((best_5, idx_5, result_5), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a31cf8-bb4b-4fd5-b0f2-709699841455",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5ff93f-ae8e-448a-835c-e1f0ea7a5cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
