{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "86149787-c402-4a9c-a671-6b80c4ba01ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "PATH=\"/export/data4/vzhekova/biases-data/Test_De/Statistics\"\n",
    "FASTBPE=\"/home/vzhekova/fastBPE/fast\" # path to the fastBPE tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "d94435ee-d0e2-4ce0-960d-3f25e9758fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device: GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "# check if we can connect to the GPU with PyTorch\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.current_device()\n",
    "    print('Current device:', torch.cuda.get_device_name(device))\n",
    "else:\n",
    "    print('Failed to find GPU. Will use CPU.')\n",
    "    device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "f862c818-8f80-4af0-a6bc-7eb426aa8db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/export/data4/vzhekova/biases-data/Test_De/Statistics\n"
     ]
    }
   ],
   "source": [
    "%cd $PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98fed95f-6e8b-40ac-a479-cf72a10de060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract original sentences\n",
    "!cut -f3 -d'\t' en.txt > en_original.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6d2d8a2-483a-4644-92d0-223a59bacdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Convert text file to csv\n",
    "with open('en.txt', 'r') as in_file:\n",
    "    stripped = (line.strip() for line in in_file)\n",
    "    lines = (line.split(\"\t\") for line in stripped if line)\n",
    "    with open('en.csv', 'w') as out_file:\n",
    "        writer = csv.writer(out_file)\n",
    "        #writer.writerow(('gender', 'position', 'sentence', 'word'))\n",
    "        writer.writerows(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55430032-744f-4890-aca5-5b0999e879b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract gender word tokens\n",
    "with open('en.csv') as csv_file, open('tokens.txt', 'w') as out_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        position = int(row[1])\n",
    "        sentence = row[2].split(\" \")\n",
    "        print(sentence[position], end='\\n', file=out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1914b00-1245-49bb-9622-80d81e616cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract gender ambiguous words\n",
    "with open('en.csv') as csv_file, open('words.txt', 'w') as out_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        print(row[3], end='\\n', file=out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8a44b8d-bb8b-41cf-9c77-4fc13513faa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify gender ambiguous words with correct gender from context\n",
    "with open('en.csv') as csv_file, open('en_modified.txt', 'w') as out_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        modified = row[0] + \" \" + row[3]\n",
    "        position = int(row[1])\n",
    "        sentence = row[2].split(\" \")\n",
    "        sentence[position] = modified\n",
    "        print(' '.join(sentence), end='\\n', file=out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "2b53297e-d36c-40e1-90a7-32df8276e33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify gender ambiguous words with gender\n",
    "\n",
    "# List with source words\n",
    "words = set() # set forces uniqueness\n",
    "with open('words.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        words.add(line.strip())\n",
    "        \n",
    "#print(len(words))\n",
    "\n",
    "with open('en.csv') as csv_file, open('en_disambiguated.txt', 'w') as out_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        modified = row[0] + \" \" + row[3]\n",
    "        position = int(row[1])\n",
    "        sentence = row[2].split(\" \")\n",
    "        sentence[position] = modified\n",
    "        for token in sentence:\n",
    "            if (token.replace(',', '') in words): # tokens often contain \",\"\n",
    "                token_pos = sentence.index(token)\n",
    "                sentence[token_pos] = \"male \" + token # could also replace with \"female\"\n",
    "        print(' '.join(sentence), end='\\n', file=out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60e45ab-0b69-4a19-9152-20a2f8d81950",
   "metadata": {},
   "source": [
    "# Translation English-German"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "b402bae1-cb74-4120-bb84-d6d444badcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished tokenizing.\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "from sacremoses import MosesPunctNormalizer\n",
    "from sacremoses import MosesTokenizer, MosesDetokenizer\n",
    "from __future__ import print_function\n",
    "\n",
    "mpn = MosesPunctNormalizer()\n",
    "mt_en = MosesTokenizer(lang='en')\n",
    "md_en = MosesDetokenizer(lang='en')\n",
    "\n",
    "with open('en_original.txt') as fin, open('tok.en_original.en','w') as fout:\n",
    "    for line in fin:\n",
    "        tokens = mt_en.tokenize(mpn.normalize(line), return_str=True)\n",
    "        print(tokens, end='\\n', file=fout) \n",
    "        \n",
    "with open('en_disambiguated.txt') as fin, open('tok.en_disambiguated.en','w') as fout:\n",
    "    for line in fin:\n",
    "        tokens = mt_en.tokenize(mpn.normalize(line), return_str=True)\n",
    "        print(tokens, end='\\n', file=fout)\n",
    "\n",
    "print('Finished tokenizing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "32892958-8082-4699-9dbb-fd02303ad2df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading codes from bpecodes.en ...\n",
      "Read 30000 codes from the codes file.\n",
      "Loading vocabulary from tok.en_original.en ...\n",
      "Read 55693 words (1890 unique) from text file.\n",
      "Applying BPE to tok.en_original.en ...\n",
      "Modified 55693 words from text file.\n",
      "Loading codes from bpecodes.en ...\n",
      "Read 30000 codes from the codes file.\n",
      "Loading vocabulary from tok.en_disambiguated.en ...\n",
      "Read 63597 words (1893 unique) from text file.\n",
      "Applying BPE to tok.en_disambiguated.en ...\n",
      "Modified 63597 words from text file.\n",
      "Finished subword.\n"
     ]
    }
   ],
   "source": [
    "# Dividing text into subword units\n",
    "\n",
    "!$FASTBPE applybpe bpe.en_original.en tok.en_original.en bpecodes.en\n",
    "!$FASTBPE applybpe bpe.en_disambiguated.en tok.en_disambiguated.en bpecodes.en\n",
    "\n",
    "print('Finished subword.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "d095e907-5ac5-4f85-b8be-8bd41137f0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-05 17:14:51 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin_original_en-de', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=True, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='en', srcdict='/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/dict.en.txt', suppress_crashes=False, target_lang='de', task='translation', tensorboard_logdir=None, testpref='bpe.en_original', tgtdict='/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/dict.de.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=8)\n",
      "2023-04-05 17:14:52 | INFO | fairseq_cli.preprocess | [en] Dictionary: 42024 types\n",
      "2023-04-05 17:14:52 | INFO | fairseq_cli.preprocess | [en] bpe.en_original.en: 3888 sents, 68526 tokens, 0.0% replaced (by <unk>)\n",
      "2023-04-05 17:14:52 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin_original_en-de\n",
      "..........\n",
      "2023-04-05 17:14:59 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin_disambiguated_en-de', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=True, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='en', srcdict='/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/dict.en.txt', suppress_crashes=False, target_lang='de', task='translation', tensorboard_logdir=None, testpref='bpe.en_disambiguated', tgtdict='/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/dict.de.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=8)\n",
      "2023-04-05 17:14:59 | INFO | fairseq_cli.preprocess | [en] Dictionary: 42024 types\n",
      "2023-04-05 17:15:00 | INFO | fairseq_cli.preprocess | [en] bpe.en_disambiguated.en: 3888 sents, 76431 tokens, 0.0% replaced (by <unk>)\n",
      "2023-04-05 17:15:00 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin_disambiguated_en-de\n"
     ]
    }
   ],
   "source": [
    "# Binarize text\n",
    "!fairseq-preprocess \\\n",
    "    --source-lang en \\\n",
    "    --target-lang de \\\n",
    "    --testpref bpe.en_original \\\n",
    "    --only-source \\\n",
    "    --srcdict /export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/dict.en.txt \\\n",
    "    --tgtdict /export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/dict.de.txt \\\n",
    "    --destdir data-bin_original_en-de \\\n",
    "    --workers 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7301e1df-d664-41a5-a042-49a3b8b358f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!fairseq-preprocess \\\n",
    "    --source-lang en \\\n",
    "    --target-lang de \\\n",
    "    --testpref bpe.en_disambiguated \\\n",
    "    --only-source \\\n",
    "    --srcdict /export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/dict.en.txt \\\n",
    "    --tgtdict /export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/dict.de.txt \\\n",
    "    --destdir data-bin_disambiguated_en-de \\\n",
    "    --workers 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "d586d870-a171-4907-938a-e0a3513da8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS=\"/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble\"\n",
    "NBEST = 10\n",
    "BEAM = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "b692d45f-09fc-4247-8ca6-d000f3066c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-05 17:15:10 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model1.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model2.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model3.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model4.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 64, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 64, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 10, 'beam_mt': 0, 'nbest': 10, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}, 'task': {'_name': 'translation', 'data': 'data-bin_original_en-de', 'source_lang': 'en', 'target_lang': 'de', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-04-05 17:15:12 | INFO | fairseq.tasks.translation | [en] dictionary: 42024 types\n",
      "2023-04-05 17:15:12 | INFO | fairseq.tasks.translation | [de] dictionary: 42024 types\n",
      "2023-04-05 17:15:12 | INFO | fairseq_cli.generate | loading model(s) from /export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model1.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model2.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model3.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model4.pt\n",
      "2023-04-05 17:16:47 | INFO | fairseq.data.data_utils | loaded 3,888 examples from: data-bin_original_en-de/test.en-de.en\n",
      "2023-04-05 17:16:47 | INFO | fairseq.tasks.translation | data-bin_original_en-de test en-de 3888 examples\n",
      "2023-04-05 17:24:15 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2023-04-05 17:24:15 | INFO | fairseq_cli.generate | Translated 3,888 sentences (78,632 tokens) in 270.9s (14.35 sentences/s, 290.27 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "# Generate N hypothesis\n",
    "!fairseq-generate data-bin_original_en-de  \\\n",
    "    --task translation \\\n",
    "    --source-lang en \\\n",
    "    --target-lang de \\\n",
    "    --path $MODELS/model1.pt:$MODELS/model2.pt:$MODELS/model3.pt:$MODELS/model4.pt \\\n",
    "    --beam $BEAM \\\n",
    "    --nbest $NBEST \\\n",
    "    --batch-size 64 \\\n",
    "    --memory-efficient-fp16 \\\n",
    "    --remove-bpe > original_en-de.decode_Beam_10.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "fe2a78ce-c255-453c-b7a6-9e238d18c119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-06 12:48:52 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model1.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model2.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model3.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model4.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 64, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 64, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 10, 'beam_mt': 0, 'nbest': 10, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}, 'task': {'_name': 'translation', 'data': 'data-bin_disambiguated_en-de', 'source_lang': 'en', 'target_lang': 'de', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-04-06 12:48:53 | INFO | fairseq.tasks.translation | [en] dictionary: 42024 types\n",
      "2023-04-06 12:48:53 | INFO | fairseq.tasks.translation | [de] dictionary: 42024 types\n",
      "2023-04-06 12:48:53 | INFO | fairseq_cli.generate | loading model(s) from /export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model1.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model2.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model3.pt:/export/data4/vzhekova/biases-data/En-De/wmt19.en-de.joined-dict.ensemble/model4.pt\n",
      "2023-04-06 12:50:27 | INFO | fairseq.data.data_utils | loaded 3,888 examples from: data-bin_disambiguated_en-de/test.en-de.en\n",
      "2023-04-06 12:50:27 | INFO | fairseq.tasks.translation | data-bin_disambiguated_en-de test en-de 3888 examples\n",
      "2023-04-06 12:58:20 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2023-04-06 12:58:20 | INFO | fairseq_cli.generate | Translated 3,888 sentences (89,059 tokens) in 297.2s (13.08 sentences/s, 299.63 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "# Generate N hypothesis\n",
    "!fairseq-generate data-bin_disambiguated_en-de  \\\n",
    "    --task translation \\\n",
    "    --source-lang en \\\n",
    "    --target-lang de \\\n",
    "    --path $MODELS/model1.pt:$MODELS/model2.pt:$MODELS/model3.pt:$MODELS/model4.pt \\\n",
    "    --beam $BEAM \\\n",
    "    --nbest $NBEST \\\n",
    "    --batch-size 64 \\\n",
    "    --memory-efficient-fp16 \\\n",
    "    --remove-bpe > disambiguated_en-de.decode_Beam_10.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9ea470-6597-4305-86c7-e9368885da0b",
   "metadata": {},
   "source": [
    "# Backtranslation German-English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "3807a901-a707-48cf-a683-f45c3f9598eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'LC_ALL=C sort -V' sorts the results in natural order \n",
    "!grep ^H original_en-de.decode_Beam_10.log | LC_ALL=C sort -V | sed 's/^H-//g' | cut -f 3 | sed 's/ @@//g' > ./hyp_original.txt\n",
    "!grep ^H disambiguated_en-de.decode_Beam_10.log | LC_ALL=C sort -V | sed 's/^H-//g' | cut -f 3 | sed 's/ @@//g' > ./hyp_disambiguated.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "d06c5b30-602c-4c10-8e3a-062aa6670d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading codes from bpecodes.de ...\n",
      "Read 30000 codes from the codes file.\n",
      "Loading vocabulary from hyp_original.txt ...\n",
      "Read 584204 words (4631 unique) from text file.\n",
      "Applying BPE to hyp_original.txt ...\n",
      "Modified 584204 words from text file.\n",
      "Loading codes from bpecodes.de ...\n",
      "Read 30000 codes from the codes file.\n",
      "Loading vocabulary from hyp_disambiguated.txt ...\n",
      "Read 638095 words (4634 unique) from text file.\n",
      "Applying BPE to hyp_disambiguated.txt ...\n",
      "Modified 638095 words from text file.\n",
      "Finished subword.\n"
     ]
    }
   ],
   "source": [
    "# Dividing tokenized text into subword units\n",
    "\n",
    "!$FASTBPE applybpe bpe.hyp_original.de hyp_original.txt bpecodes.de\n",
    "!$FASTBPE applybpe bpe.hyp_disambiguated.de hyp_disambiguated.txt bpecodes.de\n",
    "\n",
    "print('Finished subword.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "dc508917-776c-4f63-a08f-00ad1acf9a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-06 11:03:11 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin_original_de-en', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=True, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='de', srcdict='/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/dict.de.txt', suppress_crashes=False, target_lang='en', task='translation', tensorboard_logdir=None, testpref='bpe.hyp_original', tgtdict='/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/dict.en.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=8)\n",
      "2023-04-06 11:03:11 | INFO | fairseq_cli.preprocess | [de] Dictionary: 42024 types\n",
      "2023-04-06 11:03:15 | INFO | fairseq_cli.preprocess | [de] bpe.hyp_original.de: 38880 sents, 783311 tokens, 0.0% replaced (by <unk>)\n",
      "2023-04-06 11:03:15 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin_original_de-en\n",
      "..........\n",
      "2023-04-06 11:03:22 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin_disambiguated_de-en', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=True, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='de', srcdict='/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/dict.de.txt', suppress_crashes=False, target_lang='en', task='translation', tensorboard_logdir=None, testpref='bpe.hyp_disambiguated', tgtdict='/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/dict.en.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=8)\n",
      "2023-04-06 11:03:22 | INFO | fairseq_cli.preprocess | [de] Dictionary: 42024 types\n",
      "2023-04-06 11:03:26 | INFO | fairseq_cli.preprocess | [de] bpe.hyp_disambiguated.de: 38880 sents, 762216 tokens, 0.0% replaced (by <unk>)\n",
      "2023-04-06 11:03:26 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin_disambiguated_de-en\n"
     ]
    }
   ],
   "source": [
    "!fairseq-preprocess \\\n",
    "    --source-lang de \\\n",
    "    --target-lang en \\\n",
    "    --only-source \\\n",
    "    --testpref bpe.hyp_original \\\n",
    "    --srcdict /export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/dict.de.txt \\\n",
    "    --tgtdict /export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/dict.en.txt \\\n",
    "    --destdir data-bin_original_de-en \\\n",
    "    --workers 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "9e6b432b-4a25-49f0-8c7a-03188081d10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-06 12:58:33 | INFO | fairseq_cli.preprocess | Namespace(aim_repo=None, aim_run_hash=None, align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin_disambiguated_de-en', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=True, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang='de', srcdict='/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/dict.de.txt', suppress_crashes=False, target_lang='en', task='translation', tensorboard_logdir=None, testpref='bpe.hyp_disambiguated', tgtdict='/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/dict.en.txt', threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref=None, use_plasma_view=False, user_dir=None, validpref=None, wandb_project=None, workers=8)\n",
      "2023-04-06 12:58:33 | INFO | fairseq_cli.preprocess | [de] Dictionary: 42024 types\n",
      "2023-04-06 12:58:38 | INFO | fairseq_cli.preprocess | [de] bpe.hyp_disambiguated.de: 38880 sents, 884735 tokens, 0.0% replaced (by <unk>)\n",
      "2023-04-06 12:58:38 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin_disambiguated_de-en\n"
     ]
    }
   ],
   "source": [
    "!fairseq-preprocess \\\n",
    "    --source-lang de \\\n",
    "    --target-lang en \\\n",
    "    --only-source \\\n",
    "    --testpref bpe.hyp_disambiguated \\\n",
    "    --srcdict /export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/dict.de.txt \\\n",
    "    --tgtdict /export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/dict.en.txt \\\n",
    "    --destdir data-bin_disambiguated_de-en \\\n",
    "    --workers 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "adde4523-1b4b-4c60-9bfe-33f81a1a0dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS=\"/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble\"\n",
    "NBEST = 10\n",
    "BEAM = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "30d0ecf8-5bb2-4094-9b46-8baf2577abf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-05 17:24:59 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model1.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model2.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model3.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model4.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 64, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 64, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 10, 'beam_mt': 0, 'nbest': 10, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}, 'task': {'_name': 'translation', 'data': 'data-bin_original_de-en', 'source_lang': 'de', 'target_lang': 'en', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-04-05 17:25:01 | INFO | fairseq.tasks.translation | [de] dictionary: 42024 types\n",
      "2023-04-05 17:25:01 | INFO | fairseq.tasks.translation | [en] dictionary: 42024 types\n",
      "2023-04-05 17:25:01 | INFO | fairseq_cli.generate | loading model(s) from /export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model1.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model2.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model3.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model4.pt\n",
      "2023-04-05 17:26:34 | INFO | fairseq.data.data_utils | loaded 38,880 examples from: data-bin_original_de-en/test.de-en.de\n",
      "2023-04-05 17:26:34 | INFO | fairseq.tasks.translation | data-bin_original_de-en test de-en 38880 examples\n",
      "2023-04-05 18:26:43 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2023-04-05 18:26:43 | INFO | fairseq_cli.generate | Translated 38,880 sentences (669,739 tokens) in 2190.8s (17.75 sentences/s, 305.71 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "# Generate N hypothesis\n",
    "!fairseq-generate data-bin_original_de-en  \\\n",
    "    --task translation \\\n",
    "    --source-lang de \\\n",
    "    --target-lang en \\\n",
    "    --path $MODELS/model1.pt:$MODELS/model2.pt:$MODELS/model3.pt:$MODELS/model4.pt \\\n",
    "    --beam $BEAM \\\n",
    "    --nbest $NBEST \\\n",
    "    --batch-size 64 \\\n",
    "    --memory-efficient-fp16 \\\n",
    "    --remove-bpe > original_de-en.decode_Beam_10_backtranslation.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "80ec0c77-ba9a-4947-a8fc-c9508dfc6277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-06 12:58:49 | INFO | fairseq_cli.generate | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': True, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model1.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model2.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model3.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model4.pt', 'post_process': 'subword_nmt', 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': True, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': None, 'batch_size': 64, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': None, 'batch_size_valid': 64, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 10, 'beam_mt': 0, 'nbest': 10, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'wav2vec2', 'extractor_mode': 'default', 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': 'gelu', 'layer_type': 'transformer', 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.0, 'dropout_input': 0.0, 'dropout_features': 0.0, 'final_dim': 0, 'layer_norm_first': False, 'conv_feature_layers': '[(512, 10, 5)] + [(512, 3, 2)] * 4 + [(512,2,2)] + [(512,2,2)]', 'conv_bias': False, 'logit_temp': 0.1, 'quantize_targets': False, 'quantize_input': False, 'same_quantizer': False, 'target_glu': False, 'feature_grad_mult': 1.0, 'quantizer_depth': 1, 'quantizer_factor': 3, 'latent_vars': 320, 'latent_groups': 2, 'latent_dim': 0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': 'static', 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'require_same_masks': True, 'mask_dropout': 0.0, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_before': False, 'mask_channel_selection': 'static', 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'num_negatives': 100, 'negatives_from_everywhere': False, 'cross_sample_negatives': 0, 'codebook_negatives': 0, 'conv_pos': 128, 'conv_pos_groups': 16, 'pos_conv_depth': 1, 'latent_temp': [2.0, 0.5, 0.999995], 'max_positions': 100000, 'checkpoint_activations': False, 'required_seq_len_multiple': 1, 'crop_seq_to_multiple': 1, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': True}, 'task': {'_name': 'translation', 'data': 'data-bin_disambiguated_de-en', 'source_lang': 'de', 'target_lang': 'en', 'load_alignments': False, 'left_pad_source': True, 'left_pad_target': False, 'max_source_positions': 1024, 'max_target_positions': 1024, 'upsample_primary': -1, 'truncate_source': False, 'num_batch_buckets': 0, 'train_subset': 'train', 'dataset_impl': None, 'required_seq_len_multiple': 1, 'eval_bleu': False, 'eval_bleu_args': '{}', 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': '{}', 'eval_tokenized_bleu': False, 'eval_bleu_remove_bpe': None, 'eval_bleu_print_samples': False}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
      "2023-04-06 12:58:50 | INFO | fairseq.tasks.translation | [de] dictionary: 42024 types\n",
      "2023-04-06 12:58:50 | INFO | fairseq.tasks.translation | [en] dictionary: 42024 types\n",
      "2023-04-06 12:58:50 | INFO | fairseq_cli.generate | loading model(s) from /export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model1.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model2.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model3.pt:/export/data4/vzhekova/biases-data/De-En/wmt19.de-en.joined-dict.ensemble/model4.pt\n",
      "2023-04-06 13:00:24 | INFO | fairseq.data.data_utils | loaded 38,880 examples from: data-bin_disambiguated_de-en/test.de-en.de\n",
      "2023-04-06 13:00:24 | INFO | fairseq.tasks.translation | data-bin_disambiguated_de-en test de-en 38880 examples\n",
      "2023-04-06 14:05:06 | INFO | fairseq_cli.generate | NOTE: hypothesis and token scores are output in base 2\n",
      "2023-04-06 14:05:06 | INFO | fairseq_cli.generate | Translated 38,880 sentences (723,042 tokens) in 2389.1s (16.27 sentences/s, 302.64 tokens/s)\n"
     ]
    }
   ],
   "source": [
    "# Generate N hypothesis\n",
    "!fairseq-generate data-bin_disambiguated_de-en  \\\n",
    "    --task translation \\\n",
    "    --source-lang de \\\n",
    "    --target-lang en \\\n",
    "    --path $MODELS/model1.pt:$MODELS/model2.pt:$MODELS/model3.pt:$MODELS/model4.pt \\\n",
    "    --beam $BEAM \\\n",
    "    --nbest $NBEST \\\n",
    "    --batch-size 64 \\\n",
    "    --memory-efficient-fp16 \\\n",
    "    --remove-bpe > disambiguated_de-en.decode_Beam_10_backtranslation.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "1e0f05a8-383e-49b1-8e1d-dc6f98b09cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'LC_ALL=C sort -V' sorts the results in natural order \n",
    "!grep ^H original_de-en.decode_Beam_10_backtranslation.log | LC_ALL=C sort -V | sed 's/^H-//g' | cut -f 3 | sed 's/ @@//g' > ./hyp_original_back.txt\n",
    "!grep ^H disambiguated_de-en.decode_Beam_10_backtranslation.log | LC_ALL=C sort -V | sed 's/^H-//g' | cut -f 3 | sed 's/ @@//g' > ./hyp_disambiguated_back.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "839b2e7d-758f-4888-8da5-81ad424c5587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished detokenizing.\n"
     ]
    }
   ],
   "source": [
    "# Detokenize text        \n",
    "from sacremoses import MosesPunctNormalizer\n",
    "from sacremoses import MosesTokenizer, MosesDetokenizer\n",
    "from __future__ import print_function\n",
    "\n",
    "md_en = MosesDetokenizer(lang='en')\n",
    "\n",
    "with open('hyp_original_back.txt', encoding='utf8') as fin, open('original_back.txt','w', encoding='utf8') as fout:\n",
    "    for line in fin:\n",
    "        tokens = md_en.detokenize(line.split(), return_str=True)\n",
    "        print(tokens, end='\\n', file=fout)\n",
    "        \n",
    "with open('hyp_disambiguated_back.txt', encoding='utf8') as fin, open('disambiguated_back.txt','w', encoding='utf8') as fout:\n",
    "    for line in fin:\n",
    "        tokens = md_en.detokenize(line.split(), return_str=True)\n",
    "        print(tokens, end='\\n', file=fout)\n",
    "\n",
    "print('Finished detokenizing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44eb10a6-a3dc-4d89-a760-5675a4231e07",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "3b699191-5a9f-4e63-ba22-22ec3ea74197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3888\n",
      "3888\n",
      "3888\n"
     ]
    }
   ],
   "source": [
    "# List with original source sentences\n",
    "source = []\n",
    "with open('en_original.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        source.append(line.strip())\n",
    "        \n",
    "# List with disambiguated source sentences\n",
    "source_disambiguated = []\n",
    "with open('en_disambiguated.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        source_disambiguated.append(line.strip())\n",
    "    \n",
    "# List with nbest sentences for every source\n",
    "nbest_original = []\n",
    "counter = 0\n",
    "temp = []\n",
    "with open('original_back.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        temp.append(line.strip())\n",
    "        counter += 1\n",
    "        if (counter == 100):\n",
    "            nbest_original.append(temp)\n",
    "            counter = 0\n",
    "            temp = []\n",
    "            \n",
    "nbest_modified = []\n",
    "with open('disambiguated_back.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        temp.append(line.strip())\n",
    "        counter += 1\n",
    "        if (counter == 100):\n",
    "            nbest_modified.append(temp)\n",
    "            counter = 0\n",
    "            temp = []\n",
    "            \n",
    "print(len(source))\n",
    "print(len(nbest_original))\n",
    "print(len(nbest_modified))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db2cdc2-6c1f-48d1-9850-b7ad600e2b05",
   "metadata": {},
   "source": [
    "## Source sentence occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "ff840efd-694a-48b1-9c93-fa60cb0aebad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10443\n",
      "1836\n"
     ]
    }
   ],
   "source": [
    "# Count how many times the source sentence occurs in the nbest list of original\n",
    "results = []\n",
    "counter = 0\n",
    "for sent in source:\n",
    "    matches = 0\n",
    "    for target in nbest_original[counter]: \n",
    "        if (sent == target):\n",
    "            matches += 1\n",
    "    results.append(matches)  \n",
    "    counter += 1\n",
    "    \n",
    "print(sum(results))\n",
    "print(sum(x > 0 for x in results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "40442bbf-1bf9-495e-90c6-d0135c4c9aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4895\n",
      "1056\n"
     ]
    }
   ],
   "source": [
    "# Count how many times the source sentence occurs in the nbest list of modified\n",
    "results = []\n",
    "counter = 0\n",
    "for sent in source_disambiguated:\n",
    "    matches = 0\n",
    "    for target in nbest_modified[counter]: \n",
    "        if (sent == target):\n",
    "            matches += 1\n",
    "    results.append(matches)  \n",
    "    counter += 1\n",
    "    \n",
    "print(sum(results))\n",
    "print(sum(x > 0 for x in results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "deea2585-8fae-4569-8701-92d2737671ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract gender ambiguous words\n",
    "with open('en.csv') as csv_file, open('words.txt', 'w') as out_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        print(row[3], end='\\n', file=out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "f356ad93-4cab-45b1-9021-447f031dc4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3888\n",
      "3888\n",
      "3888\n"
     ]
    }
   ],
   "source": [
    "# List with source words\n",
    "source = []\n",
    "with open('words.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        source.append(line.strip())\n",
    "        \n",
    "# List with nbest sentences for every source\n",
    "nbest_original = []\n",
    "counter = 0\n",
    "temp = []\n",
    "with open('original_back.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        temp.append(line.strip())\n",
    "        counter += 1\n",
    "        if (counter == 100):\n",
    "            nbest_original.append(temp)\n",
    "            counter = 0\n",
    "            temp = []\n",
    "\n",
    "nbest_modified = []\n",
    "with open('disambiguated_back.txt', 'r') as fin:\n",
    "    for line in fin:\n",
    "        temp.append(line.strip())\n",
    "        counter += 1\n",
    "        if (counter == 100):\n",
    "            nbest_modified.append(temp)\n",
    "            counter = 0\n",
    "            temp = []  \n",
    "\n",
    "print(len(source))\n",
    "print(len(nbest_original))\n",
    "print(len(nbest_modified))     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaadbcc-9b2a-49c2-959e-5a021652d186",
   "metadata": {},
   "source": [
    "## Ambiguous source words occurrence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "7a7bd03c-b201-4a54-a5c6-f7eb38b6401f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242903\n",
      "3409\n"
     ]
    }
   ],
   "source": [
    "# Count how many times the source words occurs in the nbest list of original\n",
    "results = []\n",
    "counter = 0\n",
    "for word in source:\n",
    "    matches = 0\n",
    "    for target in nbest_original[counter]: \n",
    "        if (word in target.split(\" \")):\n",
    "            matches += 1\n",
    "    results.append(matches)  \n",
    "    counter += 1\n",
    "    \n",
    "print(sum(results))\n",
    "print(sum(x > 0 for x in results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "586ab32e-df51-4807-869e-1c38dd6eb91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233948\n",
      "3327\n"
     ]
    }
   ],
   "source": [
    "# Count how many times the source words occurs in the nbest list of modified\n",
    "results = []\n",
    "counter = 0\n",
    "for word in source:\n",
    "    matches = 0\n",
    "    for target in nbest_modified[counter]: \n",
    "        if (word in target.split(\" \")):\n",
    "            matches += 1\n",
    "    results.append(matches)  \n",
    "    counter += 1\n",
    "    \n",
    "print(sum(results))\n",
    "print(sum(x > 0 for x in results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d108e61f-10ed-407e-a8a4-5cacd11582b7",
   "metadata": {},
   "source": [
    "## Count unique sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "996ea62c-7608-4773-8ae3-9c26284f8bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.48688271604938\n"
     ]
    }
   ],
   "source": [
    "# Count unique sentences in source nbest list for each source sentence of original\n",
    "unique_sent = []\n",
    "for source_nbest in nbest_original:\n",
    "    num_values = len(set(source_nbest))\n",
    "    #print(num_values)\n",
    "    unique_sent.append(num_values)\n",
    "    \n",
    "#print(unique_sent)\n",
    "print(sum(unique_sent)/3888) # average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "dead57f9-1f48-4edc-85aa-44d545f6a5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48.79526748971193\n"
     ]
    }
   ],
   "source": [
    "# Count unique sentences in source nbest list for each source sentence of modified\n",
    "unique_sent = []\n",
    "for source_nbest in nbest_modified:\n",
    "    num_values = len(set(source_nbest))\n",
    "    #print(num_values)\n",
    "    unique_sent.append(num_values)\n",
    "    \n",
    "#print(unique_sent)\n",
    "print(sum(unique_sent)/3888) # average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "781b95a9-5aa5-4651-a171-0ed6ad92475b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#plt.bar(np.arange(len(unique_sent)), unique_sent)\n",
    "plt.hist(unique_sent, bins=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a77ec6-3c5d-47b9-88b6-eb0fd42665b1",
   "metadata": {},
   "source": [
    "## Count unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08badb74-906c-4a52-8b66-acfd04df0da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique words in source nbest list for each source sentence of original; 18.261574074074073\n",
    "import spacy\n",
    "\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "\n",
    "unique_words = []\n",
    "counter = 0\n",
    "for source_nbest in nbest_original:\n",
    "    words = set()\n",
    "    for sent in source_nbest:\n",
    "        tokens = sp(sent)\n",
    "        for token in tokens:\n",
    "            if token.text not in stopwords:    # checking whether the word is a stop word\n",
    "                words.add(token.text)\n",
    "    num_values = len(words)\n",
    "    unique_words.append(num_values)\n",
    "    \n",
    "    counter += 1\n",
    "    print(counter)\n",
    "    \n",
    "#print(unique_words)\n",
    "print(sum(unique_words)/3888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8501c996-45fd-4137-a860-48d1a634b2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count unique words in source nbest list for each source sentence of modified; 19.38065843621399\n",
    "import spacy\n",
    "\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "\n",
    "unique_words = []\n",
    "counter = 0\n",
    "for source_nbest in nbest_modified:\n",
    "    words = set()\n",
    "    for sent in source_nbest:\n",
    "        tokens = sp(sent)\n",
    "        for token in tokens:\n",
    "            if token.text not in stopwords:    # checking whether the word is a stop word\n",
    "                words.add(token.text)\n",
    "    num_values = len(words)\n",
    "    unique_words.append(num_values)\n",
    "    \n",
    "    counter += 1\n",
    "    print(counter)\n",
    "    \n",
    "#print(unique_words)\n",
    "print(sum(unique_words)/3888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f33804-290b-442c-ad0b-31360be74206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
